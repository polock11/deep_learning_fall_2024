{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the data using ImageFolder\n",
    "train_dir = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/data/train/'\n",
    "test_dir = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/data/test/'\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.class_to_idx\n",
    "\n",
    "idx2cls = {\n",
    "    0: 'pizza',\n",
    "    1: 'steak'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  # Output: 6, 60x60\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Output: 6, 30x30\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # Output: 16, 26x26\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)  # Output: 32, 22x22\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 512)  # input size: 32*4*4\n",
    "        self.fc2 = nn.Linear(512, 224)\n",
    "        self.fc3 = nn.Linear(224, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 6, 28, 28 color channel=3, out put channel(random)=6, kernel=5. input 32 pixel. [input(32)- kernel(5)]/strid(1) = 27 + 1 = 28 \n",
    "        self.pool = nn.MaxPool2d(2, 2) # 6, 14, 14, after pooling, devide height(28)/2, weight(28)/2, nXn pool metrics \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # 16, 10, 10 -> 16, 5,5\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 16)\n",
    "        self.fc2 = nn.Linear(8, 84)\n",
    "        self.fc3 = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 2  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 3  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 4  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 5  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 6  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 7  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 8  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 9  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 10  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 11  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 12  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 13  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 14  Training Loss: 0.0000  Accuracy: 100.00%\n",
      "Epoch: 15  Training Loss: 0.0000  Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model.train()\n",
    "    tr_loss = 0.0\n",
    "    correct_preds = 0  # To track correct predictions\n",
    "    total_preds = 0  # To track total predictions\n",
    "\n",
    "    for img, label in train_loader:\n",
    "        img, label = img.to('mps'), label.unsqueeze(-1).to('mps').float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fun(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions\n",
    "        # Use a threshold of 0.5 to classify the predictions as 0 or 1\n",
    "        preds = torch.round(torch.sigmoid(output))  # Applying sigmoid and rounding to get binary output\n",
    "        correct_preds += (preds == label).sum().item()  # Count correct predictions\n",
    "        total_preds += label.size(0)  # Count total samples\n",
    "    \n",
    "    tr_loss /= len(train_loader)\n",
    "    accuracy = (correct_preds / total_preds) * 100  # Calculate accuracy in percentage\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}  Training Loss: {tr_loss:.4f}  Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.0697  Test Accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "eval_loss = 0.0\n",
    "correct_preds = 0\n",
    "total_preds = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to('mps'), label.unsqueeze(-1).to('mps').float()\n",
    "        \n",
    "        output = model(img)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fun(output, label)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions\n",
    "        preds = torch.round(torch.sigmoid(output))  # Apply sigmoid and round to get binary predictions\n",
    "        correct_preds += (preds == label).sum().item()  # Count correct predictions\n",
    "        total_preds += label.size(0)  # Count total samples\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "eval_loss /= len(test_loader)\n",
    "accuracy = (correct_preds / total_preds) * 100\n",
    "\n",
    "print(f\"Test Loss: {eval_loss:.4f}  Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza\n",
      "pizza\n",
      "pizza\n",
      "steak\n",
      "pizza\n",
      "steak\n",
      "pizza\n",
      "steak\n",
      "steak\n",
      "pizza\n",
      "steak\n",
      "steak\n",
      "pizza\n",
      "pizza\n"
     ]
    }
   ],
   "source": [
    "# inference \n",
    "\n",
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_image(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_path = [\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/p1.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/p2.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/p3.jpg\",\n",
    "              '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/p4.jpg',\n",
    "              '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/p5.jpg',\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s1.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s2.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s3.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s4.webp\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s5.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s6.JPG\",\n",
    "              #\"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s7.avif\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s8.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s9.jpg\",\n",
    "              \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/pizza_steak_classification/s10.jpg\"\n",
    "              ]\n",
    "#image_path = [\"p1.jpg\", \"p2.jpg,\",\"p3.jpg\", \"p4.jpg,\", \"p5.jpg\"]\n",
    "images = [load_image(img) for img in image_path]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img in images:\n",
    "        img = img.to(\"mps\")\n",
    "        out = model(img)\n",
    "        preds = torch.round(torch.sigmoid(out))\n",
    "        print(idx2cls[int(preds.item())])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
