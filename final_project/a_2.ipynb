{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\"\"\"\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if img.mode != 'RGB':\n",
    "            raise ValueError(\"Input image must be in RGB mode\")\n",
    "        \n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            img_np = np.array(img)\n",
    "            \n",
    "            # Convert RGB to LAB (note OpenCV uses BGR but PIL uses RGB)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            \n",
    "            # Apply CLAHE to the L channel\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            \n",
    "            # Merge the channels back and convert back to RGB\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            \n",
    "            # Convert NumPy array back to PIL image\n",
    "            return Image.fromarray(img_np)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet34(pretrained=True)\n",
    "        #self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 50/50 [00:23<00:00,  2.15 batch/s, lr=1.0e-04, Loss=1.3285]\n",
      "[Train] Kappa: 0.3145 Accuracy: 0.3508 Precision: 0.3392 Recall: 0.3508 Loss: 1.4889\n",
      "[Train] Class 0: Precision: 0.6026, Recall: 0.6444\n",
      "[Train] Class 1: Precision: 0.2294, Recall: 0.2083\n",
      "[Train] Class 2: Precision: 0.2500, Recall: 0.2000\n",
      "[Train] Class 3: Precision: 0.2563, Recall: 0.3375\n",
      "[Train] Class 4: Precision: 0.1124, Recall: 0.0833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.15 batch/s]\n",
      "[Val] Kappa: 0.6458 Accuracy: 0.5400 Precision: 0.3772 Recall: 0.5400\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-04, Loss=1.4023]\n",
      "[Train] Kappa: 0.5951 Accuracy: 0.4950 Precision: 0.4660 Recall: 0.4950 Loss: 1.2531\n",
      "[Train] Class 0: Precision: 0.7117, Recall: 0.8778\n",
      "[Train] Class 1: Precision: 0.3680, Recall: 0.1917\n",
      "[Train] Class 2: Precision: 0.3262, Recall: 0.3792\n",
      "[Train] Class 3: Precision: 0.4017, Recall: 0.5792\n",
      "[Train] Class 4: Precision: 0.3333, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.15 batch/s]\n",
      "[Val] Kappa: 0.7755 Accuracy: 0.5475 Precision: 0.4689 Recall: 0.5475\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-04, Loss=1.2770]\n",
      "[Train] Kappa: 0.6855 Accuracy: 0.5425 Precision: 0.4974 Recall: 0.5425 Loss: 1.1297\n",
      "[Train] Class 0: Precision: 0.7730, Recall: 0.9083\n",
      "[Train] Class 1: Precision: 0.4204, Recall: 0.3958\n",
      "[Train] Class 2: Precision: 0.3495, Recall: 0.3000\n",
      "[Train] Class 3: Precision: 0.4695, Recall: 0.6417\n",
      "[Train] Class 4: Precision: 0.1765, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.56 batch/s]\n",
      "[Val] Kappa: 0.6865 Accuracy: 0.5550 Precision: 0.3877 Recall: 0.5550\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.27 batch/s, lr=1.0e-04, Loss=1.0482]\n",
      "[Train] Kappa: 0.7138 Accuracy: 0.5708 Precision: 0.5353 Recall: 0.5708 Loss: 1.0616\n",
      "[Train] Class 0: Precision: 0.7819, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.4545, Recall: 0.5208\n",
      "[Train] Class 2: Precision: 0.3121, Recall: 0.2042\n",
      "[Train] Class 3: Precision: 0.5324, Recall: 0.6500\n",
      "[Train] Class 4: Precision: 0.4091, Recall: 0.1500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.84 batch/s]\n",
      "[Val] Kappa: 0.5530 Accuracy: 0.5500 Precision: 0.4937 Recall: 0.5500\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.27 batch/s, lr=1.0e-04, Loss=0.9567]\n",
      "[Train] Kappa: 0.7458 Accuracy: 0.5733 Precision: 0.5543 Recall: 0.5733 Loss: 1.0315\n",
      "[Train] Class 0: Precision: 0.8247, Recall: 0.8889\n",
      "[Train] Class 1: Precision: 0.4950, Recall: 0.4167\n",
      "[Train] Class 2: Precision: 0.3421, Recall: 0.3250\n",
      "[Train] Class 3: Precision: 0.5247, Recall: 0.7083\n",
      "[Train] Class 4: Precision: 0.3448, Recall: 0.1667\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.91 batch/s]\n",
      "[Val] Kappa: 0.7846 Accuracy: 0.6325 Precision: 0.5838 Recall: 0.6325\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-04, Loss=0.8240]\n",
      "[Train] Kappa: 0.7998 Accuracy: 0.6275 Precision: 0.6102 Recall: 0.6275 Loss: 0.9372\n",
      "[Train] Class 0: Precision: 0.8346, Recall: 0.9250\n",
      "[Train] Class 1: Precision: 0.5907, Recall: 0.5833\n",
      "[Train] Class 2: Precision: 0.4615, Recall: 0.4000\n",
      "[Train] Class 3: Precision: 0.5374, Recall: 0.6583\n",
      "[Train] Class 4: Precision: 0.4194, Recall: 0.2167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.50 batch/s]\n",
      "[Val] Kappa: 0.7468 Accuracy: 0.5825 Precision: 0.6437 Recall: 0.5825\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.23 batch/s, lr=1.0e-04, Loss=1.4485]\n",
      "[Train] Kappa: 0.8066 Accuracy: 0.6667 Precision: 0.6522 Recall: 0.6667 Loss: 0.8868\n",
      "[Train] Class 0: Precision: 0.8411, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.6458, Recall: 0.6458\n",
      "[Train] Class 2: Precision: 0.5179, Recall: 0.4208\n",
      "[Train] Class 3: Precision: 0.5654, Recall: 0.7208\n",
      "[Train] Class 4: Precision: 0.5400, Recall: 0.2250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.56 batch/s]\n",
      "[Val] Kappa: 0.8070 Accuracy: 0.6475 Precision: 0.6165 Recall: 0.6475\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.26 batch/s, lr=1.0e-04, Loss=1.1961]\n",
      "[Train] Kappa: 0.8048 Accuracy: 0.6467 Precision: 0.6317 Recall: 0.6467 Loss: 0.8993\n",
      "[Train] Class 0: Precision: 0.8202, Recall: 0.9250\n",
      "[Train] Class 1: Precision: 0.6332, Recall: 0.6042\n",
      "[Train] Class 2: Precision: 0.5172, Recall: 0.4375\n",
      "[Train] Class 3: Precision: 0.5529, Recall: 0.6750\n",
      "[Train] Class 4: Precision: 0.4493, Recall: 0.2583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.38 batch/s]\n",
      "[Val] Kappa: 0.7974 Accuracy: 0.6500 Precision: 0.6295 Recall: 0.6500\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.28 batch/s, lr=1.0e-04, Loss=0.7207]\n",
      "[Train] Kappa: 0.8115 Accuracy: 0.6467 Precision: 0.6354 Recall: 0.6467 Loss: 0.8945\n",
      "[Train] Class 0: Precision: 0.8291, Recall: 0.9028\n",
      "[Train] Class 1: Precision: 0.5960, Recall: 0.6208\n",
      "[Train] Class 2: Precision: 0.4800, Recall: 0.4000\n",
      "[Train] Class 3: Precision: 0.5802, Recall: 0.7083\n",
      "[Train] Class 4: Precision: 0.5538, Recall: 0.3000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.31 batch/s]\n",
      "[Val] Kappa: 0.7747 Accuracy: 0.6450 Precision: 0.6395 Recall: 0.6450\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.27 batch/s, lr=1.0e-04, Loss=0.9487]\n",
      "[Train] Kappa: 0.8025 Accuracy: 0.6800 Precision: 0.6691 Recall: 0.6800 Loss: 0.8662\n",
      "[Train] Class 0: Precision: 0.8358, Recall: 0.9333\n",
      "[Train] Class 1: Precision: 0.6623, Recall: 0.6375\n",
      "[Train] Class 2: Precision: 0.5276, Recall: 0.4375\n",
      "[Train] Class 3: Precision: 0.6069, Recall: 0.7333\n",
      "[Train] Class 4: Precision: 0.5897, Recall: 0.3833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.57 batch/s]\n",
      "[Val] Kappa: 0.7892 Accuracy: 0.6475 Precision: 0.6288 Recall: 0.6475\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.26 batch/s, lr=1.0e-05, Loss=0.6367]\n",
      "[Train] Kappa: 0.8161 Accuracy: 0.7142 Precision: 0.7041 Recall: 0.7142 Loss: 0.7971\n",
      "[Train] Class 0: Precision: 0.8361, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.6680, Recall: 0.7125\n",
      "[Train] Class 2: Precision: 0.6082, Recall: 0.4917\n",
      "[Train] Class 3: Precision: 0.6594, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.6610, Recall: 0.3250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.74 batch/s]\n",
      "[Val] Kappa: 0.8065 Accuracy: 0.6700 Precision: 0.6570 Recall: 0.6700\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.26 batch/s, lr=1.0e-05, Loss=0.5891]\n",
      "[Train] Kappa: 0.8658 Accuracy: 0.7367 Precision: 0.7298 Recall: 0.7367 Loss: 0.7309\n",
      "[Train] Class 0: Precision: 0.8797, Recall: 0.9750\n",
      "[Train] Class 1: Precision: 0.7345, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6000, Recall: 0.5250\n",
      "[Train] Class 3: Precision: 0.6522, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.6854, Recall: 0.5083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.54 batch/s]\n",
      "[Val] Kappa: 0.8029 Accuracy: 0.6675 Precision: 0.6549 Recall: 0.6675\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.26 batch/s, lr=1.0e-05, Loss=0.5573]\n",
      "[Train] Kappa: 0.8620 Accuracy: 0.7317 Precision: 0.7217 Recall: 0.7317 Loss: 0.7343\n",
      "[Train] Class 0: Precision: 0.8655, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.7202, Recall: 0.7292\n",
      "[Train] Class 2: Precision: 0.6453, Recall: 0.4625\n",
      "[Train] Class 3: Precision: 0.6429, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.6042, Recall: 0.4833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.50 batch/s]\n",
      "[Val] Kappa: 0.8153 Accuracy: 0.6750 Precision: 0.6650 Recall: 0.6750\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-05, Loss=0.5720]\n",
      "[Train] Kappa: 0.8597 Accuracy: 0.7467 Precision: 0.7387 Recall: 0.7467 Loss: 0.6882\n",
      "[Train] Class 0: Precision: 0.8794, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.7257, Recall: 0.7167\n",
      "[Train] Class 2: Precision: 0.6337, Recall: 0.5333\n",
      "[Train] Class 3: Precision: 0.6832, Recall: 0.7458\n",
      "[Train] Class 4: Precision: 0.6634, Recall: 0.5583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.32 batch/s]\n",
      "[Val] Kappa: 0.8111 Accuracy: 0.6725 Precision: 0.6577 Recall: 0.6725\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.24 batch/s, lr=1.0e-05, Loss=0.5050]\n",
      "[Train] Kappa: 0.8766 Accuracy: 0.7467 Precision: 0.7409 Recall: 0.7467 Loss: 0.6872\n",
      "[Train] Class 0: Precision: 0.8935, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7178, Recall: 0.7208\n",
      "[Train] Class 2: Precision: 0.6056, Recall: 0.5375\n",
      "[Train] Class 3: Precision: 0.6889, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.7033, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.46 batch/s]\n",
      "[Val] Kappa: 0.8125 Accuracy: 0.6725 Precision: 0.6581 Recall: 0.6725\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-05, Loss=0.6677]\n",
      "[Train] Kappa: 0.8756 Accuracy: 0.7575 Precision: 0.7509 Recall: 0.7575 Loss: 0.6720\n",
      "[Train] Class 0: Precision: 0.8906, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.7300, Recall: 0.7208\n",
      "[Train] Class 2: Precision: 0.6296, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.7066, Recall: 0.7625\n",
      "[Train] Class 4: Precision: 0.7053, Recall: 0.5583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.33 batch/s]\n",
      "[Val] Kappa: 0.8029 Accuracy: 0.6550 Precision: 0.6423 Recall: 0.6550\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-05, Loss=0.7828]\n",
      "[Train] Kappa: 0.8655 Accuracy: 0.7433 Precision: 0.7380 Recall: 0.7433 Loss: 0.6855\n",
      "[Train] Class 0: Precision: 0.8791, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7443, Recall: 0.6792\n",
      "[Train] Class 2: Precision: 0.6150, Recall: 0.5792\n",
      "[Train] Class 3: Precision: 0.6703, Recall: 0.7792\n",
      "[Train] Class 4: Precision: 0.6835, Recall: 0.4500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.44 batch/s]\n",
      "[Val] Kappa: 0.8021 Accuracy: 0.6775 Precision: 0.6622 Recall: 0.6775\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.28 batch/s, lr=1.0e-05, Loss=0.6397]\n",
      "[Train] Kappa: 0.8659 Accuracy: 0.7542 Precision: 0.7495 Recall: 0.7542 Loss: 0.6814\n",
      "[Train] Class 0: Precision: 0.8889, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7218, Recall: 0.7458\n",
      "[Train] Class 2: Precision: 0.6700, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.6750, Recall: 0.7875\n",
      "[Train] Class 4: Precision: 0.6951, Recall: 0.4750\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.03 batch/s]\n",
      "[Val] Kappa: 0.8026 Accuracy: 0.6800 Precision: 0.6620 Recall: 0.6800\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.27 batch/s, lr=1.0e-05, Loss=0.5926]\n",
      "[Train] Kappa: 0.8666 Accuracy: 0.7500 Precision: 0.7446 Recall: 0.7500 Loss: 0.6727\n",
      "[Train] Class 0: Precision: 0.8804, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7229, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.6234, Recall: 0.6000\n",
      "[Train] Class 3: Precision: 0.7054, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.7011, Recall: 0.5083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.40 batch/s]\n",
      "[Val] Kappa: 0.8103 Accuracy: 0.6650 Precision: 0.6515 Recall: 0.6650\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-05, Loss=0.3997]\n",
      "[Train] Kappa: 0.8648 Accuracy: 0.7583 Precision: 0.7520 Recall: 0.7583 Loss: 0.6516\n",
      "[Train] Class 0: Precision: 0.8788, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.7489, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.6502, Recall: 0.6042\n",
      "[Train] Class 3: Precision: 0.7126, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.6598, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.20 batch/s]\n",
      "[Val] Kappa: 0.8047 Accuracy: 0.6625 Precision: 0.6465 Recall: 0.6625\n",
      "[Val] Best kappa: 0.8153, Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_36089/2432807949.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.06 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/a_3_base_model_gaus_claheV1_adamW_pred.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/a_3_base_model_gaus_claheV1_adamW.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/a_3_base_model_gaus_claheV1_adamW.pth'\n",
    "    state_dict = torch.load(path, map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    prediction_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/a_3_base_model_gaus_claheV1_adamW_pred.csv\"\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=prediction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with Resnet18\n",
    "\n",
    "Epoch 11/20\n",
    "Training: 100%|██████████| 50/50 [00:11<00:00,  4.48 batch/s, lr=1.0e-05, Loss=1.0473]\n",
    "[Train] Kappa: 0.8786 Accuracy: 0.7458 Precision: 0.7396 Recall: 0.7458 Loss: 0.6523\n",
    "[Train] Class 0: Precision: 0.8992, Recall: 0.9667\n",
    "[Train] Class 1: Precision: 0.7377, Recall: 0.7500\n",
    "[Train] Class 2: Precision: 0.6471, Recall: 0.5500\n",
    "[Train] Class 3: Precision: 0.6451, Recall: 0.7875\n",
    "[Train] Class 4: Precision: 0.6389, Recall: 0.3833\n",
    "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.03 batch/s]\n",
    "[Val] Kappa: 0.8429 Accuracy: 0.6650 Precision: 0.6726 Recall: 0.6650\n",
    "\n",
    "\n",
    "\n",
    "with ResNet34\n",
    "\n",
    "Epoch 16/20\n",
    "Training: 100%|██████████| 50/50 [00:16<00:00,  2.98 batch/s, lr=1.0e-05, Loss=0.3478]\n",
    "[Train] Kappa: 0.9036 Accuracy: 0.8308 Precision: 0.8289 Recall: 0.8308 Loss: 0.4927\n",
    "[Train] Class 0: Precision: 0.9219, Recall: 0.9833\n",
    "[Train] Class 1: Precision: 0.8451, Recall: 0.7958\n",
    "[Train] Class 2: Precision: 0.7333, Recall: 0.7333\n",
    "[Train] Class 3: Precision: 0.7880, Recall: 0.8208\n",
    "[Train] Class 4: Precision: 0.7900, Recall: 0.6583\n",
    "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.05 batch/s]\n",
    "[Val] Kappa: 0.8179 Accuracy: 0.6750 Precision: 0.6551 Recall: 0.6750\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augementation Techs\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize the shorter side to 256, keeping aspect ratio\n",
    "    transforms.RandomCrop(224),  # Random crop to 224x224\n",
    "    SLORandomPad((224, 224)),  # Ensure this custom transform works correctly\n",
    "    FundRandomRotate(prob=0.5, degree=30),  # Ensure this custom transform works correctly\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    # Optionally uncomment if needed:\n",
    "    # transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n",
    "    # transforms.GaussianBlur(kernel_size=(7, 13), sigma=(6, 9)),\n",
    "    transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Ensure CLAHE is implemented correctly\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "with ResNet18 GausBlur, CLAHE, autoaugement, and upper transform config\n",
    "\n",
    "Epoch 8/20\n",
    "Training: 100%|██████████| 50/50 [00:18<00:00,  2.73 batch/s, lr=1.0e-04, Loss=0.8939]\n",
    "[Train] Kappa: 0.7496 Accuracy: 0.5942 Precision: 0.5795 Recall: 0.5942 Loss: 1.0358\n",
    "[Train] Class 0: Precision: 0.7627, Recall: 0.8750\n",
    "[Train] Class 1: Precision: 0.5529, Recall: 0.4792\n",
    "[Train] Class 2: Precision: 0.4354, Recall: 0.3792\n",
    "[Train] Class 3: Precision: 0.5250, Recall: 0.7000\n",
    "[Train] Class 4: Precision: 0.4800, Recall: 0.2000\n",
    "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.27 batch/s]\n",
    "[Val] Kappa: 0.8143 Accuracy: 0.6275 Precision: 0.6758 Recall: 0.6275\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "with ResNet18 autoaugement, and upper transform config\n",
    "\n",
    "Epoch 14/20\n",
    "Training: 100%|██████████| 50/50 [00:17<00:00,  2.84 batch/s, lr=1.0e-05, Loss=1.0051]\n",
    "[Train] Kappa: 0.7815 Accuracy: 0.6317 Precision: 0.6174 Recall: 0.6317 Loss: 0.9307\n",
    "[Train] Class 0: Precision: 0.8062, Recall: 0.9361\n",
    "[Train] Class 1: Precision: 0.6215, Recall: 0.5542\n",
    "[Train] Class 2: Precision: 0.4686, Recall: 0.4042\n",
    "[Train] Class 3: Precision: 0.5331, Recall: 0.6708\n",
    "[Train] Class 4: Precision: 0.5085, Recall: 0.2500\n",
    "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.92 batch/s]\n",
    "[Val] Kappa: 0.8334 Accuracy: 0.6850 Precision: 0.6852 Recall: 0.6850\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "with Resnet 18, gaus and CLAHE v1\n",
    "\n",
    "Epoch 12/20\n",
    "Training: 100%|██████████| 50/50 [00:22<00:00,  2.24 batch/s, lr=1.0e-05, Loss=0.7302]\n",
    "[Train] Kappa: 0.8457 Accuracy: 0.7175 Precision: 0.7085 Recall: 0.7175 Loss: 0.7656\n",
    "[Train] Class 0: Precision: 0.8593, Recall: 0.9500\n",
    "[Train] Class 1: Precision: 0.6983, Recall: 0.6750\n",
    "[Train] Class 2: Precision: 0.6119, Recall: 0.5583\n",
    "[Train] Class 3: Precision: 0.6473, Recall: 0.7417\n",
    "[Train] Class 4: Precision: 0.5921, Recall: 0.3750\n",
    "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.22 batch/s]\n",
    "[Val] Kappa: 0.8265 Accuracy: 0.6775 Precision: 0.6480 Recall: 0.6775\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
