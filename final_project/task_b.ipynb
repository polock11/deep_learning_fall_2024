{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['id_code'] = os.path.join(self.image_dir, row['id_code'])\n",
    "            if not self.test:\n",
    "                file_info['diagnosis'] = int(row['diagnosis'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['id_code']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['diagnosis'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRDatasetPatient(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Group by patient_id\n",
    "        self.patient_groups = self.dataframe.groupby('patient_id')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get patient group\n",
    "        patient_id = list(self.patient_groups.groups.keys())[idx]\n",
    "        group = self.patient_groups.get_group(patient_id)\n",
    "\n",
    "        # Load all images for this patient\n",
    "        images = []\n",
    "        labels = group['level'].iloc[0]  # Assume all images for a patient have the same label\n",
    "\n",
    "        for img_name in group['image']:\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            images.append(img)\n",
    "\n",
    "        # Stack all images into a single tensor\n",
    "        images = torch.stack(images)  # Shape: (num_images, C, H, W)\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group images by patient ID\n",
    "df['patient_id'] = df['image'].str.split('_').str[0]  # Extract patient ID from image name\n",
    "\n",
    "# Oversample patients in each class\n",
    "balanced_df = df.groupby('level', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=df['level'].value_counts().max(), replace=True, random_state=42)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the balanced DataFrame\n",
    "train_dataset = DRDatasetPatient(balanced_df, img_dir, transform=transform_train)\n",
    "val_dataset = DRDatasetPatient(val_df, img_dir, transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the shapes\n",
    "for images, labels in train_loader:\n",
    "    print(\"Batch Image Shape:\", images.shape)  # (batch_size, num_images, C, H, W)\n",
    "    print(\"Batch Label Shape:\", labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True, )\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                \"\"\"\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "                        \"\"\"\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_images/train_images/\"\n",
    "train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_1.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/val_images/val_images/\"\n",
    "val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/valid.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "val_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 92/92 [05:05<00:00,  3.32s/ batch, lr=1.0e-04, Loss=0.4952]\n",
      "[Train] Kappa: 0.5058 Accuracy: 0.6212 Precision: 0.5505 Recall: 0.6212 Loss: 1.0548\n",
      "[Train] Class 0: Precision: 0.7878, Recall: 0.8466\n",
      "[Train] Class 1: Precision: 0.1462, Recall: 0.0633\n",
      "[Train] Class 2: Precision: 0.5169, Recall: 0.7178\n",
      "[Train] Class 3: Precision: 0.0481, Recall: 0.0325\n",
      "[Train] Class 4: Precision: 0.0606, Recall: 0.0085\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.6462 Accuracy: 0.7003 Precision: 0.5365 Recall: 0.7003\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 92/92 [05:06<00:00,  3.33s/ batch, lr=1.0e-04, Loss=0.7283]\n",
      "[Train] Kappa: 0.7608 Accuracy: 0.7321 Precision: 0.6429 Recall: 0.7321 Loss: 0.7406\n",
      "[Train] Class 0: Precision: 0.9241, Recall: 0.9679\n",
      "[Train] Class 1: Precision: 0.4167, Recall: 0.1000\n",
      "[Train] Class 2: Precision: 0.5365, Recall: 0.8998\n",
      "[Train] Class 3: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 92/92 [04:52<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.7750 Accuracy: 0.7618 Precision: 0.6752 Recall: 0.7618\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.7568]\n",
      "[Train] Kappa: 0.7772 Accuracy: 0.7509 Precision: 0.7600 Recall: 0.7509 Loss: 0.6638\n",
      "[Train] Class 0: Precision: 0.9482, Recall: 0.9693\n",
      "[Train] Class 1: Precision: 0.4655, Recall: 0.2700\n",
      "[Train] Class 2: Precision: 0.5643, Recall: 0.8960\n",
      "[Train] Class 3: Precision: 0.7500, Recall: 0.0195\n",
      "[Train] Class 4: Precision: 0.6667, Recall: 0.0085\n",
      "Evaluating: 100%|██████████| 92/92 [04:48<00:00,  3.14s/ batch]\n",
      "[Val] Kappa: 0.7961 Accuracy: 0.7703 Precision: 0.6952 Recall: 0.7703\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.29s/ batch, lr=1.0e-04, Loss=0.3715]\n",
      "[Train] Kappa: 0.8017 Accuracy: 0.7597 Precision: 0.7290 Recall: 0.7597 Loss: 0.6293\n",
      "[Train] Class 0: Precision: 0.9569, Recall: 0.9763\n",
      "[Train] Class 1: Precision: 0.5243, Recall: 0.3600\n",
      "[Train] Class 2: Precision: 0.5798, Recall: 0.8589\n",
      "[Train] Class 3: Precision: 0.4545, Recall: 0.0974\n",
      "[Train] Class 4: Precision: 0.2903, Recall: 0.0385\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8186 Accuracy: 0.7850 Precision: 0.7715 Recall: 0.7850\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4495]\n",
      "[Train] Kappa: 0.8273 Accuracy: 0.7730 Precision: 0.7542 Recall: 0.7730 Loss: 0.6044\n",
      "[Train] Class 0: Precision: 0.9595, Recall: 0.9742\n",
      "[Train] Class 1: Precision: 0.5291, Recall: 0.3933\n",
      "[Train] Class 2: Precision: 0.6162, Recall: 0.8564\n",
      "[Train] Class 3: Precision: 0.3818, Recall: 0.1364\n",
      "[Train] Class 4: Precision: 0.5068, Recall: 0.1581\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8697 Accuracy: 0.7788 Precision: 0.7858 Recall: 0.7788\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.31s/ batch, lr=1.0e-04, Loss=0.4822]\n",
      "[Train] Kappa: 0.8408 Accuracy: 0.7860 Precision: 0.7693 Recall: 0.7860 Loss: 0.5881\n",
      "[Train] Class 0: Precision: 0.9623, Recall: 0.9791\n",
      "[Train] Class 1: Precision: 0.5990, Recall: 0.3833\n",
      "[Train] Class 2: Precision: 0.6337, Recall: 0.8713\n",
      "[Train] Class 3: Precision: 0.4035, Recall: 0.1494\n",
      "[Train] Class 4: Precision: 0.5135, Recall: 0.2436\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8615 Accuracy: 0.8051 Precision: 0.7931 Recall: 0.8051\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.6716]\n",
      "[Train] Kappa: 0.8634 Accuracy: 0.7969 Precision: 0.7795 Recall: 0.7969 Loss: 0.5452\n",
      "[Train] Class 0: Precision: 0.9737, Recall: 0.9805\n",
      "[Train] Class 1: Precision: 0.5848, Recall: 0.4367\n",
      "[Train] Class 2: Precision: 0.6497, Recall: 0.8700\n",
      "[Train] Class 3: Precision: 0.3250, Recall: 0.0844\n",
      "[Train] Class 4: Precision: 0.5857, Recall: 0.3504\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8617 Accuracy: 0.8123 Precision: 0.8152 Recall: 0.8123\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4357]\n",
      "[Train] Kappa: 0.8532 Accuracy: 0.7966 Precision: 0.7824 Recall: 0.7966 Loss: 0.5303\n",
      "[Train] Class 0: Precision: 0.9688, Recall: 0.9742\n",
      "[Train] Class 1: Precision: 0.5817, Recall: 0.4867\n",
      "[Train] Class 2: Precision: 0.6712, Recall: 0.8465\n",
      "[Train] Class 3: Precision: 0.4154, Recall: 0.1753\n",
      "[Train] Class 4: Precision: 0.5229, Recall: 0.3419\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.14s/ batch]\n",
      "[Val] Kappa: 0.8817 Accuracy: 0.8232 Precision: 0.8247 Recall: 0.8232\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4986]\n",
      "[Train] Kappa: 0.8731 Accuracy: 0.8038 Precision: 0.7900 Recall: 0.8038 Loss: 0.5197\n",
      "[Train] Class 0: Precision: 0.9743, Recall: 0.9777\n",
      "[Train] Class 1: Precision: 0.6084, Recall: 0.5333\n",
      "[Train] Class 2: Precision: 0.6856, Recall: 0.8366\n",
      "[Train] Class 3: Precision: 0.3125, Recall: 0.1623\n",
      "[Train] Class 4: Precision: 0.5679, Recall: 0.3932\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8808 Accuracy: 0.8290 Precision: 0.8351 Recall: 0.8290\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4021]\n",
      "[Train] Kappa: 0.8666 Accuracy: 0.8143 Precision: 0.8046 Recall: 0.8143 Loss: 0.5066\n",
      "[Train] Class 0: Precision: 0.9737, Recall: 0.9812\n",
      "[Train] Class 1: Precision: 0.6352, Recall: 0.4933\n",
      "[Train] Class 2: Precision: 0.6845, Recall: 0.8700\n",
      "[Train] Class 3: Precision: 0.5283, Recall: 0.1818\n",
      "[Train] Class 4: Precision: 0.5814, Recall: 0.4274\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.8913 Accuracy: 0.8334 Precision: 0.8251 Recall: 0.8334\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.4925]\n",
      "[Train] Kappa: 0.8855 Accuracy: 0.8195 Precision: 0.8096 Recall: 0.8195 Loss: 0.4814\n",
      "[Train] Class 0: Precision: 0.9779, Recall: 0.9854\n",
      "[Train] Class 1: Precision: 0.6367, Recall: 0.5433\n",
      "[Train] Class 2: Precision: 0.7073, Recall: 0.8403\n",
      "[Train] Class 3: Precision: 0.4409, Recall: 0.2662\n",
      "[Train] Class 4: Precision: 0.5966, Recall: 0.4487\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9046 Accuracy: 0.8495 Precision: 0.8469 Recall: 0.8495\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.3255]\n",
      "[Train] Kappa: 0.9034 Accuracy: 0.8365 Precision: 0.8277 Recall: 0.8365 Loss: 0.4447\n",
      "[Train] Class 0: Precision: 0.9820, Recall: 0.9895\n",
      "[Train] Class 1: Precision: 0.6600, Recall: 0.5500\n",
      "[Train] Class 2: Precision: 0.7220, Recall: 0.8775\n",
      "[Train] Class 3: Precision: 0.4691, Recall: 0.2468\n",
      "[Train] Class 4: Precision: 0.6977, Recall: 0.5128\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9089 Accuracy: 0.8560 Precision: 0.8521 Recall: 0.8560\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.1707]\n",
      "[Train] Kappa: 0.8977 Accuracy: 0.8300 Precision: 0.8225 Recall: 0.8300 Loss: 0.4387\n",
      "[Train] Class 0: Precision: 0.9833, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6749, Recall: 0.5467\n",
      "[Train] Class 2: Precision: 0.7026, Recall: 0.8626\n",
      "[Train] Class 3: Precision: 0.4875, Recall: 0.2532\n",
      "[Train] Class 4: Precision: 0.6609, Recall: 0.4915\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9143 Accuracy: 0.8608 Precision: 0.8587 Recall: 0.8608\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.4524]\n",
      "[Train] Kappa: 0.8991 Accuracy: 0.8406 Precision: 0.8359 Recall: 0.8406 Loss: 0.4305\n",
      "[Train] Class 0: Precision: 0.9813, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6864, Recall: 0.5400\n",
      "[Train] Class 2: Precision: 0.7160, Recall: 0.8923\n",
      "[Train] Class 3: Precision: 0.6133, Recall: 0.2987\n",
      "[Train] Class 4: Precision: 0.6964, Recall: 0.5000\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9176 Accuracy: 0.8628 Precision: 0.8600 Recall: 0.8628\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.5307]\n",
      "[Train] Kappa: 0.9041 Accuracy: 0.8502 Precision: 0.8451 Recall: 0.8502 Loss: 0.4133\n",
      "[Train] Class 0: Precision: 0.9847, Recall: 0.9902\n",
      "[Train] Class 1: Precision: 0.7333, Recall: 0.5867\n",
      "[Train] Class 2: Precision: 0.7315, Recall: 0.9072\n",
      "[Train] Class 3: Precision: 0.6026, Recall: 0.3052\n",
      "[Train] Class 4: Precision: 0.6845, Recall: 0.4915\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9167 Accuracy: 0.8614 Precision: 0.8584 Recall: 0.8614\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 92/92 [05:03<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.2783]\n",
      "[Train] Kappa: 0.9022 Accuracy: 0.8403 Precision: 0.8320 Recall: 0.8403 Loss: 0.4262\n",
      "[Train] Class 0: Precision: 0.9854, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.7131, Recall: 0.5800\n",
      "[Train] Class 2: Precision: 0.7254, Recall: 0.8861\n",
      "[Train] Class 3: Precision: 0.4875, Recall: 0.2532\n",
      "[Train] Class 4: Precision: 0.6389, Recall: 0.4915\n",
      "Evaluating: 100%|██████████| 92/92 [04:49<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9176 Accuracy: 0.8703 Precision: 0.8680 Recall: 0.8703\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.31s/ batch, lr=1.0e-05, Loss=0.3456]\n",
      "[Train] Kappa: 0.8971 Accuracy: 0.8403 Precision: 0.8323 Recall: 0.8403 Loss: 0.4158\n",
      "[Train] Class 0: Precision: 0.9813, Recall: 0.9868\n",
      "[Train] Class 1: Precision: 0.6996, Recall: 0.5900\n",
      "[Train] Class 2: Precision: 0.7280, Recall: 0.8812\n",
      "[Train] Class 3: Precision: 0.5195, Recall: 0.2597\n",
      "[Train] Class 4: Precision: 0.6556, Recall: 0.5043\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.9207 Accuracy: 0.8645 Precision: 0.8599 Recall: 0.8645\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.31s/ batch, lr=1.0e-05, Loss=0.2050]\n",
      "[Train] Kappa: 0.9129 Accuracy: 0.8532 Precision: 0.8482 Recall: 0.8532 Loss: 0.4074\n",
      "[Train] Class 0: Precision: 0.9820, Recall: 0.9868\n",
      "[Train] Class 1: Precision: 0.7099, Recall: 0.6200\n",
      "[Train] Class 2: Precision: 0.7542, Recall: 0.8849\n",
      "[Train] Class 3: Precision: 0.5922, Recall: 0.3961\n",
      "[Train] Class 4: Precision: 0.6989, Recall: 0.5256\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.9147 Accuracy: 0.8635 Precision: 0.8591 Recall: 0.8635\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.31s/ batch, lr=1.0e-05, Loss=0.4898]\n",
      "[Train] Kappa: 0.9055 Accuracy: 0.8410 Precision: 0.8341 Recall: 0.8410 Loss: 0.4186\n",
      "[Train] Class 0: Precision: 0.9827, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.6939, Recall: 0.5667\n",
      "[Train] Class 2: Precision: 0.7217, Recall: 0.8762\n",
      "[Train] Class 3: Precision: 0.5256, Recall: 0.2662\n",
      "[Train] Class 4: Precision: 0.6940, Recall: 0.5427\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.15s/ batch]\n",
      "[Val] Kappa: 0.9187 Accuracy: 0.8730 Precision: 0.8709 Recall: 0.8730\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 92/92 [05:04<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.3107]\n",
      "[Train] Kappa: 0.9059 Accuracy: 0.8447 Precision: 0.8371 Recall: 0.8447 Loss: 0.4106\n",
      "[Train] Class 0: Precision: 0.9841, Recall: 0.9923\n",
      "[Train] Class 1: Precision: 0.7218, Recall: 0.5967\n",
      "[Train] Class 2: Precision: 0.7327, Recall: 0.8787\n",
      "[Train] Class 3: Precision: 0.5000, Recall: 0.2922\n",
      "[Train] Class 4: Precision: 0.6667, Recall: 0.5043\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.9234 Accuracy: 0.8717 Precision: 0.8694 Recall: 0.8717\n",
      "[Val] Best kappa: 0.9234, Epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth'\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
