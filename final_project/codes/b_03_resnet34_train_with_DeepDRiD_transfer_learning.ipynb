{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levelsA\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        eval_loss, val_metrics = evaluate_model(model, val_loader, device,criterion)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model, train_losses, eval_losses\n",
    "\n",
    "def evaluate_model(model, test_loader, device, criterion, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "    eval_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            if not test_only:\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                if not test_only:\n",
    "                    # Calculate loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    eval_loss += loss.item() * labels.size(0)\n",
    "                    total_samples += labels.size(0)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        eval_loss /= total_samples  # Calculate mean loss\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return eval_loss, metrics\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet34(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_92234/3817809042.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "Training: 100%|██████████| 50/50 [00:23<00:00,  2.17 batch/s, lr=1.0e-04, Loss=1.1028]\n",
      "[Train] Kappa: 0.6499 Accuracy: 0.4775 Precision: 0.5165 Recall: 0.4775 Loss: 1.4300\n",
      "[Train] Class 0: Precision: 0.7484, Recall: 0.6611\n",
      "[Train] Class 1: Precision: 0.3919, Recall: 0.4458\n",
      "[Train] Class 2: Precision: 0.3253, Recall: 0.5042\n",
      "[Train] Class 3: Precision: 0.6094, Recall: 0.3250\n",
      "[Train] Class 4: Precision: 0.2661, Recall: 0.2417\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.23 batch/s]\n",
      "[Val] Kappa: 0.7651 Accuracy: 0.6175 Precision: 0.6031 Recall: 0.6175\n",
      "\n",
      "Epoch 2/25\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.28 batch/s, lr=1.0e-04, Loss=0.9998]\n",
      "[Train] Kappa: 0.7311 Accuracy: 0.5833 Precision: 0.5730 Recall: 0.5833 Loss: 1.0733\n",
      "[Train] Class 0: Precision: 0.7664, Recall: 0.8111\n",
      "[Train] Class 1: Precision: 0.4890, Recall: 0.5542\n",
      "[Train] Class 2: Precision: 0.4686, Recall: 0.4042\n",
      "[Train] Class 3: Precision: 0.5606, Recall: 0.6167\n",
      "[Train] Class 4: Precision: 0.3947, Recall: 0.2500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.05 batch/s]\n",
      "[Val] Kappa: 0.7352 Accuracy: 0.5925 Precision: 0.5523 Recall: 0.5925\n",
      "\n",
      "Epoch 3/25\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.34 batch/s, lr=1.0e-04, Loss=1.0576]\n",
      "[Train] Kappa: 0.7762 Accuracy: 0.5900 Precision: 0.5806 Recall: 0.5900 Loss: 1.0262\n",
      "[Train] Class 0: Precision: 0.7892, Recall: 0.8528\n",
      "[Train] Class 1: Precision: 0.4862, Recall: 0.5125\n",
      "[Train] Class 2: Precision: 0.4043, Recall: 0.3958\n",
      "[Train] Class 3: Precision: 0.5788, Recall: 0.6583\n",
      "[Train] Class 4: Precision: 0.5000, Recall: 0.2083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.06 batch/s]\n",
      "[Val] Kappa: 0.7618 Accuracy: 0.5875 Precision: 0.5629 Recall: 0.5875\n",
      "\n",
      "Epoch 4/25\n",
      "Training: 100%|██████████| 50/50 [00:21<00:00,  2.33 batch/s, lr=1.0e-04, Loss=0.8874]\n",
      "[Train] Kappa: 0.7688 Accuracy: 0.6117 Precision: 0.6002 Recall: 0.6117 Loss: 0.9376\n",
      "[Train] Class 0: Precision: 0.8135, Recall: 0.8722\n",
      "[Train] Class 1: Precision: 0.5325, Recall: 0.5125\n",
      "[Train] Class 2: Precision: 0.4340, Recall: 0.4250\n",
      "[Train] Class 3: Precision: 0.5963, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.4359, Recall: 0.2833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.06 batch/s]\n",
      "[Val] Kappa: 0.7898 Accuracy: 0.6525 Precision: 0.6523 Recall: 0.6525\n",
      "\n",
      "Epoch 5/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.22 batch/s, lr=1.0e-04, Loss=0.7374]\n",
      "[Train] Kappa: 0.7907 Accuracy: 0.6408 Precision: 0.6272 Recall: 0.6408 Loss: 0.9363\n",
      "[Train] Class 0: Precision: 0.8241, Recall: 0.9111\n",
      "[Train] Class 1: Precision: 0.5775, Recall: 0.6208\n",
      "[Train] Class 2: Precision: 0.4525, Recall: 0.4167\n",
      "[Train] Class 3: Precision: 0.6113, Recall: 0.6750\n",
      "[Train] Class 4: Precision: 0.5172, Recall: 0.2500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.05 batch/s]\n",
      "[Val] Kappa: 0.7178 Accuracy: 0.6125 Precision: 0.6265 Recall: 0.6125\n",
      "\n",
      "Epoch 6/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.21 batch/s, lr=1.0e-04, Loss=0.7552]\n",
      "[Train] Kappa: 0.8160 Accuracy: 0.6658 Precision: 0.6582 Recall: 0.6658 Loss: 0.8977\n",
      "[Train] Class 0: Precision: 0.8379, Recall: 0.9333\n",
      "[Train] Class 1: Precision: 0.6605, Recall: 0.5917\n",
      "[Train] Class 2: Precision: 0.5000, Recall: 0.5042\n",
      "[Train] Class 3: Precision: 0.5907, Recall: 0.6375\n",
      "[Train] Class 4: Precision: 0.5663, Recall: 0.3917\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.96 batch/s]\n",
      "[Val] Kappa: 0.7882 Accuracy: 0.6600 Precision: 0.6791 Recall: 0.6600\n",
      "\n",
      "Epoch 7/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.20 batch/s, lr=1.0e-04, Loss=0.8213]\n",
      "[Train] Kappa: 0.7829 Accuracy: 0.6483 Precision: 0.6339 Recall: 0.6483 Loss: 0.8832\n",
      "[Train] Class 0: Precision: 0.8321, Recall: 0.9222\n",
      "[Train] Class 1: Precision: 0.6000, Recall: 0.6250\n",
      "[Train] Class 2: Precision: 0.5000, Recall: 0.4458\n",
      "[Train] Class 3: Precision: 0.5984, Recall: 0.6333\n",
      "[Train] Class 4: Precision: 0.4458, Recall: 0.3083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.03 batch/s]\n",
      "[Val] Kappa: 0.7779 Accuracy: 0.6600 Precision: 0.6581 Recall: 0.6600\n",
      "\n",
      "Epoch 8/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.24 batch/s, lr=1.0e-04, Loss=0.5230]\n",
      "[Train] Kappa: 0.8219 Accuracy: 0.6883 Precision: 0.6769 Recall: 0.6883 Loss: 0.8306\n",
      "[Train] Class 0: Precision: 0.8370, Recall: 0.9417\n",
      "[Train] Class 1: Precision: 0.6485, Recall: 0.6458\n",
      "[Train] Class 2: Precision: 0.5507, Recall: 0.4750\n",
      "[Train] Class 3: Precision: 0.6482, Recall: 0.6833\n",
      "[Train] Class 4: Precision: 0.5625, Recall: 0.4500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.06 batch/s]\n",
      "[Val] Kappa: 0.7975 Accuracy: 0.6425 Precision: 0.6610 Recall: 0.6425\n",
      "\n",
      "Epoch 9/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.20 batch/s, lr=1.0e-04, Loss=1.0608]\n",
      "[Train] Kappa: 0.8334 Accuracy: 0.6983 Precision: 0.6886 Recall: 0.6983 Loss: 0.8292\n",
      "[Train] Class 0: Precision: 0.8396, Recall: 0.9306\n",
      "[Train] Class 1: Precision: 0.6500, Recall: 0.6500\n",
      "[Train] Class 2: Precision: 0.5695, Recall: 0.5292\n",
      "[Train] Class 3: Precision: 0.6692, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.5897, Recall: 0.3833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.07 batch/s]\n",
      "[Val] Kappa: 0.8016 Accuracy: 0.6275 Precision: 0.6620 Recall: 0.6275\n",
      "\n",
      "Epoch 10/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-04, Loss=0.7699]\n",
      "[Train] Kappa: 0.8403 Accuracy: 0.7042 Precision: 0.6957 Recall: 0.7042 Loss: 0.7799\n",
      "[Train] Class 0: Precision: 0.8480, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.6892, Recall: 0.6375\n",
      "[Train] Class 2: Precision: 0.5588, Recall: 0.5542\n",
      "[Train] Class 3: Precision: 0.6739, Recall: 0.6458\n",
      "[Train] Class 4: Precision: 0.5686, Recall: 0.4833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.75 batch/s]\n",
      "[Val] Kappa: 0.7823 Accuracy: 0.6425 Precision: 0.6175 Recall: 0.6425\n",
      "\n",
      "Epoch 11/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.23 batch/s, lr=1.0e-05, Loss=0.5238]\n",
      "[Train] Kappa: 0.8658 Accuracy: 0.7525 Precision: 0.7446 Recall: 0.7525 Loss: 0.7023\n",
      "[Train] Class 0: Precision: 0.8673, Recall: 0.9806\n",
      "[Train] Class 1: Precision: 0.7391, Recall: 0.7083\n",
      "[Train] Class 2: Precision: 0.6210, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.7184, Recall: 0.7333\n",
      "[Train] Class 4: Precision: 0.6869, Recall: 0.5667\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.70 batch/s]\n",
      "[Val] Kappa: 0.7861 Accuracy: 0.6650 Precision: 0.6596 Recall: 0.6650\n",
      "\n",
      "Epoch 12/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-05, Loss=0.5411]\n",
      "[Train] Kappa: 0.8334 Accuracy: 0.7158 Precision: 0.7079 Recall: 0.7158 Loss: 0.7320\n",
      "[Train] Class 0: Precision: 0.8539, Recall: 0.9417\n",
      "[Train] Class 1: Precision: 0.6736, Recall: 0.6792\n",
      "[Train] Class 2: Precision: 0.5668, Recall: 0.5125\n",
      "[Train] Class 3: Precision: 0.6865, Recall: 0.7208\n",
      "[Train] Class 4: Precision: 0.6630, Recall: 0.5083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.25 batch/s]\n",
      "[Val] Kappa: 0.7858 Accuracy: 0.6725 Precision: 0.6672 Recall: 0.6725\n",
      "\n",
      "Epoch 13/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.24 batch/s, lr=1.0e-05, Loss=1.2556]\n",
      "[Train] Kappa: 0.8688 Accuracy: 0.7500 Precision: 0.7443 Recall: 0.7500 Loss: 0.6846\n",
      "[Train] Class 0: Precision: 0.8843, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7131, Recall: 0.7458\n",
      "[Train] Class 2: Precision: 0.6335, Recall: 0.5833\n",
      "[Train] Class 3: Precision: 0.7004, Recall: 0.7208\n",
      "[Train] Class 4: Precision: 0.6957, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.99 batch/s]\n",
      "[Val] Kappa: 0.8027 Accuracy: 0.6625 Precision: 0.6475 Recall: 0.6625\n",
      "\n",
      "Epoch 14/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.18 batch/s, lr=1.0e-05, Loss=1.0375]\n",
      "[Train] Kappa: 0.8697 Accuracy: 0.7667 Precision: 0.7589 Recall: 0.7667 Loss: 0.6617\n",
      "[Train] Class 0: Precision: 0.8716, Recall: 0.9806\n",
      "[Train] Class 1: Precision: 0.7458, Recall: 0.7458\n",
      "[Train] Class 2: Precision: 0.6524, Recall: 0.5708\n",
      "[Train] Class 3: Precision: 0.7407, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.6961, Recall: 0.5917\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.87 batch/s]\n",
      "[Val] Kappa: 0.8179 Accuracy: 0.6700 Precision: 0.6563 Recall: 0.6700\n",
      "\n",
      "Epoch 15/25\n",
      "Training: 100%|██████████| 50/50 [00:23<00:00,  2.17 batch/s, lr=1.0e-05, Loss=0.7447]\n",
      "[Train] Kappa: 0.8707 Accuracy: 0.7442 Precision: 0.7373 Recall: 0.7442 Loss: 0.6713\n",
      "[Train] Class 0: Precision: 0.8660, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7403, Recall: 0.7125\n",
      "[Train] Class 2: Precision: 0.5882, Recall: 0.5417\n",
      "[Train] Class 3: Precision: 0.6980, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.7222, Recall: 0.5417\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.00 batch/s]\n",
      "[Val] Kappa: 0.8131 Accuracy: 0.6725 Precision: 0.6572 Recall: 0.6725\n",
      "\n",
      "Epoch 16/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-05, Loss=1.1695]\n",
      "[Train] Kappa: 0.8826 Accuracy: 0.7592 Precision: 0.7531 Recall: 0.7592 Loss: 0.6451\n",
      "[Train] Class 0: Precision: 0.8779, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.7108, Recall: 0.7375\n",
      "[Train] Class 2: Precision: 0.6620, Recall: 0.5958\n",
      "[Train] Class 3: Precision: 0.7306, Recall: 0.7458\n",
      "[Train] Class 4: Precision: 0.6907, Recall: 0.5583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.07 batch/s]\n",
      "[Val] Kappa: 0.8168 Accuracy: 0.6775 Precision: 0.6657 Recall: 0.6775\n",
      "\n",
      "Epoch 17/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-05, Loss=0.8281]\n",
      "[Train] Kappa: 0.8572 Accuracy: 0.7350 Precision: 0.7286 Recall: 0.7350 Loss: 0.6621\n",
      "[Train] Class 0: Precision: 0.8699, Recall: 0.9472\n",
      "[Train] Class 1: Precision: 0.7026, Recall: 0.6792\n",
      "[Train] Class 2: Precision: 0.5887, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.7236, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.6465, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.02 batch/s]\n",
      "[Val] Kappa: 0.8022 Accuracy: 0.6700 Precision: 0.6506 Recall: 0.6700\n",
      "\n",
      "Epoch 18/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.20 batch/s, lr=1.0e-05, Loss=0.6185]\n",
      "[Train] Kappa: 0.8804 Accuracy: 0.7758 Precision: 0.7743 Recall: 0.7758 Loss: 0.6124\n",
      "[Train] Class 0: Precision: 0.8852, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.7953, Recall: 0.7125\n",
      "[Train] Class 2: Precision: 0.6260, Recall: 0.6625\n",
      "[Train] Class 3: Precision: 0.7541, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.7368, Recall: 0.5833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.05 batch/s]\n",
      "[Val] Kappa: 0.8046 Accuracy: 0.6725 Precision: 0.6530 Recall: 0.6725\n",
      "\n",
      "Epoch 19/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.22 batch/s, lr=1.0e-05, Loss=0.5925]\n",
      "[Train] Kappa: 0.8671 Accuracy: 0.7592 Precision: 0.7520 Recall: 0.7592 Loss: 0.6353\n",
      "[Train] Class 0: Precision: 0.8762, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.7401, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.6228, Recall: 0.5917\n",
      "[Train] Class 3: Precision: 0.7388, Recall: 0.7542\n",
      "[Train] Class 4: Precision: 0.6875, Recall: 0.5500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.08 batch/s]\n",
      "[Val] Kappa: 0.8048 Accuracy: 0.6775 Precision: 0.6622 Recall: 0.6775\n",
      "\n",
      "Epoch 20/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.21 batch/s, lr=1.0e-05, Loss=0.6752]\n",
      "[Train] Kappa: 0.8931 Accuracy: 0.7850 Precision: 0.7815 Recall: 0.7850 Loss: 0.6161\n",
      "[Train] Class 0: Precision: 0.8987, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7427, Recall: 0.7458\n",
      "[Train] Class 2: Precision: 0.6568, Recall: 0.6458\n",
      "[Train] Class 3: Precision: 0.7924, Recall: 0.7792\n",
      "[Train] Class 4: Precision: 0.7353, Recall: 0.6250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.05 batch/s]\n",
      "[Val] Kappa: 0.8049 Accuracy: 0.6675 Precision: 0.6505 Recall: 0.6675\n",
      "\n",
      "Epoch 21/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.25 batch/s, lr=1.0e-06, Loss=0.5124]\n",
      "[Train] Kappa: 0.8821 Accuracy: 0.7700 Precision: 0.7681 Recall: 0.7700 Loss: 0.6456\n",
      "[Train] Class 0: Precision: 0.8828, Recall: 0.9417\n",
      "[Train] Class 1: Precision: 0.7444, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6179, Recall: 0.6333\n",
      "[Train] Class 3: Precision: 0.7718, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.7642, Recall: 0.6750\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.98 batch/s]\n",
      "[Val] Kappa: 0.8152 Accuracy: 0.6700 Precision: 0.6553 Recall: 0.6700\n",
      "\n",
      "Epoch 22/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.20 batch/s, lr=1.0e-06, Loss=0.6087]\n",
      "[Train] Kappa: 0.8868 Accuracy: 0.7808 Precision: 0.7775 Recall: 0.7808 Loss: 0.5960\n",
      "[Train] Class 0: Precision: 0.8961, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.7675, Recall: 0.7292\n",
      "[Train] Class 2: Precision: 0.6667, Recall: 0.6583\n",
      "[Train] Class 3: Precision: 0.7712, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.6754, Recall: 0.6417\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.08 batch/s]\n",
      "[Val] Kappa: 0.8220 Accuracy: 0.6700 Precision: 0.6560 Recall: 0.6700\n",
      "\n",
      "Epoch 23/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.19 batch/s, lr=1.0e-06, Loss=0.5055]\n",
      "[Train] Kappa: 0.8958 Accuracy: 0.7692 Precision: 0.7646 Recall: 0.7692 Loss: 0.6032\n",
      "[Train] Class 0: Precision: 0.8995, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7479, Recall: 0.7292\n",
      "[Train] Class 2: Precision: 0.6250, Recall: 0.6042\n",
      "[Train] Class 3: Precision: 0.7362, Recall: 0.7208\n",
      "[Train] Class 4: Precision: 0.7297, Recall: 0.6750\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.96 batch/s]\n",
      "[Val] Kappa: 0.8084 Accuracy: 0.6600 Precision: 0.6453 Recall: 0.6600\n",
      "\n",
      "Epoch 24/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.22 batch/s, lr=1.0e-06, Loss=1.0955]\n",
      "[Train] Kappa: 0.8657 Accuracy: 0.7617 Precision: 0.7571 Recall: 0.7617 Loss: 0.6501\n",
      "[Train] Class 0: Precision: 0.8814, Recall: 0.9500\n",
      "[Train] Class 1: Precision: 0.7500, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.6413, Recall: 0.5958\n",
      "[Train] Class 3: Precision: 0.7388, Recall: 0.7542\n",
      "[Train] Class 4: Precision: 0.6667, Recall: 0.6667\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.77 batch/s]\n",
      "[Val] Kappa: 0.8050 Accuracy: 0.6675 Precision: 0.6571 Recall: 0.6675\n",
      "\n",
      "Epoch 25/25\n",
      "Training: 100%|██████████| 50/50 [00:22<00:00,  2.24 batch/s, lr=1.0e-06, Loss=0.8596]\n",
      "[Train] Kappa: 0.8835 Accuracy: 0.7725 Precision: 0.7684 Recall: 0.7725 Loss: 0.6106\n",
      "[Train] Class 0: Precision: 0.8969, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.7615, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6529, Recall: 0.6583\n",
      "[Train] Class 3: Precision: 0.7520, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.6604, Recall: 0.5833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.25 batch/s]\n",
      "[Val] Kappa: 0.8231 Accuracy: 0.6750 Precision: 0.6604 Recall: 0.6750\n",
      "[Val] Best kappa: 0.8231, Epoch 25\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/resnet34_pth/model.pth\"\n",
    "    state_dict = torch.load(state_dict_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # # Freeze all layers except the final fully connected (fc) layer\n",
    "    # for param in model.backbone.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # # Ensure only the `fc` layer is trainable\n",
    "    # for param in model.fc.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    #Train and evaluate the model with the training and validation set\n",
    "    model, tl, el = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path= '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/train_with_DeepDRiD/res34_APTOS_deepDRiD.pth'\n",
    "    )\n",
    "\n",
    "    # # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/train_with_DeepDRiD/res34_APTOS_deepDRiD.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # # Make predictions on testing set and save the prediction results\n",
    "    pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/train_with_DeepDRiD/predictions.csv\"\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAE8CAYAAABw2+D5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABYQklEQVR4nO3dd3xT1f/H8VeatukeQCeUMlqGjLIRQQTZKjJlKuDii6CiuEAEAecXFPl9AVFcuJgCooJsEGUXqOw9yugEundyfn9cGowUaEPa0PbzfDzyaHNzc+8nIfSde+655+iUUgohhBBCFImDvQsQQgghSiMJUCGEEMIKEqBCCCGEFSRAhRBCCCtIgAohhBBWkAAVQgghrCABKoQQQlhBAlQIIYSwggSoEEIIYQUJUCGEEMIKEqDirjZv3jx0Oh2RkZH2LqVQoqKiePzxxwkJCcFgMFChQgU6duzIN998g9FotHd5RbZ582Z0Op35ptfr8ff3p2/fvhw5cqTY9pv/7+7i4sLFixdveLxdu3bUr1/fqm3Pnz+fGTNm3LA8MzOTp59+mvr16+Pt7Y2HhwcRERH83//9H7m5ubfc5rPPPotOp+ORRx6xqiZROjnauwAhyoovv/ySESNGEBAQwBNPPEF4eDipqals2LCBp59+mpiYGN588017l2mVF198kebNm5Obm8v+/fv57LPP2Lx5MwcPHiQwMLDY9pudnc2HH37IzJkzbbbN+fPnc/DgQV566SWL5ZmZmRw6dIiHHnqIatWq4eDgwLZt23j55ZfZuXMn8+fPL3B7kZGRzJs3DxcXF5vVKEoHCVAhbGDHjh2MGDGCVq1asWrVKjw9Pc2PvfTSS0RGRnLw4EGb7Cs9PR13d3ebbKuw7r//fvr27Wu+X7t2bZ577jm+++47Xn/99WLbb6NGjfjiiy8YN24cwcHBxbYfgAoVKrBjxw6LZSNGjMDb25tZs2Yxffr0G74sKKV48cUXGTJkCBs2bCjW+sTdR5pwRZmwb98+unXrhpeXFx4eHnTo0OGGP4a5ublMnjyZ8PBwXFxcqFixIm3atGHdunXmdWJjY3nyySepUqUKBoOBoKAgevTowdmzZ2+5/8mTJ6PT6fjxxx8twjNfs2bNGDZsGHC9WXTz5s0W65w9exadTse8efPMy4YNG4aHhwenTp3ioYcewtPTk8GDB/P888/j4eFBRkbGDfsaOHAggYGBFk3Gv//+O/fffz/u7u54enry8MMPc+jQoVu+plu5//77ATh16pTF8osXL/LUU08REBCAwWCgXr16fP311zc8f+bMmdSrVw83Nzd8fX1p1qxZgUd4b775JkajkQ8//LBQdf3www80bdoUV1dXKlSowIABAzh//rz58Xbt2rFy5UrOnTtnbpauVq3aLbeZ/3hSUtINj33//fccPHiQ9957r1D1ibJFjkBFqXfo0CHuv/9+vLy8eP3113FycuLzzz+nXbt2/PHHH7Rs2RKASZMm8cEHH/DMM8/QokULUlJSiIyMZO/evXTq1AmAPn36cOjQIV544QWqVatGfHw869atIzo6+qZ/aDMyMtiwYQNt27alatWqNn99eXl5dOnShTZt2vDRRx/h5uZGtWrVmD17NitXruSxxx6zqOXXX39l2LBh6PV6QPsjP3ToULp06cJ///tfMjIymDNnDm3atGHfvn23DZCC5H+h8PX1NS+Li4vj3nvvRafT8fzzz+Pn58fvv//O008/TUpKirnJ9IsvvuDFF1+kb9++jB49mqysLPbv38/OnTsZNGiQxX6qV6/OkCFD+OKLLxg7duwtj0Lfe+89JkyYQL9+/XjmmWdISEhg5syZtG3bln379uHj48P48eNJTk7mwoULfPLJJwB4eHhYbCcnJ4eUlBQyMzOJjIzko48+IjQ0lLCwMIv1UlNTeeONN3jzzTeLtRlb3MWUEHexb775RgFq9+7dN12nZ8+eytnZWZ06dcq87NKlS8rT01O1bdvWvCwiIkI9/PDDN93O1atXFaCmTZtWpBr//vtvBajRo0cXav1NmzYpQG3atMli+ZkzZxSgvvnmG/OyoUOHKkCNHTvWYl2TyaQqV66s+vTpY7F88eLFClBbtmxRSimVmpqqfHx81LPPPmuxXmxsrPL29r5h+c1q/frrr1VCQoK6dOmSWr16tQoLC1M6nU7t2rXLvO7TTz+tgoKCVGJiosU2BgwYoLy9vVVGRoZSSqkePXqoevXq3XK///x3P3XqlHJ0dFQvvvii+fEHHnjAYhtnz55Ver1evffeexbbOXDggHJ0dLRY/vDDD6vQ0NCb7nvBggUKMN+aNWum9u/ff8N6r776qqpevbrKyspSSikVGhp6y8+XKHukCVeUakajkbVr19KzZ09q1KhhXh4UFMSgQYP466+/SElJAcDHx4dDhw5x4sSJArfl6uqKs7Mzmzdv5urVq4WuIX/7BTXd2spzzz1ncV+n0/HYY4+xatUq0tLSzMsXLVpE5cqVadOmDQDr1q0jKSmJgQMHkpiYaL7p9XpatmzJpk2bCrX/p556Cj8/P4KDg+natSvJycl8//33NG/eHNDOBS5dupTu3bujlLLYV5cuXUhOTmbv3r2A9u9w4cIFdu/eXah916hRgyeeeIK5c+cSExNT4DrLli3DZDLRr18/i30HBgYSHh5e6NcJ0L59e9atW8eSJUsYMWIETk5OpKenW6xz/Phx/u///o9p06ZhMBgKvW1RtkiAilItISGBjIwMateufcNjdevWxWQymc+BTZkyhaSkJGrVqkWDBg147bXX2L9/v3l9g8HAf//7X37//XcCAgJo27YtU6dOJTY29pY1eHl5AVqTXnFwdHSkSpUqNyzv378/mZmZ/PLLLwCkpaWxatUqHnvsMXQ6HYD5y8KDDz6In5+fxW3t2rXEx8cXqoaJEyeybt06li9fzpAhQ0hOTsbB4fqfj4SEBJKSkpg7d+4N+3nyyScBzPt644038PDwoEWLFoSHhzNq1Ci2bt16y/2/9dZb5OXl3fRc6IkTJ1BKER4efsP+jxw5UujXCRAQEEDHjh3p27cvc+bM4ZFHHqFTp04Wn4PRo0dz33330adPn0JvV5Q9cg5UlBtt27bl1KlTrFixgrVr1/Lll1/yySef8Nlnn/HMM88AWo/Z7t278/PPP7NmzRomTJjABx98wMaNG2ncuHGB2w0LC8PR0ZEDBw4Uqo78cPu3m10najAYLMIq37333ku1atVYvHgxgwYN4tdffyUzM5P+/fub1zGZTIB2HrSg83SOjoX7E9CgQQM6duwIQM+ePcnIyODZZ5+lTZs2hISEmPfz+OOPM3To0AK30bBhQ0D7YnPs2DF+++03Vq9ezdKlS/n000+ZOHEikydPLvC5NWrU4PHHH2fu3LmMHTv2hsdNJhM6nY7ff//dfO73n/59nrMo+vbty/jx41mxYgX/+c9/2LhxI6tXr2bZsmUWncvy8vLIzMzk7NmzVKhQwfzFSpRhdm5CFuKWbncONC8vT7m5ual+/frd8NiIESOUg4ODSk5OLvC5qampqnHjxqpy5co33f/x48eVm5ubGjx48C3r7Ny5s3J0dFTR0dG3XE+p6+dMly9fbrF8w4YNBZ4DdXd3v+m2Xn/9dWUwGFRycrLq0aOHqlatmsXj+edE16xZc9u6CpJ/DnTJkiUWy0+ePKn0er36z3/+o5TS/h08PT3VwIEDi7yP7Oxs9fDDDyu9Xq8yMzOVUgX/u588eVI5Ojqq0aNH33AOdOrUqQpQx44du+3+HnnkkVueA/23qKgoBaj//ve/FrXd6vbJJ58Uevui9JImXFGq6fV6OnfuzIoVKyyOBuLi4pg/fz5t2rQxHwlcvnzZ4rkeHh6EhYWRnZ0NaD1Ys7KyLNapWbMmnp6e5nVu5u2330YpxRNPPGFxTjLfnj17+PbbbwEIDQ1Fr9ezZcsWi3U+/fTTwr3of+jfvz/Z2dl8++23rF69mn79+lk83qVLF7y8vHj//fcLHE0nISGhyPsE7X3p06cP8+bNIzY2Fr1eT58+fVi6dGmB17v+cz///ndwdnbmnnvuQSl1yxF/atasyeOPP87nn39+Q7N679690ev1TJ48GaWUxWNKKYt9uru7k5ycfMP2ExMTb3guaANkgHYpEmjN4cuXL7/h5ufnR7NmzVi+fDndu3e/6esQZYc04YpS4euvv2b16tU3LB89ejTvvvsu69ato02bNowcORJHR0c+//xzsrOzmTp1qnnde+65h3bt2tG0aVMqVKhAZGQkP/30E88//zygdQzp0KED/fr145577sHR0ZHly5cTFxfHgAEDblnffffdx+zZsxk5ciR16tSxGIlo8+bN/PLLL7z77rsAeHt789hjjzFz5kx0Oh01a9bkt99+K9J5unxNmjQhLCyM8ePHk52dbdF8C9r52Tlz5vDEE0/QpEkTBgwYgJ+fH9HR0axcuZLWrVsza9asIu8X4LXXXmPx4sXMmDGDDz/8kA8//JBNmzbRsmVLnn32We655x6uXLnC3r17Wb9+PVeuXAGgc+fOBAYG0rp1awICAjhy5AizZs3i4Ycfvm1HrPHjx/P9999z7Ngx6tWrZ15es2ZN3n33XcaNG8fZs2fp2bMnnp6enDlzhuXLlzN8+HBeffVVAJo2bcqiRYsYM2YMzZs3x8PDg+7du/PDDz/w2WefmTukpaamsmbNGtatW0f37t158MEHAahatWqBlyu99NJLBAQE0LNnT6veT1EK2fX4V4jbuF1z2fnz55VSSu3du1d16dJFeXh4KDc3N9W+fXu1bds2i229++67qkWLFsrHx0e5urqqOnXqqPfee0/l5OQopZRKTExUo0aNUnXq1FHu7u7K29tbtWzZUi1evLjQ9e7Zs0cNGjRIBQcHKycnJ+Xr66s6dOigvv32W2U0Gs3rJSQkqD59+ig3Nzfl6+ur/vOf/6iDBw8WuQlXKaXGjx+vABUWFnbTdTZt2qS6dOmivL29lYuLi6pZs6YaNmyYioyMvOW2b9aEm69du3bKy8tLJSUlKaWUiouLU6NGjVIhISHKyclJBQYGqg4dOqi5c+ean/P555+rtm3bqooVKyqDwaBq1qypXnvtNYum9ls13edf2lPQpTBLly5Vbdq0Ue7u7srd3V3VqVNHjRo1yqJpNy0tTQ0aNEj5+PgowNycu3v3bvXYY4+pqlWrKoPBoNzd3VWTJk3U9OnTVW5u7i3fJ6XkMpbySKdUAW0WQgghhLglOQcqhBBCWEECVAghhLCCBKgQQghhBQlQIYQQwgoSoEIIIYQVJECFEEIIK5S7gRRMJhOXLl3C09PzpmOSCiGEKPuUUqSmphIcHFzgeNO3U+4C9NKlS4SEhNi7DCGEEHeJ8+fPFzjj0e2UuwDNHyrs/PnzMluCEEKUYykpKYSEhFg9l2+5C9D8ZlsvLy8JUCGEEFafzpNOREIIIYQVJECFEEIIK0iACiGEEFYod+dAhRDiVoxG4y0n9halh16vx9HRsdguWZQAFUKIa9LS0rhw4QIyy2PZ4ebmRlBQEM7OzjbftgSoEEKgHXleuHABNzc3/Pz8ZKCVUk4pRU5ODgkJCZw5c4bw8HCrBku4FQlQKxyLTeXN5Qdw0MGSEffZuxwhhA3k5uailMLPzw9XV1d7lyNswNXVFScnJ86dO0dOTg4uLi423b4EqBXcDXr2nLuKk15HntGEo176YglRVsiRZ9li66NOi20X25bLsGBvV9yc9eQaFeeuZNi7HCGEEHYgAWoFBwcdYf4eAJyIS7NzNUIIIexBAtRKYX5agJ6MT7VzJUIIYVvVqlVjxowZ9i7jrmfXAN2yZQvdu3cnODgYnU7Hzz//XOjnbt26FUdHRxo1alRs9d1KWMC1I9B4OQIVQtiHTqe75W3SpElWbXf37t0MHz78jmpr164dL7300h1t425n105E6enpRERE8NRTT9G7d+9CPy8pKYkhQ4bQoUMH4uLiirHCmwv310bvPykBKoSwk5iYGPPvixYtYuLEiRw7dsy8zMPDw/y7Ugqj0Yij4+3/7Pv5+dm20DLKrkeg3bp1491336VXr15Fet6IESMYNGgQrVq1KqbKbi/cP78JNw2jSS66FqKsUUqRkZNnl1thB3IIDAw037y9vdHpdOb7R48exdPTk99//52mTZtiMBj466+/OHXqFD169CAgIAAPDw+aN2/O+vXrLbb77yZcnU7Hl19+Sa9evXBzcyM8PJxffvnljt7fpUuXUq9ePQwGA9WqVePjjz+2ePzTTz8lPDwcFxcXAgIC6Nu3r/mxn376iQYNGuDq6krFihXp2LEj6enpd1SPNUrdZSzffPMNp0+f5ocffuDdd9+97frZ2dlkZ2eb76ekpNikjpAKbjg7OpCdZ+Li1UyqVnSzyXaFEHeHzFwj90xcY5d9H57SBTdn2/x5Hjt2LB999BE1atTA19eX8+fP89BDD/Hee+9hMBj47rvv6N69O8eOHaNq1ao33c7kyZOZOnUq06ZNY+bMmQwePJhz585RoUKFIte0Z88e+vXrx6RJk+jfvz/btm1j5MiRVKxYkWHDhhEZGcmLL77I999/z3333ceVK1f4888/Ae2oe+DAgUydOpVevXqRmprKn3/+aZfRo0pVgJ44cYKxY8fy559/FqoZAuCDDz5g8uTJNq9F76Cjpp8HR2JSOBGfKgEqhLgrTZkyhU6dOpnvV6hQgYiICPP9d955h+XLl/PLL7/w/PPP33Q7w4YNY+DAgQC8//77/O9//2PXrl107dq1yDVNnz6dDh06MGHCBABq1arF4cOHmTZtGsOGDSM6Ohp3d3ceeeQRPD09CQ0NpXHjxoAWoHl5efTu3ZvQ0FAAGjRoUOQabKHUBKjRaGTQoEFMnjyZWrVqFfp548aNY8yYMeb7+TOQ20K4f36AptGhboBNtimEuDu4Ouk5PKWL3fZtK82aNbO4n5aWxqRJk1i5cqU5jDIzM4mOjr7ldho2bGj+3d3dHS8vL+Lj462q6ciRI/To0cNiWevWrZkxYwZGo5FOnToRGhpKjRo16Nq1K127djU3H0dERNChQwcaNGhAly5d6Ny5M3379sXX19eqWu5EqQnQ1NRUIiMj2bdvn/lbkslkQimFo6Mja9eu5cEHH7zheQaDAYPBUCw1ybWgQpRdOp3OZs2o9uTu7m5x/9VXX2XdunV89NFHhIWF4erqSt++fcnJybnldpycnCzu63Q6TCaTzesF8PT0ZO/evWzevJm1a9cyceJEJk2axO7du/Hx8WHdunVs27aNtWvXMnPmTMaPH8/OnTupXr16sdRzM6XmOlAvLy8OHDhAVFSU+TZixAhq165NVFQULVu2LPGazB2JEiRAhRClw9atWxk2bBi9evWiQYMGBAYGcvbs2RKtoW7dumzduvWGumrVqoVerx19Ozo60rFjR6ZOncr+/fs5e/YsGzduBLTwbt26NZMnT2bfvn04OzuzfPnyEn0NYOcj0LS0NE6ePGm+f+bMGaKioqhQoQJVq1Zl3LhxXLx4ke+++w4HBwfq169v8Xx/f39cXFxuWF5Swq9dC3oyLhWllIyhKYS464WHh7Ns2TK6d++OTqdjwoQJxXYkmZCQQFRUlMWyoKAgXnnlFZo3b84777xD//792b59O7NmzeLTTz8F4LfffuP06dO0bdsWX19fVq1ahclkonbt2uzcuZMNGzbQuXNn/P392blzJwkJCdStW7dYXsOt2DVAIyMjad++vfl+/rnKoUOHMm/ePGJiYm7bLm9PoRXdcXTQkZ5jJCY5i2AfmcFBCHF3mz59Ok899RT33XcflSpV4o033rDZ1Qn/Nn/+fObPn2+x7J133uGtt95i8eLFTJw4kXfeeYegoCCmTJnCsGHDAPDx8WHZsmVMmjSJrKwswsPDWbBgAfXq1ePIkSNs2bKFGTNmkJKSQmhoKB9//DHdunUrltdwKzpVzmaOTUlJwdvbm+TkZLy8vO54e52m/8GJ+DS+faoFD9SSi4+FKK2ysrI4c+YM1atXt/m0V8J+bvXveqd5UGrOgd6t8ptxT8TJmLhCCFGeSIDeoeuDyktHIiGEKE8kQO9QWIA2Jq4MKi+EEOWLBOgd+ueYuOXsdLIQQpRrEqB3qHoldxx0kJyZS0Ja9u2fIIQQokyQAL1DLk56QitqI32clBGJhBCi3JAAtQHzkH5yHlQIIcoNCVAbuB6gcimLEEKUFxKgNhAug8oLIUS5IwFqA+H+2qUsp2RQeSFEGXT27Fl0Ot0N49qWdxKgNlDTX+tElJiWw5X0W08JJIQQtjRs2DB0Ot0NN2smur4T7dq146WXXirRfdpb6Z/s7i7g5uxIFV9XLlzN5GR8Gi2qV7B3SUKIcqRr16588803FsuKax5kcZ0cgdpIuHQkEqJsUQpy0u1zK+KgLAaDgcDAQIubr68vAIMGDaJ///4W6+fm5lKpUiW+++47AFavXk2bNm3w8fGhYsWKPPLII5w6dco27+M1S5cupV69ehgMBqpVq8bHH39s8finn35KeHg4Li4uBAQE0LdvX/NjP/30Ew0aNMDV1ZWKFSvSsWNH0tPTbVqfNeQI1EbC/D3YdCxBOhIJUVbkZsD7wfbZ95uXwNndJpsaPHgwjz32GGlpaXh4aF/016xZQ0ZGBr169QIgPT2dMWPG0LBhQ9LS0pg4cSK9evUiKioKB4c7P87as2cP/fr1Y9KkSfTv359t27YxcuRIKlasyLBhw4iMjOTFF1/k+++/57777uPKlSv8+eefAMTExDBw4ECmTp1Kr169SE1N5c8//7wrRn6TALWR/I5EMqi8EKKk/fbbb+ZwzPfmm2/y5ptv0qVLF9zd3Vm+fDlPPPEEoM3T+eijj+Lpqf3d6tOnj8Vzv/76a/z8/Dh8+DD169e/4/qmT59Ohw4dmDBhAgC1atXi8OHDTJs2jWHDhhEdHY27uzuPPPIInp6ehIaG0rhxY0AL0Ly8PHr37k1oaCgADRo0uOOabEEC1EbCAqQJV4gyxclNOxK0176LoH379syZM8diWYUKWl8MR0dH+vXrx48//sgTTzxBeno6K1asYOHCheZ1T5w4wcSJE9m5cyeJiYmYTCYAoqOjbRKgR44coUePHhbLWrduzYwZMzAajXTq1InQ0FBq1KhB165d6dq1K7169cLNzY2IiAg6dOhAgwYN6NKlC507d6Zv377mJmp7kgC1kfzBFOJSsknJysXLxcnOFQkh7ohOZ7Nm1OLm7u5OWFjYTR8fPHgwDzzwAPHx8axbtw5XV1eLXrrdu3cnNDSUL774guDgYEwmE/Xr1ycnp2SuKvD09GTv3r1s3ryZtWvXMnHiRCZNmsTu3bvx8fFh3bp1bNu2jbVr1zJz5kzGjx/Pzp07qV69eonUdzPSichGvFycCPTSZjuXZlwhxN3kvvvuIyQkhEWLFvHjjz/y2GOP4eSkfcm/fPkyx44d46233qJDhw7UrVuXq1ev2nT/devWZevWrRbLtm7dSq1atdDr9YB2pNyxY0emTp3K/v37OXv2LBs3bgRAp9PRunVrJk+ezL59+3B2dmb58uU2rdEacgRqQ+EBHsSmZHEyLo0mVe3fvCCEKB+ys7OJjY21WObo6EilSpXM9wcNGsRnn33G8ePH2bRpk3m5r68vFStWZO7cuQQFBREdHc3YsWOtqiMhIeGGwRaCgoJ45ZVXaN68Oe+88w79+/dn+/btzJo1i08//RTQzuGePn2atm3b4uvry6pVqzCZTNSuXZudO3eyYcMGOnfujL+/Pzt37iQhIYG6detaVaNNqXImOTlZASo5Odnm2570y0EV+sZv6t3fDtl820KI4pWZmakOHz6sMjMz7V1KkQwdOlQBN9xq165tsd7hw4cVoEJDQ5XJZLJ4bN26dapu3brKYDCohg0bqs2bNytALV++XCml1JkzZxSg9u3bd9M6HnjggQLreOedd5RSSv3000/qnnvuUU5OTqpq1apq2rRp5uf++eef6oEHHlC+vr7K1dVVNWzYUC1atMhcd5cuXZSfn58yGAyqVq1aaubMmYV+f27173qneaBT6i7oC1yCUlJS8Pb2Jjk5GS8vL5tu+8ed5xi//CDtavsx78kWNt22EKJ4ZWVlcebMGapXr46Li4u9yxE2cqt/1zvNAzkHakP5l7LItaBCCFH2SYDaUP5oRBeTMsnIybNzNUIIIYqTBKgN+bo7U8nDGYBT8fYfZkoIIUTxkQC1MZlcWwghygcJUBsznweVa0GFKJXKWb/KMq84/z0lQG3MfAQqHYmEKFXyL+gvqdF3RMnIyMgAMA8cYUsykIKN5XckOilNuEKUKo6Ojri5uZGQkICTk5NNZiER9qOUIiMjg/j4eHx8fMxfkGxJAtTG8geVj76SQVauERcn2/+jCSFsT6fTERQUxJkzZzh37py9yxE24uPjQ2BgYLFsWwLUxvw8DHi7OpGcmcuZxHTqBtl2sAYhRPFxdnYmPDxcmnHLCCcnp2I58swnAWpjOp2OcH8PIs9d5UR8mgSoEKWMg4ODjEQkCkUa+YtB+LVm3JNxch5UCCHKKgnQYlDTL/9aUOmJK4QQZZUEaDEID5BrQYUQoqyTAC0G+ZeynE1MJ9dosnM1QgghioMEqDVMRji5AfYvLvDhIG8X3J315JkU5y7LmLhCCFEWSYBa49RG+KE3rB4HxtwbHtbpdIQFyNRmQghRlkmAWqNGO3D3g4xEOLm+wFXC/aUjkRBClGUSoNbQO0GDftrvUfMLXCVMAlQIIco0uwboli1b6N69O8HBweh0On7++edbrr9s2TI6deqEn58fXl5etGrVijVr1pRMsf/WaKD28/hqyLhyw8PmI1C5FlQIIcokuwZoeno6ERERzJ49u1Drb9myhU6dOrFq1Sr27NlD+/bt6d69O/v27SvmSgsQ2EC7GXPg4NIbHs6f1ux0Yjp50hNXCCHKHLsO5detWze6detW6PVnzJhhcf/9999nxYoV/PrrrzRu3NjG1RVCxCCIHac147Z41uKhyr6uuDg5kJVr4vzVTKpXci/5+oQQQhSbUn0O1GQykZqaSoUKFW66TnZ2NikpKRY3m2nwGDg4wqW9kHDM4iG9g848ItFJOQ8qhBBlTqkO0I8++oi0tDT69et303U++OADvL29zbeQkBDbFeDhB2GdtN8L6Ex0vSeunAcVQoiyptQG6Pz585k8eTKLFy/G39//puuNGzeO5ORk8+38+fO2LSS/M9H+RdoAC/+Q3xP3pFwLKoQQZU6pnM5s4cKFPPPMMyxZsoSOHTvecl2DwYDBYCi+Ymp1BRcfSI2B05shrIP5oTB/GRNXCCHKqlJ3BLpgwQKefPJJFixYwMMPP2zvcsDRoJ0LBfh7gcVD5mnN4tMwmVRJVyaEEKIY2TVA09LSiIqKIioqCoAzZ84QFRVFdHQ0oDW/DhkyxLz+/PnzGTJkCB9//DEtW7YkNjaW2NhYkpOT7VH+dfnNuEd+hazrtYRWcMNJryMz18jFpEw7FSeEEKI42DVAIyMjady4sfkSlDFjxtC4cWMmTpwIQExMjDlMAebOnUteXh6jRo0iKCjIfBs9erRd6jcLbgKVakNeFhz62bzYUe9AjUrXjkITpBlXCCHKErueA23Xrh1K3bxpc968eRb3N2/eXLwFWUun045C10/SmnGbDjU/FBbgwbG4VE7GpdG+9s07OwkhhChdSt050LtWw/6gc4Do7XDltHmxXMoihBBlkwSorXgFa7O0APy90LxYBpUXQoiySQLUlhoN1n7+vQBM2vi3+WPinoxLu2VztRBCiNJFAtSW6jwMBi9IioZzWwGoVskNvYOO1Ow84lKy7VygEEIIW5EAtSUnV6jXU/v92jWhBkc9oRXdABkTVwghyhIJUFuLGKT9PLwCctIB6UgkhBBlkQSorVW9F3yrQ06aNrAC18+DSkciIYQoOyRAbU2ng4hrIxNdm6FFBpUXQoiyRwK0OEQM0H6e2QJJ580Bejw+VXriCiFEGSEBWhx8Q6Ha/YCC/Qup6eeBTgdJGblcTs+xd3VCCCFsQAK0uJibcRfg6uRAiK/WE/eENOMKIUSZIAFaXO55FJzc4MopuLDb3BNXBpUXQoiyQQK0uBg8oe6j2u9R8wnLnxs0Ti5lEUKIskACtDjlzxN6aBm1KjgBcimLEEKUFRKgxalaW/CqAlnJNM3aAUiACiFEWSEBWpwcHMyXtFQ5txyAhNRskjKkJ64QQpR2EqDF7VpvXMczG2nglQHImLhCCFEWSIAWt0phUKUFKBOD3HYBEqBCCFEWSICWhGudiTpkrweUnAcVQogyQAK0JNTrDXoD/pmnqac7KwEqhBBlgARoSXD10SbbBvrqt8i1oEIIUQZIgJaURto8oY/qt5GQnEZqVq6dCxJCCHEnJEBLSo324BFARV0q7R32cSoh3d4VCSGEuAMSoCVF7wgN+wHQR/8nJ6QZVwghSjUJ0JIUoTXjtnfYx85DJ8gzmuxckBBCCGtJgJakgHtI9a2Hs85IsxP/x8ivN8uoREIIUUpJgJYwz7ajABjguJn/XniC+Z+8yrHzcXauSgghRFFJgJa0RoOg3/dk+4Tjq0tjZO63+H7ZkkM/T4c8ORoVQojSQgK0pOl0cM+jGF7cSXq3mSToA/DXXaVe1GSSpkVgiloAJqO9qxRCCHEbVgXo+fPnuXDhgvn+rl27eOmll5g7d67NCivzHPS4txyC7+t/syrkFRKUNz7Zl3D4eQTGT++DI7+BUvauUgghxE1YFaCDBg1i06ZNAMTGxtKpUyd27drF+PHjmTJlik0LLOscDa489PREtj60no+MA0lWbugTj8KiwfDFg3BqkwSpEELchawK0IMHD9KiRQsAFi9eTP369dm2bRs//vgj8+bNs2V95UbPlrXoNPxD+jh/zsy8nmQoA1zaC9/3hG+7w/nd9i5RCCHEP1gVoLm5uRgMBgDWr1/Po48+CkCdOnWIiYmxXXXlTESID/Nf7Mwflf9D2+wZfJ3XFaPOCc7+CV91hAUDIe6QvcsUQgiBlQFar149PvvsM/7880/WrVtH165dAbh06RIVK1a0aYHljb+nC/OfvZdOLRowJW8IbTM/YptXN5TOAY6tgs8fgOid9i5TCCHKPasC9L///S+ff/457dq1Y+DAgURERADwyy+/mJt2hfWcHR34oHcD3utVnzgHfwbFP8Fwz9lkhdwPplz4/TUwyShGQghhTzqlrOuhYjQaSUlJwdfX17zs7NmzuLm54e/vb7MCbS0lJQVvb2+Sk5Px8vKydzm3tfvsFZ77YQ+JaTnUcM1greNLOOamwaOzoMkT9i5PCCFKrTvNA6uOQDMzM8nOzjaH57lz55gxYwbHjh27q8OzNGperQK/PN+GBpW9OZ3pxn8ze2oPbJgMWSl2rU0IIcozqwK0R48efPfddwAkJSXRsmVLPv74Y3r27MmcOXNsWqCAYB9XloxoRZd6AczL60y0LhjSE2DLNHuXJoQQ5ZZVAbp3717uv/9+AH766ScCAgI4d+4c3333Hf/73/9sWqDQuDjpmfZYBBW9PJiYPVhbuGMOXD5l38KEEKKcsipAMzIy8PT0BGDt2rX07t0bBwcH7r33Xs6dO2fTAsV1Xi5OvN+7PptNjdlsitA6FK0Zb++yhBCiXLIqQMPCwvj55585f/48a9asoXPnzgDEx8cX6UTsli1b6N69O8HBweh0On7++efbPmfz5s00adIEg8FAWFhYuRu44cE6AfRuXJl3ch8nDz0c/x1ObrB3WUIIUe5YFaATJ07k1VdfpVq1arRo0YJWrVoB2tFo48aNC72d9PR0IiIimD17dqHWP3PmDA8//DDt27cnKiqKl156iWeeeYY1a9ZY8zJKrYnd7yHZvQbf5mlfXFjzJhhz7VuUEEKUM1ZfxhIbG0tMTAwRERE4OGg5vGvXLry8vKhTp07RC9HpWL58OT179rzpOm+88QYrV67k4MGD5mUDBgwgKSmJ1atXF2o/pe0ylptZfTCW13/4g02GV6ioS4VuU6Hlf+xdlhBClBp2uYwFIDAwkMaNG3Pp0iXzzCwtWrSwKjwLa/v27XTs2NFiWZcuXdi+fftNn5OdnU1KSorFrSzoWj+Q+xuGMz3vMQDUpvch44qdqxJCiPLDqgA1mUxMmTIFb29vQkNDCQ0NxcfHh3feeQdTMY6QExsbS0BAgMWygIAAUlJSyMzMLPA5H3zwAd7e3uZbSEhIsdVX0qY8Wo81hi4cMVVFl5UEm963d0lCCFFuWBWg48ePZ9asWXz44Yfs27ePffv28f777zNz5kwmTJhg6xrvyLhx40hOTjbfzp8/b++SbKaih4GJPRoyJU8bkUhFfiWDzQshRAlxtOZJ3377LV9++aV5FhaAhg0bUrlyZUaOHMl7771nswL/KTAwkLi4OItlcXFxeHl54erqWuBzDAaDeeaYsqh7wyB++/tBVp1Yx0P6XZh+H4vD0F9Ap7N3aUIIUaZZdQR65cqVAs911qlThytXiu88XKtWrdiwwfKSjXXr1pl7AZdHOp2Od3vWZ5Z+CNnKCYezW+DoSnuXJYQQZZ5VARoREcGsWbNuWD5r1iwaNmxY6O2kpaURFRVFVFQUoF2mEhUVRXR0NKA1vw4ZMsS8/ogRIzh9+jSvv/46R48e5dNPP2Xx4sW8/PLL1ryMMsPfy4Wnu7fnC+NDAOT+/ibkZdu5KiGEKNusasKdOnUqDz/8MOvXrzcf/W3fvp3z58+zatWqQm8nMjKS9u3bm++PGTMGgKFDhzJv3jxiYmLMYQpQvXp1Vq5cycsvv8z//d//UaVKFb788ku6dOlizcsoU3o3qcyIqKeJi/6DgJRzmLZ/isP95fuLhRBCFCerrwO9dOkSs2fP5ujRowDUrVuX4cOH8+677zJ37lybFmlLZeU60IJcSspk5ifv8oFuFjl6N5xf2geegfYuSwgh7kp3mgdWB2hB/v77b5o0aYLRaLTVJm2uLAcowIKdZ6m7sjeNHE6RWqcfngO+sHdJQghxV7LbQAri7jSgRSjLA14AwPPoYkzn91i/sdws+HshLB4Kp/+wUYVCCFE2SICWMTqdjmcG9meF0qabS1z6MhS1keHyKW2Wl+l1YPl/4PDPML8/RO+0fcFCCFFKSYCWQSEV3Mh5YALpyoB/0t9c3vHj7Z9kzIXDv8B3PWBmE9g+CzKvgncIVG4KeZkwvx/EHyn+FyCEEKVAkXrh9u7d+5aPJyUl3Uktwob6tGvBor0DGJj2Lbr1b6Oa9ERn8LhxxeSLsPdb2PsdpMZcW6iD8M7Q7CkI7wR5WVqwXtgN3/eGp9eCT9kZElEIIaxRpE5ETz75ZKHW++abb6wuqLiV9U5E/3Q2NhHHOfdSRZfAwbAR1H/8v9oDJhOc3gi7v9bmE1XXxi9294MmQ6DJUPANtdxYxhX4uiskHoNKteCpNeBWoWRfkBBC2NBd1Qu3NChPAQqwfulcOh54jSzlROrg3/CL3wF7voGrZ6+vVO1+aPYk1OkOjs4331jyBfiqM6RchMrNYOgv4Oxe7K9BCCGKgwRoEZW3ADUaTRz+8AEa5O63WJ6uc+dP985s8XqYRJfqODk64Kx3wEmvw0nvgJPeAYOj9tPVWc8jDYMIregO8Ufhm67a+dGwTjBwAeid7PTqhBDCehKgRVTeAhQg+vBOghZ1w0lnJMpUgx+NHfnV2IosCj/IvouTA692rs2Traujv7gbvn1U61jUsD/0/AwcpD+aEKJ0kQAtovIYoACxJ/YQm5RBkldtco2KnDwTuUYTOUbtZ26eSVt+7X7+47lGxaFLyew+exWApqG+TO3bkJpXt8GCAaCM0Op56FI8M/CUqPREiPkbfKqCb3XQWzXSpRCilJAALaLyGqB3QinFgl3neX/VEdKy8zA4OvBK51o847kThxXPaSt1mgKtR9u3UGtlJmmX7Wz/FHLTtWV6Z6hQE/xqgV8dreOUX22oGA5OLnYtVwhhGxKgRSQBar2LSZmMXbqfP08kAtAoxIcvw7ZRafu72go950CjQXassIhyMmDX5/DXDMhK0pZ5VYHMK5CbUfBzdA7gE6qFql8tqFT7WsCGg4t8noQoTSRAi0gC9M4opVgSeYF3fjtManYezo4OLKq+ksbnvwedXutUVOsunx0nL0e79nXLNEi7NkG7Xx148C2o84g2clPyeUg8DgnHIOHotd+PQlbyzbcb3Bi6fACh5Xd+WiFKEwnQIpIAtY2Y5EzGLTvA5mMJ6DDxlfc3PJi9ARxdYcgKqNrS3iXeyGSEA0tg0/uQdE5b5lMV2r0JDfuBg/7Wz1cK0uK1a2ETrt0Sj0HCcUiLvb5exECtSdvDv/heixDijkmAFpEEqO0opVi69yJTfj1ERlYWXzpPp51DFMrFB91Tq8G/rr1L1CgFR3+Dje9qR5EAHgHQ9jVt0IhbXftaWKlxsOk9bUQnFBi8oP2b0PxZ6YwkxF1KArSIJEBtLy4li/HLD7D1SDQ/Or9PE4eT5LoH4TR8PXhXsV9hSsHpTbBhClzapy1z8YE2L0GL/4Czm+33eWEPrHrl+v7868FD06Baa9vvS4jSymTU/o/EHtBOfQRFgE5X4mVIgBaRBGjxUEqxIuoSn/yygy+NEwh3uMgV12p4PLcBZ69KJV/Q+V1acJ79U7vv5A6tRmqX3Lj6FO++TUbtSHTDZG3ACYAG/aDzOzLBuSi/0hLg1AY4sQ5ObdQ66+XzDNLG367VFWo8UGIjnEmAFpEEaPGKT83i4yUbGX1uFMG6K5xwqEF8lS4EBIdQtWp1nL0DwN1fOz/oWPiBHG6gFGSnaOck0+Ku3a79HrNf+48K2uUozZ6G+8eU/DnJjCtaiO+ZByhw9oT246DF8PI5etPlU3DmD+2SoOAmxdMCIO4eJiNciIST6+HkOrgUBfwjbgzeENhAOxLNv3wMQG+A6m21zoi1umj9FIqJBGgRSYAWP6UUm/76kyYbBuJD2s3Xc/FG5+6vnY/08LserB7+2u/KZBmM5t9jtZ95WTcvQuegXVLzwFj7zxxzcS+sehUuXpvc3K8uPPwRVGtj37pKSm4m/PkxbP0/MOZoyxwcIbAhhLSEkBbaT+/K9q1T3Lm0eC0w848y8y8PyxfYEMI6arM8VWmufZHMy4azf8HxNdrkFknRls/xr3ctTLtClWa37+xXBBKgRSQBWnKSzh/hwuavSEu8SF5KHJ7Gq/jpkqhEMs46o212YvC6FroB134GgmeAdjlKpXDb7MMWTCbY9z2sn3S96ap+X+j8LngF2bW0YnVsNfz++vVez0GNtC9C5qnz/sGritZ7Oz9UAxqUrw5YuVnaKYdTG7UWln9+qXT3u/7zTlpubCW/BSg1DlIuaAF4cr02ktc/uXhDzQe1cbPDOtz+FIZSWu/246u1QD2/4/psUQCuFa419XbRtnuHp2MkQItIAtQ+lFKcu5zBjtOX2Xn6ModOncOYFo//tUD10yXj75BMuHsm1V3S8NOl4G5wwsEr8HowmoMy4Prvpa0ZMOOK1hs48mu0Zl0PeOANrcnKlKdNbG7KvfZ7nva7MdfysX/edzRA7W727axVkKvnYPVYOLZKu+9VGbp+CHW7a/eTz2vnqc/v1G6xB7VhIf/JyU2bzD3kWqhWbgruFYu3bqW0mYou7tGaH6+e1ZoZq7WGKi1s/3lLvwwn1mrv06mNkHPzFhszF+8CgtVfC1y3SuDkCo4u126Gf/101n7qnQvutGMyQUYipMZeb/XJ/93iZ7w2FnZBghppR5hhnbR/szv5EpRxBU5u0AL15DrL67AdHKH/j1C7q9WblwAtIgnQu4NSiugrGew8fYUdpy+z4/RlLiVbNslW9nHlmyebUyvA005VFqNLUVqz7oXdNtiYTgvgRoO0gLLnFHN52bBtJmz5SPsD6+AIrUZB29ehoAnd82WnaaGVH6oXdhU8aIVHoHZ5VEA98L8HAu7RBsFwcrWu3qxkrYn9QiRcjNR+ZiQWvK6DE1RuAqGttUANaQkGKz6bl09pgXnsd4jebnmE5RmkNVW6+midbtLjtbBKT9B+mnKtepkF+nfAGnO1ffz7i8ytGLy1Fp/ABtePMourr4ExT/ts5B+dJh6DV45r+7eSBGgRSYDenZRSXLiaeS1Mr7DlRAIJqdl4uzrx1dBmNKtWBifvNpng7/naUII5adofaL3jtZ9OWvjonW69PPkCRG+7vk1nD7inhzaYQ2jrkp0l59Qm7UvB5ZPa/dA28PDH4F+n6NsymbTRn87v0EI1egdcOVXwujoHbfD/gHu082X5PytUtzxfZsyD+MPXgnKP9uUl8TgWHVtAe1+DGmpz3vpWg0t74exWSL30r/3qIbgRhN6nvdaq9xbcpJjfmSY/NBOPWT4e0EBrRajzkHb0drPLOZTSzikWFKzp8dryjEStb0BedsE/C0UH7pWut/p4BmqtPf/+ae8WoOSLd3zeXAK0iCRAS4ekjByemrebvdFJGBwdmDWoCZ3usf6bZpl29Sz8vRD+XmA5UbpPVS1IIwZAhRrFt/+US7BmPBxapt1399dm52nwmG2v7ctO1eajjT8E8Ucg7pAWiBmXC17f0UWbAKBSbW0S+Ev7Ch7j2CdU69BSpZkWmoENbpwwIL9p99xWLUzP/XVjZxd015p722hfXnQ6LTSPr9GCLp+Do7ZO7Ye04CzGXqY3vAZjzs0DVueghaO7X7npJS4BWkQSoKVHZo6RFxbsZf2ReBx08H6vBgxoUUJ/bEojpbQmwaj5cOhnyEm9/ljVVlqY1uupnUOzBWMu7PwcNn+gHUHrHLRLdNq/abt93E7+8IrmUD187fejBZ+jM3hpzbCVm2mhWbmpdu7QGknn4dw2LUzPbr35ETJoTZ3hnbTADO9Ucu+PuCUJ0CKSAC1d8owmxi8/yKLI8wCM6VSLFx4MQ2eHUUtKlZwMOLpSayI+tQlzM6Wji9ZDudFAqNHe+ksCzm2Hla9oYQVaGD38sTaizN3AZNSOGOMPa706PQO10KxUq/iatVNitCPUc9u0n8Yc7bxgnYeg6n22GTJS2JQEaBFJgJY+SimmrzvOzI3aubXH763K5Efro3eQEC2UlEuwfxFELbjx/Jv+X70zHQ3XlhWwPL/3ZuZVbWxh0C4r6DQZGj1esudbhbABCdAikgAtvb7bfpa3fzmEUtC1XiAzBjTCxcl2F1WXeUppHWKi5sOBn268yL2omgyFjpPArQx28BLlggRoEUmAlm6rDsTw0sIocowmWlSvwBdDmuHtWj46PNiUMU8b0CEv+3pHEuM/fs/7V2cTc+eTLK15NPzaNX5ClGISoEUkAVr6bT91meHfRZKanUedQE/mPdmCQG+X2z9RCCH+4U7zQE5aiFKnVc2KLPpPK/w9DRyNTaXPnG2cjC/ECC5CCGFDEqCiVLon2Iulz91HjUruXEzK5LHPtrE3+qq9yxJClCMSoKLUCqngxpIRrYgI8eFqRi6DvtjBxqNx9i5LCFFOSICKUq2ih4EFz7akXW0/snJNPPvdHhZfu2ZUCCGKk3QiEmVCrtHE2KUHWLr3AgBVfF1x1jvg7OiAk94BJ70Op3/dd3bUaz/1+cscCPAy8Pi9obgbytE0WkKUU3eaB/JXQpQJTnoHPnqsIX6eBj774xQXrt5kqqVC+DnqEl8NbUawj5UzfAghygU5AhVlzvkrGSSmZZNrVOQaTeQYTeTkmcg1XrvlKXKu/Z6/PMeoyMkz8dOe8ySm5eDnaeDLIc2ICPGx98sRQhQTuQ60iCRAxa1cuJrB0/MiORaXiouTA9P7NeKhBkH2LksIUQzkOlAhbKiKrxs/PdfK3Clp5I97mb3pJOXse6YQohDsHqCzZ8+mWrVquLi40LJlS3bt2nXL9WfMmEHt2rVxdXUlJCSEl19+mayswk4UK8Ttebo48eWQZgy7rxoA09Yc45Ulf5OdZ7RvYUKIu4pdA3TRokWMGTOGt99+m7179xIREUGXLl2Ij48vcP358+czduxY3n77bY4cOcJXX33FokWLePPNN0u4clHWOeodmPRoPd7pUQ+9g45ley/y+Jc7uZKeY+/ShBB3CbueA23ZsiXNmzdn1qxZAJhMJkJCQnjhhRcYO3bsDes///zzHDlyhA0bNpiXvfLKK+zcuZO//vqrUPuUc6CiqP44nsDzP+4lNTuPqhXc+HpYM8L8Pe1dlhDiDpXac6A5OTns2bOHjh07Xi/GwYGOHTuyffv2Ap9z3333sWfPHnMz7+nTp1m1ahUPPfTQTfeTnZ1NSkqKxU2Ioniglh/LRt5HSAVXoq9k0OvTbfx5IsHeZQkh7MxuAZqYmIjRaCQgIMBieUBAALGxsQU+Z9CgQUyZMoU2bdrg5OREzZo1adeu3S2bcD/44AO8vb3Nt5CQEJu+DlE+hAd48vPI1jQL9SU1K49h3+zmhx3n7F2WEMKO7N6JqCg2b97M+++/z6effsrevXtZtmwZK1eu5J133rnpc8aNG0dycrL5dv68DPMmrFPRw8CPz7akV+PKGE2Kt34+yJRfD2M0SQ9dIcoju41EVKlSJfR6PXFxloN/x8XFERgYWOBzJkyYwBNPPMEzzzwDQIMGDUhPT2f48OGMHz8eB4cbvw8YDAYMBoPtX4AolwyOeqb3i6BGJXc+Xnecr7ee4ezldP43sDEeMvyfEOWK3Y5AnZ2dadq0qUWHIJPJxIYNG2jVqlWBz8nIyLghJPV6PYBcpydKjE6n44UO4cwa1BiDowMbj8bTd842LiZZP3ygEKL0sWsT7pgxY/jiiy/49ttvOXLkCM899xzp6ek8+eSTAAwZMoRx48aZ1+/evTtz5sxh4cKFnDlzhnXr1jFhwgS6d+9uDlIhSsojDYNZ9J9WVPK4NrH3p9tITMu2d1lCiBJi1zan/v37k5CQwMSJE4mNjaVRo0asXr3a3LEoOjra4ojzrbfeQqfT8dZbb3Hx4kX8/Pzo3r077733nr1egijnGoX4sOL51jzx5U5OJ6bz8qIo5j3ZAr2Dzt6lCSGKmYyFK4QNHI9LpcesrWTmGnmlUy1e6BBu75KEELdRaq8DFaIsqRXgyTs96wPwyfrjbD912c4VCSGKmwSoEDbSt2kV+jatgknBiwv3kZAq50OFKMskQIWwoSk96hHu70FCajYvL4qSa0SFKMMkQIWwITdnRz4d3ARXJz1/nUxk9qaT9i5JCFFMJECFsLHwAE/evXY+dMb642w7lWjnioQQxUECVIhi0KdpFR7LPx+6IIr4VJmzVoiyRgJUiGIypUd9agV4kJgm50OFKIskQIUoJq7OevP50K0nLzNz4wl7lySEsCEJUCGKUZi/J+/10s6H/t+GE2w7advzoXJUK4T9SIAKUcx6N6lC/2YhKAUvLrTN+dAdpy/T7/Pt3DNxNfO2npHJFISwAwlQIUrApEfrUTvAk8S0bF5aaP350D3nrjDoix0MmLuDXWeukJ1nYtKvh3lj6X6y84w2rloIcSsSoEKUAFdnPbMHN8HNWc+2U5f534ainQ+NOp/EkK930WfOdraduoyTXscT94byaudaOOhgceQFBs7dIb19hShBMpi8ECXo530XeWlRFDod/PB0S1qHVbrl+gcvJvPJuuNsOBoPgKODjseaVWFU+zCq+LoB8MfxBF6Yv5eUrDwCvVz4/ImmRIT4FPdLEaLUu9M8kAAVooSNXbqfhbvPU8nDwKrRbfD3dLlhnSMxKXyy7jhrD8cBoHfQ0btxZV54MJyqFd1uWP9MYjrPfhfJyfg0nB0d+G+fBvRqXKXYX4sQpZkEaBFJgAp7y8o10nP2Vo7GptKqRkV+eKalef7QE3GpzFh/gpUHYgDQ6aBno8q82CGc6pXcb7nd1KxcXl4Uxfoj2tHq8LY1eKNrHZmbVIibkAAtIglQcTc4lZBG95l/kZFj5MUO4fRoFMz/Npzgl78vkf8/8pGGQbzUMZwwf89Cb9dkUkxfd5xZ18bgbVvLj5kDGuPt5lQcL0OIUk0CtIgkQMXd4p/nQ3VAfsfcrvUCealTOHUCrf98/rb/Eq8t2U9mrpFqFd34cmizIgWxEOWBTKgtRCnVs3FlBrbQrg81KehY15/fXmjDZ080vaPwBHikYTA/PdeKyj6unL2cQc/Z21h/7XyqEMI25AhUCDvKzjOyfO9F6gZ5FUvP2ctp2Yz8cS87z1xBp4NXO9dmZLua6HRyXlQIacItIglQUd7kGk1M+fUw3+84B8DDDYOY1rchbs6Odq5MCPuSJlwhxC056R14p2d93u/VACe9jpX7Y+g7ZzsXrmbYuzQhSjUJUCHKiUEtqzL/2Xup5OHM4ZgUOk3fwqtL/mbPuSsylq4QVpAmXCHKmUtJmYz8cS9R55PMy8L9PejfPITeTapQwd3ZfsUJUYLkHGgRSYAKAUop9py7ysLd5/lt/yWyck0AOOsd6FwvgIEtqtKqRkUcZBAGUYZJgBaRBKgQllKycvkl6hILd0dz8GKKeXnVCm70bx7CY02r4O9143CDt2M0KaKvZHAiLpUT8WmcjE8jKSOHRxoG0z0iGGdHOYMk7EsCtIgkQIW4uYMXk1m4O5oV+y6Rmp0HaOPwtq/tz8AWITxQyw9HvWXw5RpNnLucwcn4VE7EpXEiPo3jcamcTkwnJ89U4H78PQ0Mva8ag1tWxcdNmoyFfUiAFpEEqBC3l5GTx6oDsSzcFU3kuavm5YFeLvRpWhknvQMn4tM4EZfKmcR0co0F/xlxcXIgzN+DcH9Pwvw9MJoUP+48R1xKNgCuTnr6NavCU22qE1rx1mP9WiP6cgY7Tl+mWTVfavh52Hz7onSTAC0iCVAhiuZkfCoLd51n6d4LXM3ILXAdN2c94f4ehPl7Eh7gQfi10Kzi63rDedScPBO/7b/EF3+e4UiM1mSs00GXewJ55v7qNA31tXqgh5w8E7vPXmHj0Xg2HYvndEI6AO7OemYNakL7Ov5WbVeUTRKgRSQBKoR1svOMrDscx+8HYnE36LWjymthGex9Y1DejlKKbacu88Wfp9l8LMG8vFGID8/eX4Mu9QJuaC4uSGxyFpuPaYH514lE0nOM5sccHXQEeLlwMSkTBx283b0eQ++rVqQ6RdklAVpEEqBC3H1OxKXy1V9nWLbvovm8aRVfV55sXZ3+zUPwMFwfNcloUuyLvsqmY/FsOprA4ZgUi21V8jDQvrYf7ev40ya8Eq5Oet5afpBFkecBGHZfNSY8co9M82ZnSRk5bD6WQLvafnY7Dy4BWkQSoELcvRJSs/l+xzl+2HGOK+k5AHi6ODKoRVVqB3qy+VgCW04kkPSPpmSdDiKq+PBgHX/a1/anXrDXDUfDSik+33KaD38/CsCDdfz538DGFsFc2mXmGDkSm0JEFZ+7/svB4UspDP8+kgtXM/H3NPBhnwY8WCegxOuQAC0iCVAh7n5ZuUaW7r3AV3+e4XRi+g2Pe7k48kBtf9rX9uOBWn5U9DAUaru/H4jhpUVRZOeZqBPoydfDmhPs42rr8ktUVq6R+TujmfPHKRJSs2lX24+ZAxvj6XJ3zgH7z6n2HHTXp/Hr3yyEtx6pW6J1S4AWkQSoEKWHyaTYdCyeedvOkpyZS5uwSrSv40/jEJ9CnR8tSNT5JJ75NpLEtGz8PA18NbQZDav42LbwEpCVa2Thrmg+3XyK+NRsi8dqB3jy1bBmVPF1s1N1NzKaFB+tPcaczacAuD+8EtP6RvDFn6f5eusZlILKPq5M69uQ+8IqlUhNEqBFJAEqhLiYlMnT83ZzNDYVFycHZvRvTNf6gTbZ9vG4VJZEnic1K48H6/jTtpYfLk56m2wbtM5ciyMvMHvjSWJTsgAteEa1D6N2oCfP/bCH+NRsKnkY+GJIUxpX9bXZvq2VnJnL6IX7zJ3Fhretwetdapu/BO08fZlXf/qb81cyARjaKpQ3utUp9hmDJECLSAJUCAGQmpXL8/P38cfxBHQ6GNu1DsPb1rDqEpqMnDx+2x/Dwl3R7I1OsnjM3VlPh7oBPNQgiHa1rQ/TnDwTP+25wKyNJ7iUrAVnkLcLo9qH8VizKhgcte1eSsrk6W8jORKTgsHRgen9GvFwwyCr9mkLJ+JSGf79Hs4kpmNwdGBq34b0aFT5hvXSs/N4f9URftwZDUC1im583C+CpqEViq02CdAikgAVQuTLM5qY8tthvtuuzZU6oHkI7/Ssj1Mhm4cPXEhmwe5ofom6RNo/Rm7qUMefYB9X1hyKJeZa2IF2veyDdfx5qEEQ7Wv74+p8+zDNNZpYtvcC/9twkotJ2hFagJeBUe3D6N88xByc/5SenceLC/ax4Wg8AK91sc9E6msPxfLyoijSc4xU9nHl8yeaUr+y9y2fs+V4Am8s3U9MchY6HQy/vwYvd6pl06P4fBKgRSQBKoT4t2+2nuGd3w5jUtA6rCKfDm6Kt2vBnVlSsnJZse8iC3ef59Cl65fQhFbUxg7u2+T62MEmkyLqQhKr9sfw+8FYcwCCNgpT+zp+5jB1/1eP4DyjiWX7LjJr40mir2hzt/p5GhjZriYDW1S9baAYTYr3Vh7h661nAOjTpArv965fYODamsmk+N/GE8xYfwKAe2tUYPagJoXu7JWcmcuUXw+zdO8FQJstaHq/RjSocuvwLSoJ0CKSABVCFGTDkTheWLCPjBwjNf3c+WZYC6pW1Drh5M9es2DXeVYesJy9pkv9QAY2D+He28xeo5Ri/4VkVh2IYdXBGPP5PgCDowPtamth2q6WP+uPxDFz4wnOXtaCs5KHMyMeqMnj94YW+Ujs+x3nmPTLIYwmRYvqFfj88ab4FuOUdalZuYxZ/DfrDscB2nW34x+uW+ij+n9adziOccsOkJiWjd5Bx/Ptw3j+wTCrtlUQCdAikgAVQtzMoUvJPD0vktiULCq4O/PxYxGcSkhj4e7znIxPM68X7u/BgBZV6d24slVhpJTi4MUUVh2MYdWBGM5dC8p/q+juzH8eqMHj94beUYeaP44n8PyPe0nNzqNaRTe+GtacmsUwNvCZxHSe/S6Sk/FpOOsdeLdXffo1C7mjbV5Jz2HCioOs3B8DQL1gL6b3a0TtQM87rrfUB+js2bOZNm0asbGxREREMHPmTFq0aHHT9ZOSkhg/fjzLli3jypUrhIaGMmPGDB566KFC7U8CVAhxK3EpWTz97W6Lqd1Aa3J9pGEQA1pUpUlVH5udT1RKcTgmhd8PxLLqQAynE9PxdXNieNuaDGkVekPTrrWOx6Xy1LzdXLiaiberE5893pRWNSvaZNsAm47F8+KCfaRm5RHgZeCzx23bA/jXvy8xYcVBkjJycdY78HKnWgxvW+OOBo0o1QG6aNEihgwZwmeffUbLli2ZMWMGS5Ys4dixY/j73zjoc05ODq1bt8bf358333yTypUrc+7cOXx8fIiIiCjUPiVAhRC3k5GTx8uLolhzKI4Glb3p3zyERxsF41XMF/krpbiUnEUFN+dCdTAqqsS0bJ79LpJ90Uk4Ouh4v1cD+jW/syNEpRRz/jjFtDXHUAqahvoy5/Em+HsWfQ7Z24lPzeLNZQdYf0TrHDW1b8M7OsIt1QHasmVLmjdvzqxZswAwmUyEhITwwgsvMHbs2BvW/+yzz5g2bRpHjx7Fycm6D7IEqBCiMJRSXE7PoVIhO76UFlm5Rl77aT+//n0JgBEP1OT1LrULNRmAyaRITMvmQlImF69mcjEpkx2nL5uv7xzYoiqTH61XrJOlK6VYuvciv/59ia+HNS+fR6A5OTm4ubnx008/0bNnT/PyoUOHkpSUxIoVK254zkMPPUSFChVwc3NjxYoV+Pn5MWjQIN544w30+oK/rWVnZ5OdfX2UjpSUFEJCQiRAhRDlllKKT9af4H8btF6yXesF8kn/RjjpdcSmZJnD8eLVTC7k/37tVtAk6U56HZMercfglqEl+hrutBn9TgPUbiMpJyYmYjQaCQiwHEA4ICCAo0ePFvic06dPs3HjRgYPHsyqVas4efIkI0eOJDc3l7fffrvA53zwwQdMnjzZ5vULIURppdPpGNOpFtUrufHGTwdYfSiWre+vJyPHiNF062MqB502sXplX1cq+7hS2deVbvWDbnt9p62V9DWtBSlVUxGYTCb8/f2ZO3cuer2epk2bcvHiRaZNm3bTAB03bhxjxowx388/AhVCiPKuV+MqVPF1Y/h3kebJ0p30OoJ9roXjtYCs4utGZR9Xqvi6EujtYrPLSEo7uwVopUqV0Ov1xMXFWSyPi4sjMLDgMSmDgoJwcnKyaK6tW7cusbGx5OTk4Ox8Y3dyg8GAwVC2zmEIIYStNK9WgS2vt+dkfBpB3q74eRru+unQ7hZ2+xrh7OxM06ZN2bBhg3mZyWRiw4YNtGrVqsDntG7dmpMnT2IyXW+DP378OEFBQQWGpxBCiNvzdHGicVVfAr1dJDyLwK7H4WPGjOGLL77g22+/5ciRIzz33HOkp6fz5JNPAjBkyBDGjRtnXv+5557jypUrjB49muPHj7Ny5Uref/99Ro0aZa+XIIQQopyy6znQ/v37k5CQwMSJE4mNjaVRo0asXr3a3LEoOjoaB4frGR8SEsKaNWt4+eWXadiwIZUrV2b06NG88cYb9noJQgghyim7j0RU0uQ6UCGEEHDneSBdqYQQQggrSIAKIYQQVpAAFUIIIawgASqEEEJYoVSNRGQL+X2mUlJSbrOmEEKIsiw/B6ztS1vuAjQ1NRVAhvMTQggBaLng7V30sXzL3WUsJpOJS5cu4enpeUeDEeePqXv+/Hm5HOYm5D0qHHmfbk/eo9uT96hw/vk+eXp6kpqaSnBwsMWYA4VV7o5AHRwcqFKlis225+XlJR/W25D3qHDkfbo9eY9uT96jwsl/n6w58swnnYiEEEIIK0iACiGEEFaQALWSwWDg7bfflqnSbkHeo8KR9+n25D26PXmPCseW71O560QkhBBC2IIcgQohhBBWkAAVQgghrCABKoQQQlhBAlQIIYSwggSoFWbPnk21atVwcXGhZcuW7Nq1y94l3VUmTZqETqezuNWpU8feZdnVli1b6N69O8HBweh0On7++WeLx5VSTJw4kaCgIFxdXenYsSMnTpywT7F2dLv3adiwYTd8trp27WqfYu3kgw8+oHnz5nh6euLv70/Pnj05duyYxTpZWVmMGjWKihUr4uHhQZ8+fYiLi7NTxSWvMO9Ru3btbvgsjRgxokj7kQAtokWLFjFmzBjefvtt9u7dS0REBF26dCE+Pt7epd1V6tWrR0xMjPn2119/2bsku0pPTyciIoLZs2cX+PjUqVP53//+x2effcbOnTtxd3enS5cuZGVllXCl9nW79wmga9euFp+tBQsWlGCF9vfHH38watQoduzYwbp168jNzaVz586kp6eb13n55Zf59ddfWbJkCX/88QeXLl2id+/edqy6ZBXmPQJ49tlnLT5LU6dOLdqOlCiSFi1aqFGjRpnvG41GFRwcrD744AM7VnV3efvtt1VERIS9y7hrAWr58uXm+yaTSQUGBqpp06aZlyUlJSmDwaAWLFhghwrvDv9+n5RSaujQoapHjx52qeduFR8frwD1xx9/KKW0z46Tk5NasmSJeZ0jR44oQG3fvt1eZdrVv98jpZR64IEH1OjRo+9ou3IEWgQ5OTns2bOHjh07mpc5ODjQsWNHtm/fbsfK7j4nTpwgODiYGjVqMHjwYKKjo+1d0l3rzJkzxMbGWnyuvL29admypXyuCrB582b8/f2pXbs2zz33HJcvX7Z3SXaVnJwMQIUKFQDYs2cPubm5Fp+nOnXqULVq1XL7efr3e5Tvxx9/pFKlStSvX59x48aRkZFRpO2Wu8Hk70RiYiJGo5GAgACL5QEBARw9etROVd19WrZsybx586hduzYxMTFMnjyZ+++/n4MHD+Lp6Wnv8u46sbGxAAV+rvIfE5quXbvSu3dvqlevzqlTp3jzzTfp1q0b27dvR6/X27u8EmcymXjppZdo3bo19evXB7TPk7OzMz4+PhbrltfPU0HvEcCgQYMIDQ0lODiY/fv388Ybb3Ds2DGWLVtW6G1LgAqb69atm/n3hg0b0rJlS0JDQ1m8eDFPP/20HSsTpd2AAQPMvzdo0ICGDRtSs2ZNNm/eTIcOHexYmX2MGjWKgwcPlvs+Brdys/do+PDh5t8bNGhAUFAQHTp04NSpU9SsWbNQ25Ym3CKoVKkSer3+ht5scXFxBAYG2qmqu5+Pjw+1atXi5MmT9i7lrpT/2ZHPVdHVqFGDSpUqlcvP1vPPP89vv/3Gpk2bLKZoDAwMJCcnh6SkJIv1y+Pn6WbvUUFatmwJUKTPkgRoETg7O9O0aVM2bNhgXmYymdiwYQOtWrWyY2V3t7S0NE6dOkVQUJC9S7krVa9encDAQIvPVUpKCjt37pTP1W1cuHCBy5cvl6vPllKK559/nuXLl7Nx40aqV69u8XjTpk1xcnKy+DwdO3aM6OjocvN5ut17VJCoqCiAon2W7qgLUjm0cOFCZTAY1Lx589Thw4fV8OHDlY+Pj4qNjbV3aXeNV155RW3evFmdOXNGbd26VXXs2FFVqlRJxcfH27s0u0lNTVX79u1T+/btU4CaPn262rdvnzp37pxSSqkPP/xQ+fj4qBUrVqj9+/erHj16qOrVq6vMzEw7V16ybvU+paamqldffVVt375dnTlzRq1fv141adJEhYeHq6ysLHuXXmKee+455e3trTZv3qxiYmLMt4yMDPM6I0aMUFWrVlUbN25UkZGRqlWrVqpVq1Z2rLpk3e49OnnypJoyZYqKjIxUZ86cUStWrFA1atRQbdu2LdJ+JECtMHPmTFW1alXl7OysWrRooXbs2GHvku4q/fv3V0FBQcrZ2VlVrlxZ9e/fX508edLeZdnVpk2bFHDDbejQoUop7VKWCRMmqICAAGUwGFSHDh3UsWPH7Fu0HdzqfcrIyFCdO3dWfn5+ysnJSYWGhqpnn3223H15Lej9AdQ333xjXiczM1ONHDlS+fr6Kjc3N9WrVy8VExNjv6JL2O3eo+joaNW2bVtVoUIFZTAYVFhYmHrttddUcnJykfYj05kJIYQQVpBzoEIIIYQVJECFEEIIK0iACiGEEFaQABVCCCGsIAEqhBBCWEECVAghhLCCBKgQQghhBQlQIYQQwgoSoEKIQtPpdPz888/2LkOIu4IEqBClxLBhw9DpdDfcunbtau/ShCiXZD5QIUqRrl278s0331gsMxgMdqpGiPJNjkCFKEUMBgOBgYEWN19fX0BrXp0zZw7dunXD1dWVGjVq8NNPP1k8/8CBAzz44IO4urpSsWJFhg8fTlpamsU6X3/9NfXq1cNgMBAUFMTzzz9v8XhiYiK9evXCzc2N8PBwfvnll+J90ULcpSRAhShDJkyYQJ8+ffj7778ZPHgwAwYM4MiRIwCkp6fTpUsXfH192b17N0uWLGH9+vUWATlnzhxGjRrF8OHDOXDgAL/88gthYWEW+5g8eTL9+vVj//79PPTQQwwePJgrV66U6OsU4q5g83lkhBDFYujQoUqv1yt3d3eL23vvvaeU0qZwGjFihMVzWrZsqZ577jmllFJz585Vvr6+Ki0tzfz4ypUrlYODg3lKsODgYDV+/Pib1gCot956y3w/LS1NAer333+32esUorSQc6BClCLt27dnzpw5FssqVKhg/r1Vq1YWj7Vq1YqoqCgAjhw5QkREBO7u7ubHW7dujclk4tixY+h0Oi5dukSHDh1uWUPDhg3Nv7u7u+Pl5UV8fLy1L0mIUksCVIhSxN3d/YYmVVtxdXUt1HpOTk4W93U6HSaTqThKEuKuJudAhShDduzYccP9unXrAlC3bl3+/vtv0tPTzY9v3boVBwcHateujaenJ9WqVWPDhg0lWrMQpZUcgQpRimRnZxMbG2uxzNHRkUqVKgGwZMkSmjVrRps2bfjxxx/ZtWsXX331FQCDBw/m7bffZujQoUyaNImEhAReeOEFnnjiCQICAgCYNGkSI0aMwN/fn27dupGamsrWrVt54YUXSvaFClEKSIAKUYqsXr2aoKAgi2W1a9fm6NGjgNZDduHChYwcOZKgoCAWLFjAPffcA4Cbmxtr1qxh9OjRNG/eHDc3N/r06cP06dPN2xo6dChZWVl88sknvPrqq1SqVIm+ffuW3AsUohTRKaWUvYsQQtw5nU7H8uXL6dmzp71LEaJckHOgQgghhBUkQIUQQggryDlQIcoIORsjRMmSI1AhhBDCChKgQgghhBUkQIUQQggrSIAKIYQQVpAAFUIIIawgASqEEEJYQQJUCCGEsIIEqBBCCGGF/wf3wcxTbbpvxgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = pd.DataFrame({\n",
    "    'train_loss': tl,\n",
    "    'eval_loss': el\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(loss['train_loss'], label='Train Loss')\n",
    "plt.plot(loss['eval_loss'], label='Eval Loss')\n",
    "plt.title('Loss Curve ResNet34')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
