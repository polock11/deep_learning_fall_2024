{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# Hyper Parameters\n",
    "batch_size = 32\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # Backbone (ResNet18)\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        # Self-Attention Layer\n",
    "        self.attention = SelfAttention(512)  # 512 is the feature size from ResNet18\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using ResNet18 backbone\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        # Apply self-attention\n",
    "        x = self.attention(x)\n",
    "\n",
    "        # Pass through the fully connected layers\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "\n",
    "        # Compute Query, Key, and Value matrices\n",
    "        Q = self.query(x)  # [batch_size, input_dim]\n",
    "        K = self.key(x)    # [batch_size, input_dim]\n",
    "        V = self.value(x)  # [batch_size, input_dim]\n",
    "\n",
    "        # Compute attention scores (scaled dot-product attention)\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (torch.sqrt(torch.tensor(Q.size(-1))))  # [batch_size, batch_size]\n",
    "        attention_weights = self.softmax(attention_scores)  # [batch_size, batch_size]\n",
    "\n",
    "        # Compute the attention output\n",
    "        attended_features = torch.matmul(attention_weights, V)  # [batch_size, input_dim]\n",
    "\n",
    "        return attended_features\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (attention): SelfAttention(\n",
      "    (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 38/38 [00:18<00:00,  2.08 batch/s, lr=1.0e-04, Loss=1.3747]\n",
      "[Train] Kappa: 0.0134 Accuracy: 0.2833 Precision: 0.2301 Recall: 0.2833 Loss: 1.5506\n",
      "[Train] Class 0: Precision: 0.3110, Recall: 0.7722\n",
      "[Train] Class 1: Precision: 0.2297, Recall: 0.1417\n",
      "[Train] Class 2: Precision: 0.1795, Recall: 0.0583\n",
      "[Train] Class 3: Precision: 0.2000, Recall: 0.0333\n",
      "[Train] Class 4: Precision: 0.1500, Recall: 0.0500\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.55 batch/s]\n",
      "[Val] Kappa: 0.0405 Accuracy: 0.3000 Precision: 0.0957 Recall: 0.3000\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.18 batch/s, lr=1.0e-04, Loss=1.1749]\n",
      "[Train] Kappa: 0.3617 Accuracy: 0.4033 Precision: 0.3620 Recall: 0.4033 Loss: 1.4197\n",
      "[Train] Class 0: Precision: 0.6354, Recall: 0.8083\n",
      "[Train] Class 1: Precision: 0.2715, Recall: 0.3292\n",
      "[Train] Class 2: Precision: 0.2493, Recall: 0.3500\n",
      "[Train] Class 3: Precision: 0.2736, Recall: 0.1208\n",
      "[Train] Class 4: Precision: 0.1250, Recall: 0.0083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.13 batch/s]\n",
      "[Val] Kappa: 0.2532 Accuracy: 0.3900 Precision: 0.2393 Recall: 0.3900\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.31 batch/s, lr=1.0e-04, Loss=1.2045]\n",
      "[Train] Kappa: 0.5133 Accuracy: 0.4250 Precision: 0.3853 Recall: 0.4250 Loss: 1.3412\n",
      "[Train] Class 0: Precision: 0.7378, Recall: 0.8833\n",
      "[Train] Class 1: Precision: 0.2418, Recall: 0.1833\n",
      "[Train] Class 2: Precision: 0.2292, Recall: 0.2750\n",
      "[Train] Class 3: Precision: 0.2774, Recall: 0.3375\n",
      "[Train] Class 4: Precision: 0.1429, Recall: 0.0083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.88 batch/s]\n",
      "[Val] Kappa: 0.6445 Accuracy: 0.4900 Precision: 0.3915 Recall: 0.4900\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.15 batch/s, lr=1.0e-04, Loss=1.1391]\n",
      "[Train] Kappa: 0.5237 Accuracy: 0.4333 Precision: 0.3774 Recall: 0.4333 Loss: 1.2877\n",
      "[Train] Class 0: Precision: 0.7564, Recall: 0.8972\n",
      "[Train] Class 1: Precision: 0.2158, Recall: 0.1708\n",
      "[Train] Class 2: Precision: 0.2509, Recall: 0.2833\n",
      "[Train] Class 3: Precision: 0.2857, Recall: 0.3667\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.13 batch/s]\n",
      "[Val] Kappa: 0.7350 Accuracy: 0.4650 Precision: 0.4536 Recall: 0.4650\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.11 batch/s, lr=1.0e-04, Loss=1.4147]\n",
      "[Train] Kappa: 0.5326 Accuracy: 0.4350 Precision: 0.3966 Recall: 0.4350 Loss: 1.3089\n",
      "[Train] Class 0: Precision: 0.7367, Recall: 0.8861\n",
      "[Train] Class 1: Precision: 0.2308, Recall: 0.1375\n",
      "[Train] Class 2: Precision: 0.2593, Recall: 0.3500\n",
      "[Train] Class 3: Precision: 0.2881, Recall: 0.3542\n",
      "[Train] Class 4: Precision: 0.2000, Recall: 0.0083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.02 batch/s]\n",
      "[Val] Kappa: 0.5914 Accuracy: 0.4625 Precision: 0.3522 Recall: 0.4625\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.23 batch/s, lr=1.0e-04, Loss=1.1022]\n",
      "[Train] Kappa: 0.6138 Accuracy: 0.4775 Precision: 0.4251 Recall: 0.4775 Loss: 1.2496\n",
      "[Train] Class 0: Precision: 0.7596, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.3673, Recall: 0.1500\n",
      "[Train] Class 2: Precision: 0.3227, Recall: 0.2958\n",
      "[Train] Class 3: Precision: 0.2963, Recall: 0.5333\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.20 batch/s]\n",
      "[Val] Kappa: 0.6894 Accuracy: 0.4625 Precision: 0.3353 Recall: 0.4625\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.21 batch/s, lr=1.0e-04, Loss=1.2982]\n",
      "[Train] Kappa: 0.5994 Accuracy: 0.4508 Precision: 0.4180 Recall: 0.4508 Loss: 1.2399\n",
      "[Train] Class 0: Precision: 0.7765, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.2556, Recall: 0.0958\n",
      "[Train] Class 2: Precision: 0.2609, Recall: 0.3000\n",
      "[Train] Class 3: Precision: 0.2725, Recall: 0.4417\n",
      "[Train] Class 4: Precision: 0.2727, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 13/13 [00:01<00:00,  6.72 batch/s]\n",
      "[Val] Kappa: 0.7335 Accuracy: 0.5275 Precision: 0.4450 Recall: 0.5275\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.27 batch/s, lr=1.0e-04, Loss=1.0421]\n",
      "[Train] Kappa: 0.6436 Accuracy: 0.4842 Precision: 0.4356 Recall: 0.4842 Loss: 1.1909\n",
      "[Train] Class 0: Precision: 0.7770, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.2828, Recall: 0.1708\n",
      "[Train] Class 2: Precision: 0.2804, Recall: 0.2208\n",
      "[Train] Class 3: Precision: 0.3492, Recall: 0.6125\n",
      "[Train] Class 4: Precision: 0.2000, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.31 batch/s]\n",
      "[Val] Kappa: 0.7727 Accuracy: 0.5875 Precision: 0.6314 Recall: 0.5875\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.34 batch/s, lr=1.0e-04, Loss=1.2736]\n",
      "[Train] Kappa: 0.6629 Accuracy: 0.4842 Precision: 0.4193 Recall: 0.4842 Loss: 1.2042\n",
      "[Train] Class 0: Precision: 0.7578, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.3362, Recall: 0.1625\n",
      "[Train] Class 2: Precision: 0.2569, Recall: 0.2708\n",
      "[Train] Class 3: Precision: 0.3668, Recall: 0.5792\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.39 batch/s]\n",
      "[Val] Kappa: 0.8030 Accuracy: 0.5675 Precision: 0.5011 Recall: 0.5675\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.28 batch/s, lr=1.0e-04, Loss=1.2526]\n",
      "[Train] Kappa: 0.7072 Accuracy: 0.5400 Precision: 0.4947 Recall: 0.5400 Loss: 1.1466\n",
      "[Train] Class 0: Precision: 0.7820, Recall: 0.9167\n",
      "[Train] Class 1: Precision: 0.4467, Recall: 0.2792\n",
      "[Train] Class 2: Precision: 0.3164, Recall: 0.3375\n",
      "[Train] Class 3: Precision: 0.4706, Recall: 0.7000\n",
      "[Train] Class 4: Precision: 0.1333, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.43 batch/s]\n",
      "[Val] Kappa: 0.7901 Accuracy: 0.5525 Precision: 0.4565 Recall: 0.5525\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.29 batch/s, lr=1.0e-05, Loss=1.0326]\n",
      "[Train] Kappa: 0.7226 Accuracy: 0.5475 Precision: 0.5238 Recall: 0.5475 Loss: 1.0864\n",
      "[Train] Class 0: Precision: 0.8157, Recall: 0.9222\n",
      "[Train] Class 1: Precision: 0.4145, Recall: 0.2625\n",
      "[Train] Class 2: Precision: 0.3413, Recall: 0.4167\n",
      "[Train] Class 3: Precision: 0.4727, Recall: 0.6500\n",
      "[Train] Class 4: Precision: 0.3333, Recall: 0.0500\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.40 batch/s]\n",
      "[Val] Kappa: 0.7930 Accuracy: 0.6025 Precision: 0.5319 Recall: 0.6025\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.20 batch/s, lr=1.0e-05, Loss=1.1586]\n",
      "[Train] Kappa: 0.7313 Accuracy: 0.5558 Precision: 0.5116 Recall: 0.5558 Loss: 1.0966\n",
      "[Train] Class 0: Precision: 0.7934, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.4459, Recall: 0.2917\n",
      "[Train] Class 2: Precision: 0.3668, Recall: 0.4417\n",
      "[Train] Class 3: Precision: 0.4950, Recall: 0.6250\n",
      "[Train] Class 4: Precision: 0.1200, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.25 batch/s]\n",
      "[Val] Kappa: 0.7955 Accuracy: 0.6025 Precision: 0.5371 Recall: 0.6025\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.33 batch/s, lr=1.0e-05, Loss=1.0576]\n",
      "[Train] Kappa: 0.7501 Accuracy: 0.5717 Precision: 0.5316 Recall: 0.5717 Loss: 1.0758\n",
      "[Train] Class 0: Precision: 0.8220, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.4795, Recall: 0.2917\n",
      "[Train] Class 2: Precision: 0.3919, Recall: 0.4833\n",
      "[Train] Class 3: Precision: 0.5000, Recall: 0.6667\n",
      "[Train] Class 4: Precision: 0.1071, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.33 batch/s]\n",
      "[Val] Kappa: 0.8041 Accuracy: 0.6225 Precision: 0.5592 Recall: 0.6225\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.32 batch/s, lr=1.0e-05, Loss=1.2864]\n",
      "[Train] Kappa: 0.7681 Accuracy: 0.5733 Precision: 0.5414 Recall: 0.5733 Loss: 1.0433\n",
      "[Train] Class 0: Precision: 0.8329, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.4596, Recall: 0.3792\n",
      "[Train] Class 2: Precision: 0.3320, Recall: 0.3583\n",
      "[Train] Class 3: Precision: 0.5282, Recall: 0.6625\n",
      "[Train] Class 4: Precision: 0.2759, Recall: 0.0667\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.86 batch/s]\n",
      "[Val] Kappa: 0.8233 Accuracy: 0.6400 Precision: 0.5780 Recall: 0.6400\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.24 batch/s, lr=1.0e-05, Loss=0.8954]\n",
      "[Train] Kappa: 0.7643 Accuracy: 0.5742 Precision: 0.5330 Recall: 0.5742 Loss: 1.0382\n",
      "[Train] Class 0: Precision: 0.8337, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.4555, Recall: 0.3625\n",
      "[Train] Class 2: Precision: 0.3527, Recall: 0.3792\n",
      "[Train] Class 3: Precision: 0.5229, Recall: 0.6667\n",
      "[Train] Class 4: Precision: 0.1667, Recall: 0.0417\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.29 batch/s]\n",
      "[Val] Kappa: 0.8367 Accuracy: 0.6550 Precision: 0.5898 Recall: 0.6550\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.33 batch/s, lr=1.0e-05, Loss=0.9737]\n",
      "[Train] Kappa: 0.7669 Accuracy: 0.5742 Precision: 0.5414 Recall: 0.5742 Loss: 1.0393\n",
      "[Train] Class 0: Precision: 0.8554, Recall: 0.9528\n",
      "[Train] Class 1: Precision: 0.4423, Recall: 0.3833\n",
      "[Train] Class 2: Precision: 0.3374, Recall: 0.3417\n",
      "[Train] Class 3: Precision: 0.5190, Recall: 0.6833\n",
      "[Train] Class 4: Precision: 0.2500, Recall: 0.0667\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.46 batch/s]\n",
      "[Val] Kappa: 0.8551 Accuracy: 0.6450 Precision: 0.5865 Recall: 0.6450\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.26 batch/s, lr=1.0e-05, Loss=1.1624]\n",
      "[Train] Kappa: 0.7811 Accuracy: 0.6008 Precision: 0.5600 Recall: 0.6008 Loss: 1.0266\n",
      "[Train] Class 0: Precision: 0.8325, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.5138, Recall: 0.3875\n",
      "[Train] Class 2: Precision: 0.3802, Recall: 0.4167\n",
      "[Train] Class 3: Precision: 0.5517, Recall: 0.7333\n",
      "[Train] Class 4: Precision: 0.2105, Recall: 0.0333\n",
      "Evaluating: 100%|██████████| 13/13 [00:01<00:00,  6.75 batch/s]\n",
      "[Val] Kappa: 0.8457 Accuracy: 0.6675 Precision: 0.5994 Recall: 0.6675\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 38/38 [00:15<00:00,  2.38 batch/s, lr=1.0e-05, Loss=1.7516]\n",
      "[Train] Kappa: 0.7776 Accuracy: 0.5917 Precision: 0.5567 Recall: 0.5917 Loss: 1.0304\n",
      "[Train] Class 0: Precision: 0.8561, Recall: 0.9417\n",
      "[Train] Class 1: Precision: 0.4783, Recall: 0.4125\n",
      "[Train] Class 2: Precision: 0.3975, Recall: 0.4042\n",
      "[Train] Class 3: Precision: 0.5152, Recall: 0.7083\n",
      "[Train] Class 4: Precision: 0.2174, Recall: 0.0417\n",
      "Evaluating: 100%|██████████| 13/13 [00:01<00:00,  6.80 batch/s]\n",
      "[Val] Kappa: 0.8519 Accuracy: 0.6525 Precision: 0.5895 Recall: 0.6525\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 38/38 [00:15<00:00,  2.38 batch/s, lr=1.0e-05, Loss=1.2135]\n",
      "[Train] Kappa: 0.7690 Accuracy: 0.5950 Precision: 0.5627 Recall: 0.5950 Loss: 0.9936\n",
      "[Train] Class 0: Precision: 0.8660, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.4545, Recall: 0.4167\n",
      "[Train] Class 2: Precision: 0.3887, Recall: 0.4000\n",
      "[Train] Class 3: Precision: 0.5311, Recall: 0.6750\n",
      "[Train] Class 4: Precision: 0.2800, Recall: 0.0583\n",
      "Evaluating: 100%|██████████| 13/13 [00:01<00:00,  6.65 batch/s]\n",
      "[Val] Kappa: 0.8364 Accuracy: 0.6425 Precision: 0.5783 Recall: 0.6425\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.36 batch/s, lr=1.0e-05, Loss=1.0804]\n",
      "[Train] Kappa: 0.7630 Accuracy: 0.5917 Precision: 0.5651 Recall: 0.5917 Loss: 1.0470\n",
      "[Train] Class 0: Precision: 0.8120, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.4871, Recall: 0.4708\n",
      "[Train] Class 2: Precision: 0.3700, Recall: 0.3500\n",
      "[Train] Class 3: Precision: 0.5537, Recall: 0.6875\n",
      "[Train] Class 4: Precision: 0.3929, Recall: 0.0917\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.23 batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_47421/2173995008.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_c/c_1_self_attention.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val] Kappa: 0.8123 Accuracy: 0.6300 Precision: 0.5589 Recall: 0.6300\n",
      "[Val] Best kappa: 0.8551, Epoch 16\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.44 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_c/c_1_self_attention.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    #state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    #state_dict = torch.load(state_dict_path, map_location='cpu')\n",
    "    #model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_c/c_1_self_attention.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_c/c_1_self_attention.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    pred_path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_c/c_1_self_attention.csv'\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
