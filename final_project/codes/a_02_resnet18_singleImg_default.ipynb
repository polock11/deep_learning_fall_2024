{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.55 batch/s, lr=1.0e-04, Loss=1.2499]\n",
      "[Train] Kappa: 0.2430 Accuracy: 0.3442 Precision: 0.3128 Recall: 0.3442 Loss: 1.4918\n",
      "[Train] Class 0: Precision: 0.5212, Recall: 0.6833\n",
      "[Train] Class 1: Precision: 0.2975, Recall: 0.1958\n",
      "[Train] Class 2: Precision: 0.2594, Recall: 0.3458\n",
      "[Train] Class 3: Precision: 0.2025, Recall: 0.1375\n",
      "[Train] Class 4: Precision: 0.0460, Recall: 0.0333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.70 batch/s]\n",
      "[Val] Kappa: 0.5928 Accuracy: 0.5200 Precision: 0.5170 Recall: 0.5200\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.72 batch/s, lr=1.0e-04, Loss=0.9771]\n",
      "[Train] Kappa: 0.5374 Accuracy: 0.4792 Precision: 0.4458 Recall: 0.4792 Loss: 1.2561\n",
      "[Train] Class 0: Precision: 0.7616, Recall: 0.9139\n",
      "[Train] Class 1: Precision: 0.3247, Recall: 0.4167\n",
      "[Train] Class 2: Precision: 0.2857, Recall: 0.3333\n",
      "[Train] Class 3: Precision: 0.3765, Recall: 0.2667\n",
      "[Train] Class 4: Precision: 0.2000, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.24 batch/s]\n",
      "[Val] Kappa: 0.6990 Accuracy: 0.6200 Precision: 0.5461 Recall: 0.6200\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.72 batch/s, lr=1.0e-04, Loss=0.9888]\n",
      "[Train] Kappa: 0.6883 Accuracy: 0.5433 Precision: 0.5141 Recall: 0.5433 Loss: 1.1204\n",
      "[Train] Class 0: Precision: 0.7901, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.4658, Recall: 0.4542\n",
      "[Train] Class 2: Precision: 0.3165, Recall: 0.3125\n",
      "[Train] Class 3: Precision: 0.4204, Recall: 0.4292\n",
      "[Train] Class 4: Precision: 0.3659, Recall: 0.1250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.15 batch/s]\n",
      "[Val] Kappa: 0.7613 Accuracy: 0.6225 Precision: 0.5565 Recall: 0.6225\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.71 batch/s, lr=1.0e-04, Loss=1.0399]\n",
      "[Train] Kappa: 0.7191 Accuracy: 0.5708 Precision: 0.5405 Recall: 0.5708 Loss: 1.0499\n",
      "[Train] Class 0: Precision: 0.8005, Recall: 0.9472\n",
      "[Train] Class 1: Precision: 0.4828, Recall: 0.5250\n",
      "[Train] Class 2: Precision: 0.3575, Recall: 0.3083\n",
      "[Train] Class 3: Precision: 0.4853, Recall: 0.5500\n",
      "[Train] Class 4: Precision: 0.3529, Recall: 0.1000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.23 batch/s]\n",
      "[Val] Kappa: 0.7007 Accuracy: 0.5300 Precision: 0.5643 Recall: 0.5300\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.66 batch/s, lr=1.0e-04, Loss=0.9139]\n",
      "[Train] Kappa: 0.7779 Accuracy: 0.6183 Precision: 0.5902 Recall: 0.6183 Loss: 0.9579\n",
      "[Train] Class 0: Precision: 0.8325, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.5741, Recall: 0.6292\n",
      "[Train] Class 2: Precision: 0.4505, Recall: 0.3417\n",
      "[Train] Class 3: Precision: 0.5018, Recall: 0.5917\n",
      "[Train] Class 4: Precision: 0.3519, Recall: 0.1583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.19 batch/s]\n",
      "[Val] Kappa: 0.7807 Accuracy: 0.6275 Precision: 0.5657 Recall: 0.6275\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.58 batch/s, lr=1.0e-04, Loss=1.1549]\n",
      "[Train] Kappa: 0.7889 Accuracy: 0.6342 Precision: 0.6082 Recall: 0.6342 Loss: 0.9571\n",
      "[Train] Class 0: Precision: 0.8410, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.6230, Recall: 0.6333\n",
      "[Train] Class 2: Precision: 0.4791, Recall: 0.4292\n",
      "[Train] Class 3: Precision: 0.5036, Recall: 0.5875\n",
      "[Train] Class 4: Precision: 0.3478, Recall: 0.1333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.05 batch/s]\n",
      "[Val] Kappa: 0.7596 Accuracy: 0.6325 Precision: 0.5666 Recall: 0.6325\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.68 batch/s, lr=1.0e-04, Loss=0.6725]\n",
      "[Train] Kappa: 0.7944 Accuracy: 0.6317 Precision: 0.6109 Recall: 0.6317 Loss: 0.9063\n",
      "[Train] Class 0: Precision: 0.8402, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.6478, Recall: 0.6208\n",
      "[Train] Class 2: Precision: 0.4545, Recall: 0.4167\n",
      "[Train] Class 3: Precision: 0.5074, Recall: 0.5750\n",
      "[Train] Class 4: Precision: 0.3692, Recall: 0.2000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.08 batch/s]\n",
      "[Val] Kappa: 0.7117 Accuracy: 0.6125 Precision: 0.5438 Recall: 0.6125\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.69 batch/s, lr=1.0e-04, Loss=1.2107]\n",
      "[Train] Kappa: 0.8140 Accuracy: 0.6750 Precision: 0.6643 Recall: 0.6750 Loss: 0.8737\n",
      "[Train] Class 0: Precision: 0.8575, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.6709, Recall: 0.6542\n",
      "[Train] Class 2: Precision: 0.5179, Recall: 0.4833\n",
      "[Train] Class 3: Precision: 0.5590, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.5745, Recall: 0.2250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.08 batch/s]\n",
      "[Val] Kappa: 0.7819 Accuracy: 0.6475 Precision: 0.6401 Recall: 0.6475\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.61 batch/s, lr=1.0e-04, Loss=0.7634]\n",
      "[Train] Kappa: 0.8325 Accuracy: 0.6858 Precision: 0.6771 Recall: 0.6858 Loss: 0.8296\n",
      "[Train] Class 0: Precision: 0.8785, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.7048, Recall: 0.6667\n",
      "[Train] Class 2: Precision: 0.5550, Recall: 0.4833\n",
      "[Train] Class 3: Precision: 0.5452, Recall: 0.7042\n",
      "[Train] Class 4: Precision: 0.5254, Recall: 0.2583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.14 batch/s]\n",
      "[Val] Kappa: 0.7921 Accuracy: 0.6600 Precision: 0.6656 Recall: 0.6600\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.69 batch/s, lr=1.0e-04, Loss=0.8711]\n",
      "[Train] Kappa: 0.8279 Accuracy: 0.7025 Precision: 0.6910 Recall: 0.7025 Loss: 0.7833\n",
      "[Train] Class 0: Precision: 0.8691, Recall: 0.9778\n",
      "[Train] Class 1: Precision: 0.6940, Recall: 0.6708\n",
      "[Train] Class 2: Precision: 0.5859, Recall: 0.4833\n",
      "[Train] Class 3: Precision: 0.5952, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.5526, Recall: 0.3500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.86 batch/s]\n",
      "[Val] Kappa: 0.7443 Accuracy: 0.6600 Precision: 0.6476 Recall: 0.6600\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.60 batch/s, lr=1.0e-05, Loss=0.5935]\n",
      "[Train] Kappa: 0.8676 Accuracy: 0.7492 Precision: 0.7407 Recall: 0.7492 Loss: 0.6845\n",
      "[Train] Class 0: Precision: 0.8850, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.7689, Recall: 0.7625\n",
      "[Train] Class 2: Precision: 0.6716, Recall: 0.5625\n",
      "[Train] Class 3: Precision: 0.6413, Recall: 0.7375\n",
      "[Train] Class 4: Precision: 0.5882, Recall: 0.4167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.80 batch/s]\n",
      "[Val] Kappa: 0.7589 Accuracy: 0.6700 Precision: 0.6502 Recall: 0.6700\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.57 batch/s, lr=1.0e-05, Loss=0.7679]\n",
      "[Train] Kappa: 0.8684 Accuracy: 0.7383 Precision: 0.7289 Recall: 0.7383 Loss: 0.6896\n",
      "[Train] Class 0: Precision: 0.8716, Recall: 0.9806\n",
      "[Train] Class 1: Precision: 0.7588, Recall: 0.7208\n",
      "[Train] Class 2: Precision: 0.6179, Recall: 0.5458\n",
      "[Train] Class 3: Precision: 0.6604, Recall: 0.7292\n",
      "[Train] Class 4: Precision: 0.6000, Recall: 0.4500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.06 batch/s]\n",
      "[Val] Kappa: 0.7737 Accuracy: 0.6750 Precision: 0.6505 Recall: 0.6750\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.64 batch/s, lr=1.0e-05, Loss=0.4875]\n",
      "[Train] Kappa: 0.8751 Accuracy: 0.7475 Precision: 0.7416 Recall: 0.7475 Loss: 0.6748\n",
      "[Train] Class 0: Precision: 0.9013, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.7521, Recall: 0.7458\n",
      "[Train] Class 2: Precision: 0.6400, Recall: 0.6000\n",
      "[Train] Class 3: Precision: 0.6515, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.6250, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.96 batch/s]\n",
      "[Val] Kappa: 0.7570 Accuracy: 0.6625 Precision: 0.6430 Recall: 0.6625\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.63 batch/s, lr=1.0e-05, Loss=0.5333]\n",
      "[Train] Kappa: 0.8771 Accuracy: 0.7483 Precision: 0.7417 Recall: 0.7483 Loss: 0.6430\n",
      "[Train] Class 0: Precision: 0.8939, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.7457, Recall: 0.7208\n",
      "[Train] Class 2: Precision: 0.6205, Recall: 0.5792\n",
      "[Train] Class 3: Precision: 0.6642, Recall: 0.7333\n",
      "[Train] Class 4: Precision: 0.6747, Recall: 0.4667\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.99 batch/s]\n",
      "[Val] Kappa: 0.7909 Accuracy: 0.6775 Precision: 0.6538 Recall: 0.6775\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.39 batch/s, lr=1.0e-05, Loss=0.7060]\n",
      "[Train] Kappa: 0.8681 Accuracy: 0.7525 Precision: 0.7465 Recall: 0.7525 Loss: 0.6502\n",
      "[Train] Class 0: Precision: 0.8934, Recall: 0.9778\n",
      "[Train] Class 1: Precision: 0.7928, Recall: 0.7333\n",
      "[Train] Class 2: Precision: 0.6444, Recall: 0.6042\n",
      "[Train] Class 3: Precision: 0.6530, Recall: 0.7292\n",
      "[Train] Class 4: Precision: 0.6044, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.53 batch/s]\n",
      "[Val] Kappa: 0.7937 Accuracy: 0.6725 Precision: 0.6571 Recall: 0.6725\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.61 batch/s, lr=1.0e-05, Loss=0.5782]\n",
      "[Train] Kappa: 0.8855 Accuracy: 0.7808 Precision: 0.7750 Recall: 0.7808 Loss: 0.6149\n",
      "[Train] Class 0: Precision: 0.9010, Recall: 0.9861\n",
      "[Train] Class 1: Precision: 0.8133, Recall: 0.7625\n",
      "[Train] Class 2: Precision: 0.6695, Recall: 0.6500\n",
      "[Train] Class 3: Precision: 0.7211, Recall: 0.7542\n",
      "[Train] Class 4: Precision: 0.6392, Recall: 0.5167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.88 batch/s]\n",
      "[Val] Kappa: 0.7823 Accuracy: 0.6825 Precision: 0.6588 Recall: 0.6825\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.56 batch/s, lr=1.0e-05, Loss=0.5363]\n",
      "[Train] Kappa: 0.8891 Accuracy: 0.7783 Precision: 0.7726 Recall: 0.7783 Loss: 0.6110\n",
      "[Train] Class 0: Precision: 0.9072, Recall: 0.9778\n",
      "[Train] Class 1: Precision: 0.7848, Recall: 0.7750\n",
      "[Train] Class 2: Precision: 0.6959, Recall: 0.6292\n",
      "[Train] Class 3: Precision: 0.6955, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.6522, Recall: 0.5000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.68 batch/s]\n",
      "[Val] Kappa: 0.7695 Accuracy: 0.6575 Precision: 0.6400 Recall: 0.6575\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 50/50 [00:14<00:00,  3.43 batch/s, lr=1.0e-05, Loss=0.5572]\n",
      "[Train] Kappa: 0.8853 Accuracy: 0.7642 Precision: 0.7589 Recall: 0.7642 Loss: 0.6159\n",
      "[Train] Class 0: Precision: 0.9143, Recall: 0.9778\n",
      "[Train] Class 1: Precision: 0.7743, Recall: 0.7292\n",
      "[Train] Class 2: Precision: 0.6476, Recall: 0.6125\n",
      "[Train] Class 3: Precision: 0.6827, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.6374, Recall: 0.4833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.57 batch/s]\n",
      "[Val] Kappa: 0.7614 Accuracy: 0.6625 Precision: 0.6375 Recall: 0.6625\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.60 batch/s, lr=1.0e-05, Loss=0.5624]\n",
      "[Train] Kappa: 0.8851 Accuracy: 0.7875 Precision: 0.7870 Recall: 0.7875 Loss: 0.5810\n",
      "[Train] Class 0: Precision: 0.9235, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.7964, Recall: 0.7333\n",
      "[Train] Class 2: Precision: 0.6564, Recall: 0.7083\n",
      "[Train] Class 3: Precision: 0.7266, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.7412, Recall: 0.5250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.84 batch/s]\n",
      "[Val] Kappa: 0.7754 Accuracy: 0.6675 Precision: 0.6407 Recall: 0.6675\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 50/50 [00:13<00:00,  3.59 batch/s, lr=1.0e-05, Loss=0.5609]\n",
      "[Train] Kappa: 0.8890 Accuracy: 0.7867 Precision: 0.7829 Recall: 0.7867 Loss: 0.5641\n",
      "[Train] Class 0: Precision: 0.9086, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.7782, Recall: 0.7750\n",
      "[Train] Class 2: Precision: 0.6891, Recall: 0.6833\n",
      "[Train] Class 3: Precision: 0.7262, Recall: 0.7625\n",
      "[Train] Class 4: Precision: 0.7159, Recall: 0.5250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  6.82 batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_25542/3388358429.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_check_point.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val] Kappa: 0.7914 Accuracy: 0.6775 Precision: 0.6536 Recall: 0.6775\n",
      "[Val] Best kappa: 0.7937, Epoch 15\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.84 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_base_result.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    #state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    #state_dict = torch.load(state_dict_path, map_location='cpu')\n",
    "    #model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_check_point.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_check_point.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    pred_path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_base_result.csv'\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
