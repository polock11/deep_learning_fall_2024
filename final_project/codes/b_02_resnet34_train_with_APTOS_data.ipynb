{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['id_code'] = os.path.join(self.image_dir, row['id_code'])\n",
    "            if not self.test:\n",
    "                file_info['diagnosis'] = int(row['diagnosis'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['id_code']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['diagnosis'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet34(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            \n",
    "            \n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                \"\"\"\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "                        \"\"\"\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_images/train_images/\"\n",
    "train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_1.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/val_images/val_images/\"\n",
    "val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/valid.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "val_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 92/92 [05:19<00:00,  3.47s/ batch, lr=1.0e-04, Loss=0.6778]\n",
      "[Train] Kappa: 0.5432 Accuracy: 0.6471 Precision: 0.5723 Recall: 0.6471 Loss: 0.9950\n",
      "[Train] Class 0: Precision: 0.8417, Recall: 0.8821\n",
      "[Train] Class 1: Precision: 0.1200, Recall: 0.0100\n",
      "[Train] Class 2: Precision: 0.5151, Recall: 0.7599\n",
      "[Train] Class 3: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 4: Precision: 0.0757, Recall: 0.0598\n",
      "Evaluating: 100%|██████████| 92/92 [04:52<00:00,  3.18s/ batch]\n",
      "[Val] Kappa: 0.7675 Accuracy: 0.7392 Precision: 0.6061 Recall: 0.7392\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 92/92 [05:17<00:00,  3.45s/ batch, lr=1.0e-04, Loss=0.7354]\n",
      "[Train] Kappa: 0.7805 Accuracy: 0.7410 Precision: 0.6810 Recall: 0.7410 Loss: 0.7115\n",
      "[Train] Class 0: Precision: 0.9324, Recall: 0.9714\n",
      "[Train] Class 1: Precision: 0.4706, Recall: 0.1067\n",
      "[Train] Class 2: Precision: 0.5531, Recall: 0.9084\n",
      "[Train] Class 3: Precision: 0.0000, Recall: 0.0000\n",
      "[Train] Class 4: Precision: 0.3000, Recall: 0.0513\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.7291 Accuracy: 0.7461 Precision: 0.6487 Recall: 0.7461\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 92/92 [05:16<00:00,  3.44s/ batch, lr=1.0e-04, Loss=0.4366]\n",
      "[Train] Kappa: 0.8005 Accuracy: 0.7543 Precision: 0.7300 Recall: 0.7543 Loss: 0.6476\n",
      "[Train] Class 0: Precision: 0.9503, Recall: 0.9735\n",
      "[Train] Class 1: Precision: 0.4897, Recall: 0.3167\n",
      "[Train] Class 2: Precision: 0.5893, Recall: 0.8416\n",
      "[Train] Class 3: Precision: 0.5263, Recall: 0.0649\n",
      "[Train] Class 4: Precision: 0.3085, Recall: 0.1239\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.8171 Accuracy: 0.7816 Precision: 0.7786 Recall: 0.7816\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 92/92 [05:15<00:00,  3.43s/ batch, lr=1.0e-04, Loss=0.6717]\n",
      "[Train] Kappa: 0.8153 Accuracy: 0.7635 Precision: 0.7328 Recall: 0.7635 Loss: 0.6039\n",
      "[Train] Class 0: Precision: 0.9544, Recall: 0.9770\n",
      "[Train] Class 1: Precision: 0.5068, Recall: 0.3733\n",
      "[Train] Class 2: Precision: 0.6201, Recall: 0.8342\n",
      "[Train] Class 3: Precision: 0.3382, Recall: 0.1494\n",
      "[Train] Class 4: Precision: 0.3140, Recall: 0.1154\n",
      "Evaluating: 100%|██████████| 92/92 [04:55<00:00,  3.21s/ batch]\n",
      "[Val] Kappa: 0.8451 Accuracy: 0.7959 Precision: 0.7969 Recall: 0.7959\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 92/92 [05:16<00:00,  3.44s/ batch, lr=1.0e-04, Loss=0.7969]\n",
      "[Train] Kappa: 0.8410 Accuracy: 0.7703 Precision: 0.7511 Recall: 0.7703 Loss: 0.5969\n",
      "[Train] Class 0: Precision: 0.9660, Recall: 0.9707\n",
      "[Train] Class 1: Precision: 0.4978, Recall: 0.3733\n",
      "[Train] Class 2: Precision: 0.6334, Recall: 0.8317\n",
      "[Train] Class 3: Precision: 0.3922, Recall: 0.1299\n",
      "[Train] Class 4: Precision: 0.4013, Recall: 0.2607\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.8284 Accuracy: 0.7908 Precision: 0.7847 Recall: 0.7908\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 92/92 [05:18<00:00,  3.46s/ batch, lr=1.0e-04, Loss=0.8171]\n",
      "[Train] Kappa: 0.8637 Accuracy: 0.7860 Precision: 0.7682 Recall: 0.7860 Loss: 0.5633\n",
      "[Train] Class 0: Precision: 0.9729, Recall: 0.9777\n",
      "[Train] Class 1: Precision: 0.5500, Recall: 0.3667\n",
      "[Train] Class 2: Precision: 0.6527, Recall: 0.8465\n",
      "[Train] Class 3: Precision: 0.3125, Recall: 0.1299\n",
      "[Train] Class 4: Precision: 0.4915, Recall: 0.3718\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.8767 Accuracy: 0.8109 Precision: 0.8022 Recall: 0.8109\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 92/92 [05:17<00:00,  3.46s/ batch, lr=1.0e-04, Loss=0.6148]\n",
      "[Train] Kappa: 0.8634 Accuracy: 0.8041 Precision: 0.7910 Recall: 0.8041 Loss: 0.5240\n",
      "[Train] Class 0: Precision: 0.9738, Recall: 0.9847\n",
      "[Train] Class 1: Precision: 0.6323, Recall: 0.4700\n",
      "[Train] Class 2: Precision: 0.6632, Recall: 0.8626\n",
      "[Train] Class 3: Precision: 0.4426, Recall: 0.1753\n",
      "[Train] Class 4: Precision: 0.5448, Recall: 0.3376\n",
      "Evaluating: 100%|██████████| 92/92 [04:54<00:00,  3.20s/ batch]\n",
      "[Val] Kappa: 0.8840 Accuracy: 0.8157 Precision: 0.8045 Recall: 0.8157\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 92/92 [05:19<00:00,  3.48s/ batch, lr=1.0e-04, Loss=0.5454]\n",
      "[Train] Kappa: 0.8656 Accuracy: 0.7952 Precision: 0.7725 Recall: 0.7952 Loss: 0.5338\n",
      "[Train] Class 0: Precision: 0.9758, Recall: 0.9826\n",
      "[Train] Class 1: Precision: 0.5817, Recall: 0.4867\n",
      "[Train] Class 2: Precision: 0.6582, Recall: 0.8366\n",
      "[Train] Class 3: Precision: 0.1860, Recall: 0.0519\n",
      "[Train] Class 4: Precision: 0.5515, Recall: 0.3889\n",
      "Evaluating: 100%|██████████| 92/92 [04:54<00:00,  3.20s/ batch]\n",
      "[Val] Kappa: 0.8712 Accuracy: 0.8321 Precision: 0.8349 Recall: 0.8321\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 92/92 [05:17<00:00,  3.45s/ batch, lr=1.0e-04, Loss=0.4046]\n",
      "[Train] Kappa: 0.8826 Accuracy: 0.8109 Precision: 0.8000 Recall: 0.8109 Loss: 0.5002\n",
      "[Train] Class 0: Precision: 0.9792, Recall: 0.9868\n",
      "[Train] Class 1: Precision: 0.5966, Recall: 0.4633\n",
      "[Train] Class 2: Precision: 0.6861, Recall: 0.8465\n",
      "[Train] Class 3: Precision: 0.4471, Recall: 0.2468\n",
      "[Train] Class 4: Precision: 0.5882, Recall: 0.4274\n",
      "Evaluating: 100%|██████████| 92/92 [04:53<00:00,  3.19s/ batch]\n",
      "[Val] Kappa: 0.8743 Accuracy: 0.8225 Precision: 0.8184 Recall: 0.8225\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 92/92 [05:17<00:00,  3.45s/ batch, lr=1.0e-04, Loss=0.8391]\n",
      "[Train] Kappa: 0.8735 Accuracy: 0.8089 Precision: 0.7991 Recall: 0.8089 Loss: 0.5095\n",
      "[Train] Class 0: Precision: 0.9764, Recall: 0.9791\n",
      "[Train] Class 1: Precision: 0.6025, Recall: 0.4800\n",
      "[Train] Class 2: Precision: 0.6735, Recall: 0.8552\n",
      "[Train] Class 3: Precision: 0.4667, Recall: 0.1818\n",
      "[Train] Class 4: Precision: 0.6168, Recall: 0.4402\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.8649 Accuracy: 0.8007 Precision: 0.8206 Recall: 0.8007\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 92/92 [05:17<00:00,  3.45s/ batch, lr=1.0e-05, Loss=0.5965]\n",
      "[Train] Kappa: 0.8812 Accuracy: 0.8222 Precision: 0.8129 Recall: 0.8222 Loss: 0.4772\n",
      "[Train] Class 0: Precision: 0.9793, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6556, Recall: 0.5267\n",
      "[Train] Class 2: Precision: 0.7053, Recall: 0.8589\n",
      "[Train] Class 3: Precision: 0.4762, Recall: 0.3247\n",
      "[Train] Class 4: Precision: 0.5882, Recall: 0.3846\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.9149 Accuracy: 0.8546 Precision: 0.8532 Recall: 0.8546\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 92/92 [05:15<00:00,  3.43s/ batch, lr=1.0e-05, Loss=0.6296]\n",
      "[Train] Kappa: 0.8954 Accuracy: 0.8311 Precision: 0.8230 Recall: 0.8311 Loss: 0.4493\n",
      "[Train] Class 0: Precision: 0.9840, Recall: 0.9847\n",
      "[Train] Class 1: Precision: 0.6917, Recall: 0.5833\n",
      "[Train] Class 2: Precision: 0.7150, Recall: 0.8663\n",
      "[Train] Class 3: Precision: 0.4773, Recall: 0.2727\n",
      "[Train] Class 4: Precision: 0.6057, Recall: 0.4530\n",
      "Evaluating: 100%|██████████| 92/92 [04:50<00:00,  3.16s/ batch]\n",
      "[Val] Kappa: 0.9213 Accuracy: 0.8662 Precision: 0.8641 Recall: 0.8662\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 92/92 [05:18<00:00,  3.46s/ batch, lr=1.0e-05, Loss=0.4754]\n",
      "[Train] Kappa: 0.9009 Accuracy: 0.8447 Precision: 0.8392 Recall: 0.8447 Loss: 0.4314\n",
      "[Train] Class 0: Precision: 0.9854, Recall: 0.9895\n",
      "[Train] Class 1: Precision: 0.7063, Recall: 0.5933\n",
      "[Train] Class 2: Precision: 0.7302, Recall: 0.8775\n",
      "[Train] Class 3: Precision: 0.5745, Recall: 0.3506\n",
      "[Train] Class 4: Precision: 0.6647, Recall: 0.4915\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.9183 Accuracy: 0.8625 Precision: 0.8614 Recall: 0.8625\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 92/92 [05:18<00:00,  3.46s/ batch, lr=1.0e-05, Loss=0.3264]\n",
      "[Train] Kappa: 0.9118 Accuracy: 0.8491 Precision: 0.8428 Recall: 0.8491 Loss: 0.4252\n",
      "[Train] Class 0: Precision: 0.9874, Recall: 0.9874\n",
      "[Train] Class 1: Precision: 0.7184, Recall: 0.5867\n",
      "[Train] Class 2: Precision: 0.7376, Recall: 0.9010\n",
      "[Train] Class 3: Precision: 0.5301, Recall: 0.2857\n",
      "[Train] Class 4: Precision: 0.6851, Recall: 0.5299\n",
      "Evaluating: 100%|██████████| 92/92 [04:52<00:00,  3.18s/ batch]\n",
      "[Val] Kappa: 0.9222 Accuracy: 0.8662 Precision: 0.8664 Recall: 0.8662\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 92/92 [05:19<00:00,  3.48s/ batch, lr=1.0e-05, Loss=0.6844]\n",
      "[Train] Kappa: 0.9017 Accuracy: 0.8372 Precision: 0.8292 Recall: 0.8372 Loss: 0.4284\n",
      "[Train] Class 0: Precision: 0.9820, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6865, Recall: 0.5767\n",
      "[Train] Class 2: Precision: 0.7260, Recall: 0.8626\n",
      "[Train] Class 3: Precision: 0.5000, Recall: 0.2727\n",
      "[Train] Class 4: Precision: 0.6492, Recall: 0.5299\n",
      "Evaluating: 100%|██████████| 92/92 [04:54<00:00,  3.20s/ batch]\n",
      "[Val] Kappa: 0.9217 Accuracy: 0.8710 Precision: 0.8673 Recall: 0.8710\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 92/92 [05:20<00:00,  3.48s/ batch, lr=1.0e-05, Loss=0.2178]\n",
      "[Train] Kappa: 0.9151 Accuracy: 0.8584 Precision: 0.8538 Recall: 0.8584 Loss: 0.3913\n",
      "[Train] Class 0: Precision: 0.9868, Recall: 0.9874\n",
      "[Train] Class 1: Precision: 0.7191, Recall: 0.6400\n",
      "[Train] Class 2: Precision: 0.7566, Recall: 0.8849\n",
      "[Train] Class 3: Precision: 0.6203, Recall: 0.3182\n",
      "[Train] Class 4: Precision: 0.7010, Recall: 0.6111\n",
      "Evaluating: 100%|██████████| 92/92 [04:51<00:00,  3.17s/ batch]\n",
      "[Val] Kappa: 0.9235 Accuracy: 0.8717 Precision: 0.8689 Recall: 0.8717\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 92/92 [06:17<00:00,  4.10s/ batch, lr=1.0e-05, Loss=0.6686]\n",
      "[Train] Kappa: 0.9045 Accuracy: 0.8451 Precision: 0.8387 Recall: 0.8451 Loss: 0.4212\n",
      "[Train] Class 0: Precision: 0.9861, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.6875, Recall: 0.5867\n",
      "[Train] Class 2: Precision: 0.7334, Recall: 0.8750\n",
      "[Train] Class 3: Precision: 0.5488, Recall: 0.2922\n",
      "[Train] Class 4: Precision: 0.6842, Recall: 0.5556\n",
      "Evaluating: 100%|██████████| 92/92 [05:58<00:00,  3.90s/ batch]\n",
      "[Val] Kappa: 0.9206 Accuracy: 0.8747 Precision: 0.8742 Recall: 0.8747\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 92/92 [05:48<00:00,  3.79s/ batch, lr=1.0e-05, Loss=0.3898]\n",
      "[Train] Kappa: 0.9124 Accuracy: 0.8526 Precision: 0.8470 Recall: 0.8526 Loss: 0.4057\n",
      "[Train] Class 0: Precision: 0.9875, Recall: 0.9902\n",
      "[Train] Class 1: Precision: 0.6989, Recall: 0.6267\n",
      "[Train] Class 2: Precision: 0.7532, Recall: 0.8762\n",
      "[Train] Class 3: Precision: 0.5773, Recall: 0.3636\n",
      "[Train] Class 4: Precision: 0.6774, Recall: 0.5385\n",
      "Evaluating: 100%|██████████| 92/92 [04:57<00:00,  3.24s/ batch]\n",
      "[Val] Kappa: 0.9292 Accuracy: 0.8778 Precision: 0.8746 Recall: 0.8778\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 92/92 [05:18<00:00,  3.46s/ batch, lr=1.0e-05, Loss=0.1115]\n",
      "[Train] Kappa: 0.9079 Accuracy: 0.8515 Precision: 0.8461 Recall: 0.8515 Loss: 0.3897\n",
      "[Train] Class 0: Precision: 0.9875, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.7099, Recall: 0.6200\n",
      "[Train] Class 2: Precision: 0.7487, Recall: 0.8738\n",
      "[Train] Class 3: Precision: 0.5714, Recall: 0.3377\n",
      "[Train] Class 4: Precision: 0.6717, Recall: 0.5684\n",
      "Evaluating: 100%|██████████| 92/92 [04:53<00:00,  3.19s/ batch]\n",
      "[Val] Kappa: 0.9288 Accuracy: 0.8792 Precision: 0.8765 Recall: 0.8792\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 92/92 [05:18<00:00,  3.46s/ batch, lr=1.0e-05, Loss=0.7711]\n",
      "[Train] Kappa: 0.9187 Accuracy: 0.8648 Precision: 0.8599 Recall: 0.8648 Loss: 0.3848\n",
      "[Train] Class 0: Precision: 0.9909, Recall: 0.9923\n",
      "[Train] Class 1: Precision: 0.7656, Recall: 0.6533\n",
      "[Train] Class 2: Precision: 0.7634, Recall: 0.8985\n",
      "[Train] Class 3: Precision: 0.5824, Recall: 0.3442\n",
      "[Train] Class 4: Precision: 0.6939, Recall: 0.5812\n",
      "Evaluating: 100%|██████████| 92/92 [04:57<00:00,  3.23s/ batch]\n",
      "[Val] Kappa: 0.9304 Accuracy: 0.8850 Precision: 0.8841 Recall: 0.8850\n",
      "[Val] Best kappa: 0.9304, Epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path=\"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/resnet34_pth/model.pth\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Best [Val] Kappa: 0.9234 Accuracy: 0.8717 Precision: 0.8694 Recall: 0.8717 Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_test(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            #if test_only:\n",
    "            #    images = data\n",
    "            #else:\n",
    "            #    images, labels = data\n",
    "\n",
    "            images, labels = data\n",
    "            \n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                \"\"\"\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "                        \"\"\"\n",
    "\n",
    "            pbar.update(1)\n",
    "    \"\"\"\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        \"\"\"\n",
    "    metrics = compute_metrics(all_preds, all_labels)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_93383/4162799127.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(dict_path, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/test_images/test_images/\"\n",
    "test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/test.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dict_path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/resnet34_pth/model.pth'\n",
    "\n",
    "state_dict = torch.load(dict_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [00:35<00:00,  2.94s/ batch]\n"
     ]
    }
   ],
   "source": [
    "pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d/resnet34_pth/test_res.csv\"\n",
    "kappa, accuracy, precision, recall = evaluate_model_test(model, test_loader, device, test_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Kappa: 0.9294 Accuracy: 0.8607 Precision: 0.8640 Recall: 0.8607\n"
     ]
    }
   ],
   "source": [
    "print(f'[Test] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
