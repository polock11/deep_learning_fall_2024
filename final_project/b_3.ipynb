{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if img.mode != 'RGB':\n",
    "            raise ValueError(\"Input image must be in RGB mode\")\n",
    "        \n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            img_np = np.array(img)\n",
    "            \n",
    "            # Convert RGB to LAB (note OpenCV uses BGR but PIL uses RGB)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            \n",
    "            # Apply CLAHE to the L channel\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            \n",
    "            # Merge the channels back and convert back to RGB\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            \n",
    "            # Convert NumPy array back to PIL image\n",
    "            return Image.fromarray(img_np)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        #self.backbone = models.resnet34(pretrained=True)\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_60080/1516140836.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 50/50 [00:07<00:00,  6.64 batch/s, lr=1.0e-04, Loss=1.2450]\n",
      "[Train] Kappa: 0.6002 Accuracy: 0.4417 Precision: 0.4513 Recall: 0.4417 Loss: 1.6817\n",
      "[Train] Class 0: Precision: 0.5485, Recall: 0.6917\n",
      "[Train] Class 1: Precision: 0.4105, Recall: 0.3250\n",
      "[Train] Class 2: Precision: 0.3052, Recall: 0.4375\n",
      "[Train] Class 3: Precision: 0.5736, Recall: 0.3083\n",
      "[Train] Class 4: Precision: 0.2892, Recall: 0.2000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.07 batch/s]\n",
      "[Val] Kappa: 0.6172 Accuracy: 0.4925 Precision: 0.4100 Recall: 0.4925\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.58 batch/s, lr=1.0e-04, Loss=1.2435]\n",
      "[Train] Kappa: 0.6336 Accuracy: 0.4683 Precision: 0.4563 Recall: 0.4683 Loss: 1.2616\n",
      "[Train] Class 0: Precision: 0.6063, Recall: 0.6417\n",
      "[Train] Class 1: Precision: 0.3944, Recall: 0.3500\n",
      "[Train] Class 2: Precision: 0.3112, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.5390, Recall: 0.6042\n",
      "[Train] Class 4: Precision: 0.2549, Recall: 0.1083\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.60 batch/s]\n",
      "[Val] Kappa: 0.6143 Accuracy: 0.4900 Precision: 0.4190 Recall: 0.4900\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.61 batch/s, lr=1.0e-04, Loss=1.1269]\n",
      "[Train] Kappa: 0.6199 Accuracy: 0.4475 Precision: 0.4363 Recall: 0.4475 Loss: 1.2439\n",
      "[Train] Class 0: Precision: 0.5760, Recall: 0.6000\n",
      "[Train] Class 1: Precision: 0.3294, Recall: 0.3458\n",
      "[Train] Class 2: Precision: 0.3163, Recall: 0.2833\n",
      "[Train] Class 3: Precision: 0.4861, Recall: 0.6542\n",
      "[Train] Class 4: Precision: 0.3714, Recall: 0.1083\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.83 batch/s]\n",
      "[Val] Kappa: 0.6034 Accuracy: 0.4800 Precision: 0.4003 Recall: 0.4800\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.54 batch/s, lr=1.0e-04, Loss=1.1680]\n",
      "[Train] Kappa: 0.6165 Accuracy: 0.4650 Precision: 0.4535 Recall: 0.4650 Loss: 1.2486\n",
      "[Train] Class 0: Precision: 0.5711, Recall: 0.6361\n",
      "[Train] Class 1: Precision: 0.3578, Recall: 0.3250\n",
      "[Train] Class 2: Precision: 0.3267, Recall: 0.2750\n",
      "[Train] Class 3: Precision: 0.4897, Recall: 0.6958\n",
      "[Train] Class 4: Precision: 0.4737, Recall: 0.1500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.71 batch/s]\n",
      "[Val] Kappa: 0.6250 Accuracy: 0.4850 Precision: 0.3943 Recall: 0.4850\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.57 batch/s, lr=1.0e-04, Loss=1.0040]\n",
      "[Train] Kappa: 0.6391 Accuracy: 0.4783 Precision: 0.4528 Recall: 0.4783 Loss: 1.2146\n",
      "[Train] Class 0: Precision: 0.5912, Recall: 0.6750\n",
      "[Train] Class 1: Precision: 0.4121, Recall: 0.3417\n",
      "[Train] Class 2: Precision: 0.3364, Recall: 0.3083\n",
      "[Train] Class 3: Precision: 0.4970, Recall: 0.6875\n",
      "[Train] Class 4: Precision: 0.2632, Recall: 0.0833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.97 batch/s]\n",
      "[Val] Kappa: 0.6161 Accuracy: 0.4875 Precision: 0.4068 Recall: 0.4875\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.56 batch/s, lr=1.0e-04, Loss=1.0246]\n",
      "[Train] Kappa: 0.6443 Accuracy: 0.4967 Precision: 0.4721 Recall: 0.4967 Loss: 1.2132\n",
      "[Train] Class 0: Precision: 0.6063, Recall: 0.7528\n",
      "[Train] Class 1: Precision: 0.4331, Recall: 0.2833\n",
      "[Train] Class 2: Precision: 0.3761, Recall: 0.3542\n",
      "[Train] Class 3: Precision: 0.4752, Recall: 0.6792\n",
      "[Train] Class 4: Precision: 0.3333, Recall: 0.0750\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.92 batch/s]\n",
      "[Val] Kappa: 0.6642 Accuracy: 0.4975 Precision: 0.4231 Recall: 0.4975\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.54 batch/s, lr=1.0e-04, Loss=1.3378]\n",
      "[Train] Kappa: 0.6576 Accuracy: 0.5108 Precision: 0.4897 Recall: 0.5108 Loss: 1.1673\n",
      "[Train] Class 0: Precision: 0.6219, Recall: 0.7583\n",
      "[Train] Class 1: Precision: 0.4481, Recall: 0.3417\n",
      "[Train] Class 2: Precision: 0.3713, Recall: 0.3125\n",
      "[Train] Class 3: Precision: 0.4928, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.4074, Recall: 0.0917\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.70 batch/s]\n",
      "[Val] Kappa: 0.6753 Accuracy: 0.5075 Precision: 0.4077 Recall: 0.5075\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.56 batch/s, lr=1.0e-04, Loss=1.3025]\n",
      "[Train] Kappa: 0.6694 Accuracy: 0.5158 Precision: 0.4923 Recall: 0.5158 Loss: 1.1645\n",
      "[Train] Class 0: Precision: 0.6475, Recall: 0.7500\n",
      "[Train] Class 1: Precision: 0.4067, Recall: 0.3542\n",
      "[Train] Class 2: Precision: 0.3606, Recall: 0.3125\n",
      "[Train] Class 3: Precision: 0.5231, Recall: 0.7542\n",
      "[Train] Class 4: Precision: 0.4000, Recall: 0.0667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.60 batch/s]\n",
      "[Val] Kappa: 0.6772 Accuracy: 0.5075 Precision: 0.3955 Recall: 0.5075\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.57 batch/s, lr=1.0e-04, Loss=1.2005]\n",
      "[Train] Kappa: 0.6890 Accuracy: 0.5342 Precision: 0.5140 Recall: 0.5342 Loss: 1.1383\n",
      "[Train] Class 0: Precision: 0.6315, Recall: 0.7806\n",
      "[Train] Class 1: Precision: 0.4481, Recall: 0.2875\n",
      "[Train] Class 2: Precision: 0.4201, Recall: 0.3833\n",
      "[Train] Class 3: Precision: 0.5272, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.4545, Recall: 0.1250\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.69 batch/s]\n",
      "[Val] Kappa: 0.6874 Accuracy: 0.5225 Precision: 0.4377 Recall: 0.5225\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.56 batch/s, lr=1.0e-04, Loss=1.1728]\n",
      "[Train] Kappa: 0.6899 Accuracy: 0.5150 Precision: 0.4767 Recall: 0.5150 Loss: 1.1510\n",
      "[Train] Class 0: Precision: 0.6480, Recall: 0.8028\n",
      "[Train] Class 1: Precision: 0.4070, Recall: 0.3375\n",
      "[Train] Class 2: Precision: 0.3858, Recall: 0.3167\n",
      "[Train] Class 3: Precision: 0.4985, Recall: 0.6917\n",
      "[Train] Class 4: Precision: 0.2400, Recall: 0.0500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.52 batch/s]\n",
      "[Val] Kappa: 0.7076 Accuracy: 0.5375 Precision: 0.4560 Recall: 0.5375\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 50/50 [00:07<00:00,  7.10 batch/s, lr=1.0e-05, Loss=1.2439]\n",
      "[Train] Kappa: 0.7000 Accuracy: 0.5392 Precision: 0.5089 Recall: 0.5392 Loss: 1.1186\n",
      "[Train] Class 0: Precision: 0.6813, Recall: 0.8194\n",
      "[Train] Class 1: Precision: 0.4597, Recall: 0.4042\n",
      "[Train] Class 2: Precision: 0.3957, Recall: 0.3083\n",
      "[Train] Class 3: Precision: 0.5059, Recall: 0.7125\n",
      "[Train] Class 4: Precision: 0.3226, Recall: 0.0833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.72 batch/s]\n",
      "[Val] Kappa: 0.7275 Accuracy: 0.5525 Precision: 0.4744 Recall: 0.5525\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.46 batch/s, lr=1.0e-05, Loss=1.0411]\n",
      "[Train] Kappa: 0.6997 Accuracy: 0.5250 Precision: 0.4923 Recall: 0.5250 Loss: 1.1224\n",
      "[Train] Class 0: Precision: 0.6729, Recall: 0.8000\n",
      "[Train] Class 1: Precision: 0.4462, Recall: 0.3625\n",
      "[Train] Class 2: Precision: 0.4009, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.4969, Recall: 0.6583\n",
      "[Train] Class 4: Precision: 0.2162, Recall: 0.0667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.87 batch/s]\n",
      "[Val] Kappa: 0.7235 Accuracy: 0.5450 Precision: 0.4720 Recall: 0.5450\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.54 batch/s, lr=1.0e-05, Loss=1.0590]\n",
      "[Train] Kappa: 0.6713 Accuracy: 0.5275 Precision: 0.5052 Recall: 0.5275 Loss: 1.1331\n",
      "[Train] Class 0: Precision: 0.6419, Recall: 0.7667\n",
      "[Train] Class 1: Precision: 0.4462, Recall: 0.3458\n",
      "[Train] Class 2: Precision: 0.4204, Recall: 0.3958\n",
      "[Train] Class 3: Precision: 0.5090, Recall: 0.7083\n",
      "[Train] Class 4: Precision: 0.3750, Recall: 0.0750\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.98 batch/s]\n",
      "[Val] Kappa: 0.7250 Accuracy: 0.5400 Precision: 0.4607 Recall: 0.5400\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.55 batch/s, lr=1.0e-05, Loss=1.1123]\n",
      "[Train] Kappa: 0.7177 Accuracy: 0.5467 Precision: 0.5207 Recall: 0.5467 Loss: 1.1118\n",
      "[Train] Class 0: Precision: 0.6854, Recall: 0.7806\n",
      "[Train] Class 1: Precision: 0.4976, Recall: 0.4292\n",
      "[Train] Class 2: Precision: 0.4218, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.5000, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.3125, Recall: 0.0417\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.94 batch/s]\n",
      "[Val] Kappa: 0.7287 Accuracy: 0.5475 Precision: 0.4726 Recall: 0.5475\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.55 batch/s, lr=1.0e-05, Loss=1.1048]\n",
      "[Train] Kappa: 0.6850 Accuracy: 0.5292 Precision: 0.5024 Recall: 0.5292 Loss: 1.1169\n",
      "[Train] Class 0: Precision: 0.6452, Recall: 0.7778\n",
      "[Train] Class 1: Precision: 0.4270, Recall: 0.3292\n",
      "[Train] Class 2: Precision: 0.4384, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.5057, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.3462, Recall: 0.0750\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.53 batch/s]\n",
      "[Val] Kappa: 0.7402 Accuracy: 0.5525 Precision: 0.4860 Recall: 0.5525\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.42 batch/s, lr=1.0e-05, Loss=0.9156]\n",
      "[Train] Kappa: 0.7157 Accuracy: 0.5408 Precision: 0.5063 Recall: 0.5408 Loss: 1.0997\n",
      "[Train] Class 0: Precision: 0.6737, Recall: 0.7972\n",
      "[Train] Class 1: Precision: 0.4604, Recall: 0.3875\n",
      "[Train] Class 2: Precision: 0.3889, Recall: 0.3500\n",
      "[Train] Class 3: Precision: 0.5325, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.2778, Recall: 0.0417\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.62 batch/s]\n",
      "[Val] Kappa: 0.7319 Accuracy: 0.5550 Precision: 0.4902 Recall: 0.5550\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.44 batch/s, lr=1.0e-05, Loss=1.1106]\n",
      "[Train] Kappa: 0.6865 Accuracy: 0.5200 Precision: 0.4880 Recall: 0.5200 Loss: 1.1361\n",
      "[Train] Class 0: Precision: 0.6706, Recall: 0.7861\n",
      "[Train] Class 1: Precision: 0.4422, Recall: 0.3667\n",
      "[Train] Class 2: Precision: 0.3687, Recall: 0.3333\n",
      "[Train] Class 3: Precision: 0.4926, Recall: 0.6958\n",
      "[Train] Class 4: Precision: 0.2609, Recall: 0.0500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.79 batch/s]\n",
      "[Val] Kappa: 0.7278 Accuracy: 0.5450 Precision: 0.4736 Recall: 0.5450\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.53 batch/s, lr=1.0e-05, Loss=1.1325]\n",
      "[Train] Kappa: 0.7064 Accuracy: 0.5442 Precision: 0.5222 Recall: 0.5442 Loss: 1.1150\n",
      "[Train] Class 0: Precision: 0.6566, Recall: 0.7861\n",
      "[Train] Class 1: Precision: 0.4286, Recall: 0.3500\n",
      "[Train] Class 2: Precision: 0.4352, Recall: 0.3917\n",
      "[Train] Class 3: Precision: 0.5449, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.4348, Recall: 0.0833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.73 batch/s]\n",
      "[Val] Kappa: 0.7269 Accuracy: 0.5450 Precision: 0.4803 Recall: 0.5450\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.50 batch/s, lr=1.0e-05, Loss=1.4132]\n",
      "[Train] Kappa: 0.7053 Accuracy: 0.5300 Precision: 0.5058 Recall: 0.5300 Loss: 1.0997\n",
      "[Train] Class 0: Precision: 0.6621, Recall: 0.8000\n",
      "[Train] Class 1: Precision: 0.4663, Recall: 0.3458\n",
      "[Train] Class 2: Precision: 0.3689, Recall: 0.3458\n",
      "[Train] Class 3: Precision: 0.5103, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.3810, Recall: 0.0667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.61 batch/s]\n",
      "[Val] Kappa: 0.7412 Accuracy: 0.5650 Precision: 0.5003 Recall: 0.5650\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 50/50 [00:06<00:00,  7.49 batch/s, lr=1.0e-05, Loss=1.4365]\n",
      "[Train] Kappa: 0.7154 Accuracy: 0.5458 Precision: 0.5033 Recall: 0.5458 Loss: 1.0947\n",
      "[Train] Class 0: Precision: 0.6912, Recall: 0.8333\n",
      "[Train] Class 1: Precision: 0.4837, Recall: 0.3708\n",
      "[Train] Class 2: Precision: 0.3761, Recall: 0.3417\n",
      "[Train] Class 3: Precision: 0.5248, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.1905, Recall: 0.0333\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.61 batch/s]\n",
      "[Val] Kappa: 0.7252 Accuracy: 0.5550 Precision: 0.4940 Recall: 0.5550\n",
      "[Val] Best kappa: 0.7412, Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_60080/1516140836.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.11 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/b_3_train_with_DeepDiR_pred.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    state_dict = torch.load(state_dict_path, map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Freeze all layers except the final fully connected (fc) layer\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Ensure only the `fc` layer is trainable\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    # Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/b_3_train_with_DeepDiR.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/b_3_train_with_DeepDiR.pth'\n",
    "    state_dict = torch.load(path, map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    prediction_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/b_3_train_with_DeepDiR_pred.csv\"\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=prediction_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
