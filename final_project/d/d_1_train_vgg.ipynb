{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['id_code'] = os.path.join(self.image_dir, row['id_code'])\n",
    "            if not self.test:\n",
    "                file_info['diagnosis'] = int(row['diagnosis'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['id_code']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['diagnosis'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.vgg16(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1000, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            \n",
    "            \n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                \"\"\"\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "                        \"\"\"\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5  # 5 DR levels\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 20\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_images/train_images/\"\n",
    "train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/train_1.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/val_images/val_images/\"\n",
    "val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/valid.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "val_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training: 100%|██████████| 123/123 [06:51<00:00,  3.35s/ batch, lr=1.0e-04, Loss=0.2255]\n",
      "[Train] Kappa: 0.5624 Accuracy: 0.6495 Precision: 0.5761 Recall: 0.6495 Loss: 0.9727\n",
      "[Train] Class 0: Precision: 0.8107, Recall: 0.9079\n",
      "[Train] Class 1: Precision: 0.1839, Recall: 0.0533\n",
      "[Train] Class 2: Precision: 0.5071, Recall: 0.7042\n",
      "[Train] Class 3: Precision: 0.2000, Recall: 0.0260\n",
      "[Train] Class 4: Precision: 0.1263, Recall: 0.0513\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.7914 Accuracy: 0.7488 Precision: 0.6614 Recall: 0.7488\n",
      "\n",
      "Epoch 2/20\n",
      "Training: 100%|██████████| 123/123 [06:44<00:00,  3.29s/ batch, lr=1.0e-04, Loss=0.6977]\n",
      "[Train] Kappa: 0.7712 Accuracy: 0.7365 Precision: 0.6853 Recall: 0.7365 Loss: 0.7473\n",
      "[Train] Class 0: Precision: 0.9462, Recall: 0.9693\n",
      "[Train] Class 1: Precision: 0.3361, Recall: 0.1333\n",
      "[Train] Class 2: Precision: 0.5553, Recall: 0.8824\n",
      "[Train] Class 3: Precision: 0.2500, Recall: 0.0519\n",
      "[Train] Class 4: Precision: 0.2692, Recall: 0.0299\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.7801 Accuracy: 0.7549 Precision: 0.6579 Recall: 0.7549\n",
      "\n",
      "Epoch 3/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4122]\n",
      "[Train] Kappa: 0.7727 Accuracy: 0.7338 Precision: 0.6829 Recall: 0.7338 Loss: 0.7252\n",
      "[Train] Class 0: Precision: 0.9386, Recall: 0.9693\n",
      "[Train] Class 1: Precision: 0.4046, Recall: 0.1767\n",
      "[Train] Class 2: Precision: 0.5569, Recall: 0.8540\n",
      "[Train] Class 3: Precision: 0.2143, Recall: 0.0584\n",
      "[Train] Class 4: Precision: 0.2162, Recall: 0.0342\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8105 Accuracy: 0.7604 Precision: 0.6839 Recall: 0.7604\n",
      "\n",
      "Epoch 4/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.2521]\n",
      "[Train] Kappa: 0.8073 Accuracy: 0.7444 Precision: 0.7038 Recall: 0.7444 Loss: 0.6740\n",
      "[Train] Class 0: Precision: 0.9608, Recall: 0.9735\n",
      "[Train] Class 1: Precision: 0.3862, Recall: 0.1867\n",
      "[Train] Class 2: Precision: 0.5675, Recall: 0.8738\n",
      "[Train] Class 3: Precision: 0.2222, Recall: 0.0779\n",
      "[Train] Class 4: Precision: 0.3235, Recall: 0.0470\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8058 Accuracy: 0.7655 Precision: 0.6904 Recall: 0.7655\n",
      "\n",
      "Epoch 5/20\n",
      "Training: 100%|██████████| 123/123 [06:46<00:00,  3.30s/ batch, lr=1.0e-04, Loss=1.2156]\n",
      "[Train] Kappa: 0.8101 Accuracy: 0.7563 Precision: 0.7295 Recall: 0.7563 Loss: 0.6364\n",
      "[Train] Class 0: Precision: 0.9677, Recall: 0.9812\n",
      "[Train] Class 1: Precision: 0.4637, Recall: 0.2767\n",
      "[Train] Class 2: Precision: 0.5735, Recall: 0.8639\n",
      "[Train] Class 3: Precision: 0.2917, Recall: 0.0909\n",
      "[Train] Class 4: Precision: 0.4375, Recall: 0.0598\n",
      "Evaluating: 100%|██████████| 123/123 [05:17<00:00,  2.58s/ batch]\n",
      "[Val] Kappa: 0.8285 Accuracy: 0.7840 Precision: 0.7280 Recall: 0.7840\n",
      "\n",
      "Epoch 6/20\n",
      "Training: 100%|██████████| 123/123 [06:46<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.0385]\n",
      "[Train] Kappa: 0.8126 Accuracy: 0.7560 Precision: 0.7250 Recall: 0.7560 Loss: 0.6581\n",
      "[Train] Class 0: Precision: 0.9567, Recall: 0.9707\n",
      "[Train] Class 1: Precision: 0.4502, Recall: 0.3467\n",
      "[Train] Class 2: Precision: 0.6086, Recall: 0.8391\n",
      "[Train] Class 3: Precision: 0.2987, Recall: 0.1494\n",
      "[Train] Class 4: Precision: 0.3396, Recall: 0.0769\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8321 Accuracy: 0.7765 Precision: 0.7824 Recall: 0.7765\n",
      "\n",
      "Epoch 7/20\n",
      "Training: 100%|██████████| 123/123 [06:47<00:00,  3.31s/ batch, lr=1.0e-04, Loss=0.9733]\n",
      "[Train] Kappa: 0.8210 Accuracy: 0.7532 Precision: 0.7221 Recall: 0.7532 Loss: 0.6313\n",
      "[Train] Class 0: Precision: 0.9664, Recall: 0.9819\n",
      "[Train] Class 1: Precision: 0.4049, Recall: 0.2200\n",
      "[Train] Class 2: Precision: 0.5906, Recall: 0.8391\n",
      "[Train] Class 3: Precision: 0.2698, Recall: 0.1104\n",
      "[Train] Class 4: Precision: 0.3838, Recall: 0.1624\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8339 Accuracy: 0.7795 Precision: 0.7234 Recall: 0.7795\n",
      "\n",
      "Epoch 8/20\n",
      "Training: 100%|██████████| 123/123 [06:47<00:00,  3.31s/ batch, lr=1.0e-04, Loss=0.3618]\n",
      "[Train] Kappa: 0.8344 Accuracy: 0.7700 Precision: 0.7488 Recall: 0.7700 Loss: 0.5840\n",
      "[Train] Class 0: Precision: 0.9750, Recall: 0.9791\n",
      "[Train] Class 1: Precision: 0.4844, Recall: 0.3633\n",
      "[Train] Class 2: Precision: 0.6122, Recall: 0.8441\n",
      "[Train] Class 3: Precision: 0.3800, Recall: 0.1234\n",
      "[Train] Class 4: Precision: 0.4158, Recall: 0.1795\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8657 Accuracy: 0.7980 Precision: 0.7893 Recall: 0.7980\n",
      "\n",
      "Epoch 9/20\n",
      "Training: 100%|██████████| 123/123 [06:47<00:00,  3.31s/ batch, lr=1.0e-04, Loss=0.1300]\n",
      "[Train] Kappa: 0.8159 Accuracy: 0.7621 Precision: 0.7341 Recall: 0.7621 Loss: 0.6175\n",
      "[Train] Class 0: Precision: 0.9521, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.5258, Recall: 0.3400\n",
      "[Train] Class 2: Precision: 0.6072, Recall: 0.8168\n",
      "[Train] Class 3: Precision: 0.2885, Recall: 0.0974\n",
      "[Train] Class 4: Precision: 0.3966, Recall: 0.1966\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8680 Accuracy: 0.7911 Precision: 0.7854 Recall: 0.7911\n",
      "\n",
      "Epoch 10/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-04, Loss=0.4949]\n",
      "[Train] Kappa: 0.8555 Accuracy: 0.7836 Precision: 0.7651 Recall: 0.7836 Loss: 0.5608\n",
      "[Train] Class 0: Precision: 0.9792, Recall: 0.9861\n",
      "[Train] Class 1: Precision: 0.5401, Recall: 0.4267\n",
      "[Train] Class 2: Precision: 0.6363, Recall: 0.8292\n",
      "[Train] Class 3: Precision: 0.3279, Recall: 0.1299\n",
      "[Train] Class 4: Precision: 0.4741, Recall: 0.2735\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8808 Accuracy: 0.8044 Precision: 0.7745 Recall: 0.8044\n",
      "\n",
      "Epoch 11/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.3335]\n",
      "[Train] Kappa: 0.8791 Accuracy: 0.8130 Precision: 0.8011 Recall: 0.8130 Loss: 0.5021\n",
      "[Train] Class 0: Precision: 0.9861, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6592, Recall: 0.4900\n",
      "[Train] Class 2: Precision: 0.6733, Recall: 0.8775\n",
      "[Train] Class 3: Precision: 0.3816, Recall: 0.1883\n",
      "[Train] Class 4: Precision: 0.5674, Recall: 0.3419\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8895 Accuracy: 0.8184 Precision: 0.7817 Recall: 0.8184\n",
      "\n",
      "Epoch 12/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-05, Loss=1.1050]\n",
      "[Train] Kappa: 0.8786 Accuracy: 0.8075 Precision: 0.7938 Recall: 0.8075 Loss: 0.4964\n",
      "[Train] Class 0: Precision: 0.9854, Recall: 0.9868\n",
      "[Train] Class 1: Precision: 0.5939, Recall: 0.5167\n",
      "[Train] Class 2: Precision: 0.6901, Recall: 0.8490\n",
      "[Train] Class 3: Precision: 0.3636, Recall: 0.2078\n",
      "[Train] Class 4: Precision: 0.5166, Recall: 0.3333\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8894 Accuracy: 0.8249 Precision: 0.7866 Recall: 0.8249\n",
      "\n",
      "Epoch 13/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-05, Loss=2.1840]\n",
      "[Train] Kappa: 0.8870 Accuracy: 0.8072 Precision: 0.7923 Recall: 0.8072 Loss: 0.5098\n",
      "[Train] Class 0: Precision: 0.9895, Recall: 0.9902\n",
      "[Train] Class 1: Precision: 0.6250, Recall: 0.4667\n",
      "[Train] Class 2: Precision: 0.6774, Recall: 0.8626\n",
      "[Train] Class 3: Precision: 0.2963, Recall: 0.1558\n",
      "[Train] Class 4: Precision: 0.5217, Recall: 0.3590\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8928 Accuracy: 0.8294 Precision: 0.7906 Recall: 0.8294\n",
      "\n",
      "Epoch 14/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.30s/ batch, lr=1.0e-05, Loss=0.0000]\n",
      "[Train] Kappa: 0.8876 Accuracy: 0.8160 Precision: 0.8002 Recall: 0.8160 Loss: 0.4863\n",
      "[Train] Class 0: Precision: 0.9868, Recall: 0.9895\n",
      "[Train] Class 1: Precision: 0.6307, Recall: 0.5067\n",
      "[Train] Class 2: Precision: 0.6871, Recall: 0.8725\n",
      "[Train] Class 3: Precision: 0.3393, Recall: 0.1234\n",
      "[Train] Class 4: Precision: 0.5680, Recall: 0.4103\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8991 Accuracy: 0.8362 Precision: 0.8513 Recall: 0.8362\n",
      "\n",
      "Epoch 15/20\n",
      "Training: 100%|██████████| 123/123 [06:45<00:00,  3.29s/ batch, lr=1.0e-05, Loss=0.2839]\n",
      "[Train] Kappa: 0.8913 Accuracy: 0.8215 Precision: 0.8092 Recall: 0.8215 Loss: 0.4735\n",
      "[Train] Class 0: Precision: 0.9855, Recall: 0.9930\n",
      "[Train] Class 1: Precision: 0.6695, Recall: 0.5200\n",
      "[Train] Class 2: Precision: 0.6975, Recall: 0.8676\n",
      "[Train] Class 3: Precision: 0.4051, Recall: 0.2078\n",
      "[Train] Class 4: Precision: 0.5595, Recall: 0.4017\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8928 Accuracy: 0.8273 Precision: 0.8271 Recall: 0.8273\n",
      "\n",
      "Epoch 16/20\n",
      "Training: 100%|██████████| 123/123 [06:44<00:00,  3.29s/ batch, lr=1.0e-05, Loss=0.1913]\n",
      "[Train] Kappa: 0.8878 Accuracy: 0.8099 Precision: 0.7952 Recall: 0.8099 Loss: 0.4836\n",
      "[Train] Class 0: Precision: 0.9888, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.6245, Recall: 0.5267\n",
      "[Train] Class 2: Precision: 0.6843, Recall: 0.8502\n",
      "[Train] Class 3: Precision: 0.2593, Recall: 0.1364\n",
      "[Train] Class 4: Precision: 0.5633, Recall: 0.3803\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8907 Accuracy: 0.8324 Precision: 0.8307 Recall: 0.8324\n",
      "\n",
      "Epoch 17/20\n",
      "Training: 100%|██████████| 123/123 [06:42<00:00,  3.27s/ batch, lr=1.0e-05, Loss=0.3634]\n",
      "[Train] Kappa: 0.8942 Accuracy: 0.8239 Precision: 0.8129 Recall: 0.8239 Loss: 0.4605\n",
      "[Train] Class 0: Precision: 0.9909, Recall: 0.9888\n",
      "[Train] Class 1: Precision: 0.6560, Recall: 0.5467\n",
      "[Train] Class 2: Precision: 0.6954, Recall: 0.8700\n",
      "[Train] Class 3: Precision: 0.3836, Recall: 0.1818\n",
      "[Train] Class 4: Precision: 0.6121, Recall: 0.4316\n",
      "Evaluating: 100%|██████████| 123/123 [05:14<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8991 Accuracy: 0.8358 Precision: 0.8250 Recall: 0.8358\n",
      "\n",
      "Epoch 18/20\n",
      "Training: 100%|██████████| 123/123 [06:40<00:00,  3.26s/ batch, lr=1.0e-05, Loss=0.6738]\n",
      "[Train] Kappa: 0.8925 Accuracy: 0.8218 Precision: 0.8099 Recall: 0.8218 Loss: 0.4671\n",
      "[Train] Class 0: Precision: 0.9854, Recall: 0.9881\n",
      "[Train] Class 1: Precision: 0.6653, Recall: 0.5300\n",
      "[Train] Class 2: Precision: 0.6950, Recall: 0.8800\n",
      "[Train] Class 3: Precision: 0.3766, Recall: 0.1883\n",
      "[Train] Class 4: Precision: 0.6013, Recall: 0.3932\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.56s/ batch]\n",
      "[Val] Kappa: 0.8902 Accuracy: 0.8287 Precision: 0.8196 Recall: 0.8287\n",
      "\n",
      "Epoch 19/20\n",
      "Training: 100%|██████████| 123/123 [06:43<00:00,  3.28s/ batch, lr=1.0e-05, Loss=0.0192]\n",
      "[Train] Kappa: 0.8962 Accuracy: 0.8253 Precision: 0.8143 Recall: 0.8253 Loss: 0.4644\n",
      "[Train] Class 0: Precision: 0.9881, Recall: 0.9874\n",
      "[Train] Class 1: Precision: 0.6395, Recall: 0.5500\n",
      "[Train] Class 2: Precision: 0.7045, Recall: 0.8762\n",
      "[Train] Class 3: Precision: 0.3797, Recall: 0.1948\n",
      "[Train] Class 4: Precision: 0.6387, Recall: 0.4231\n",
      "Evaluating: 100%|██████████| 123/123 [05:15<00:00,  2.57s/ batch]\n",
      "[Val] Kappa: 0.8977 Accuracy: 0.8389 Precision: 0.8314 Recall: 0.8389\n",
      "\n",
      "Epoch 20/20\n",
      "Training: 100%|██████████| 123/123 [06:42<00:00,  3.27s/ batch, lr=1.0e-05, Loss=0.0011]\n",
      "[Train] Kappa: 0.8964 Accuracy: 0.8218 Precision: 0.8076 Recall: 0.8218 Loss: 0.4500\n",
      "[Train] Class 0: Precision: 0.9882, Recall: 0.9916\n",
      "[Train] Class 1: Precision: 0.6398, Recall: 0.5567\n",
      "[Train] Class 2: Precision: 0.6989, Recall: 0.8589\n",
      "[Train] Class 3: Precision: 0.3235, Recall: 0.1429\n",
      "[Train] Class 4: Precision: 0.6095, Recall: 0.4402\n",
      "Evaluating: 100%|██████████| 123/123 [05:13<00:00,  2.55s/ batch]\n",
      "[Val] Kappa: 0.9065 Accuracy: 0.8471 Precision: 0.8395 Recall: 0.8471\n",
      "[Val] Best kappa: 0.9065, Epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "#for param in model.backbone.parameters():\n",
    "#    param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path=\"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d_2/vgg_16/model.pth\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Best [Val] Kappa: 0.9234 Accuracy: 0.8717 Precision: 0.8694 Recall: 0.8717 Epoch 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_test(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            #if test_only:\n",
    "            #    images = data\n",
    "            #else:\n",
    "            #    images, labels = data\n",
    "\n",
    "            images, labels = data\n",
    "            \n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                \"\"\"\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "                        \"\"\"\n",
    "\n",
    "            pbar.update(1)\n",
    "    \"\"\"\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        \"\"\"\n",
    "    metrics = compute_metrics(all_preds, all_labels)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_10576/682570878.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(dict_path, map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/test_images/test_images/\"\n",
    "test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/APTOS/test.csv\"\n",
    "mode = 'single'\n",
    "\n",
    "test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dict_path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d_2/vgg_16/model.pth'\n",
    "\n",
    "state_dict = torch.load(dict_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [00:38<00:00,  3.23s/ batch]\n"
     ]
    }
   ],
   "source": [
    "pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_d_2/preditcions.csv\"\n",
    "kappa, accuracy, precision, recall = evaluate_model_test(model, test_loader, device, test_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] Kappa: 0.9011 Accuracy: 0.8306 Precision: 0.8303 Recall: 0.8306\n"
     ]
    }
   ],
   "source": [
    "print(f'[Test] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
