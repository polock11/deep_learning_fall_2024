{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levelsA\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        eval_loss, val_metrics = evaluate_model(model, val_loader, device,criterion)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model, train_losses, eval_losses\n",
    "\n",
    "def evaluate_model(model, test_loader, device, criterion, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "    eval_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            if not test_only:\n",
    "                labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                if not test_only:\n",
    "                    # Calculate loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    eval_loss += loss.item() * labels.size(0)\n",
    "                    total_samples += labels.size(0)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        eval_loss /= total_samples  # Calculate mean loss\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return eval_loss, metrics\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\"\"\"\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_85502/2275422289.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.80 batch/s, lr=1.0e-04, Loss=1.2770]\n",
      "[Train] Kappa: 0.6277 Accuracy: 0.4758 Precision: 0.4754 Recall: 0.4758 Loss: 1.5237\n",
      "[Train] Class 0: Precision: 0.6747, Recall: 0.7028\n",
      "[Train] Class 1: Precision: 0.3885, Recall: 0.4208\n",
      "[Train] Class 2: Precision: 0.3474, Recall: 0.4458\n",
      "[Train] Class 3: Precision: 0.5281, Recall: 0.3917\n",
      "[Train] Class 4: Precision: 0.2025, Recall: 0.1333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.97 batch/s]\n",
      "[Val] Kappa: 0.7342 Accuracy: 0.5900 Precision: 0.5407 Recall: 0.5900\n",
      "\n",
      "Epoch 2/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.92 batch/s, lr=1.0e-04, Loss=0.9695]\n",
      "[Train] Kappa: 0.7484 Accuracy: 0.5783 Precision: 0.5453 Recall: 0.5783 Loss: 1.0606\n",
      "[Train] Class 0: Precision: 0.7750, Recall: 0.8611\n",
      "[Train] Class 1: Precision: 0.4875, Recall: 0.4875\n",
      "[Train] Class 2: Precision: 0.3946, Recall: 0.3667\n",
      "[Train] Class 3: Precision: 0.5566, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.2500, Recall: 0.0583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.70 batch/s]\n",
      "[Val] Kappa: 0.7742 Accuracy: 0.5850 Precision: 0.5646 Recall: 0.5850\n",
      "\n",
      "Epoch 3/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.81 batch/s, lr=1.0e-04, Loss=0.8742]\n",
      "[Train] Kappa: 0.7631 Accuracy: 0.6033 Precision: 0.5825 Recall: 0.6033 Loss: 0.9994\n",
      "[Train] Class 0: Precision: 0.7906, Recall: 0.8917\n",
      "[Train] Class 1: Precision: 0.5242, Recall: 0.4958\n",
      "[Train] Class 2: Precision: 0.4338, Recall: 0.3958\n",
      "[Train] Class 3: Precision: 0.5719, Recall: 0.6958\n",
      "[Train] Class 4: Precision: 0.3929, Recall: 0.1833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.62 batch/s]\n",
      "[Val] Kappa: 0.7508 Accuracy: 0.5325 Precision: 0.5254 Recall: 0.5325\n",
      "\n",
      "Epoch 4/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.93 batch/s, lr=1.0e-04, Loss=0.9070]\n",
      "[Train] Kappa: 0.7841 Accuracy: 0.6033 Precision: 0.5837 Recall: 0.6033 Loss: 0.9490\n",
      "[Train] Class 0: Precision: 0.8020, Recall: 0.8889\n",
      "[Train] Class 1: Precision: 0.5144, Recall: 0.5208\n",
      "[Train] Class 2: Precision: 0.4425, Recall: 0.4167\n",
      "[Train] Class 3: Precision: 0.5699, Recall: 0.6625\n",
      "[Train] Class 4: Precision: 0.3774, Recall: 0.1667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.08 batch/s]\n",
      "[Val] Kappa: 0.8001 Accuracy: 0.6425 Precision: 0.5946 Recall: 0.6425\n",
      "\n",
      "Epoch 5/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.94 batch/s, lr=1.0e-04, Loss=0.7323]\n",
      "[Train] Kappa: 0.7875 Accuracy: 0.6100 Precision: 0.5949 Recall: 0.6100 Loss: 0.9223\n",
      "[Train] Class 0: Precision: 0.8184, Recall: 0.9139\n",
      "[Train] Class 1: Precision: 0.5323, Recall: 0.5500\n",
      "[Train] Class 2: Precision: 0.4120, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.5524, Recall: 0.6583\n",
      "[Train] Class 4: Precision: 0.5000, Recall: 0.2000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.48 batch/s]\n",
      "[Val] Kappa: 0.7763 Accuracy: 0.6175 Precision: 0.5677 Recall: 0.6175\n",
      "\n",
      "Epoch 6/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.90 batch/s, lr=1.0e-04, Loss=0.9333]\n",
      "[Train] Kappa: 0.8135 Accuracy: 0.6550 Precision: 0.6466 Recall: 0.6550 Loss: 0.8636\n",
      "[Train] Class 0: Precision: 0.8557, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.6422, Recall: 0.6208\n",
      "[Train] Class 2: Precision: 0.4500, Recall: 0.4500\n",
      "[Train] Class 3: Precision: 0.5755, Recall: 0.6667\n",
      "[Train] Class 4: Precision: 0.5636, Recall: 0.2583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.89 batch/s]\n",
      "[Val] Kappa: 0.7937 Accuracy: 0.6075 Precision: 0.6817 Recall: 0.6075\n",
      "\n",
      "Epoch 7/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.96 batch/s, lr=1.0e-04, Loss=1.0398]\n",
      "[Train] Kappa: 0.8197 Accuracy: 0.6458 Precision: 0.6394 Recall: 0.6458 Loss: 0.8626\n",
      "[Train] Class 0: Precision: 0.8291, Recall: 0.9167\n",
      "[Train] Class 1: Precision: 0.6053, Recall: 0.5750\n",
      "[Train] Class 2: Precision: 0.4454, Recall: 0.4417\n",
      "[Train] Class 3: Precision: 0.5951, Recall: 0.7042\n",
      "[Train] Class 4: Precision: 0.6154, Recall: 0.2667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.62 batch/s]\n",
      "[Val] Kappa: 0.7913 Accuracy: 0.6200 Precision: 0.5859 Recall: 0.6200\n",
      "\n",
      "Epoch 8/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.01 batch/s, lr=1.0e-04, Loss=0.8440]\n",
      "[Train] Kappa: 0.8039 Accuracy: 0.6675 Precision: 0.6583 Recall: 0.6675 Loss: 0.8609\n",
      "[Train] Class 0: Precision: 0.8267, Recall: 0.9278\n",
      "[Train] Class 1: Precision: 0.6447, Recall: 0.6125\n",
      "[Train] Class 2: Precision: 0.4807, Recall: 0.4667\n",
      "[Train] Class 3: Precision: 0.6310, Recall: 0.6625\n",
      "[Train] Class 4: Precision: 0.5904, Recall: 0.4083\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 10.41 batch/s]\n",
      "[Val] Kappa: 0.8006 Accuracy: 0.6675 Precision: 0.7024 Recall: 0.6675\n",
      "\n",
      "Epoch 9/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.96 batch/s, lr=1.0e-04, Loss=1.0982]\n",
      "[Train] Kappa: 0.8129 Accuracy: 0.6817 Precision: 0.6725 Recall: 0.6817 Loss: 0.8165\n",
      "[Train] Class 0: Precision: 0.8354, Recall: 0.9167\n",
      "[Train] Class 1: Precision: 0.6532, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5398, Recall: 0.5083\n",
      "[Train] Class 3: Precision: 0.6331, Recall: 0.6542\n",
      "[Train] Class 4: Precision: 0.5663, Recall: 0.3917\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.81 batch/s]\n",
      "[Val] Kappa: 0.7970 Accuracy: 0.6625 Precision: 0.5937 Recall: 0.6625\n",
      "\n",
      "Epoch 10/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.91 batch/s, lr=1.0e-04, Loss=1.0983]\n",
      "[Train] Kappa: 0.8066 Accuracy: 0.6742 Precision: 0.6630 Recall: 0.6742 Loss: 0.8240\n",
      "[Train] Class 0: Precision: 0.8465, Recall: 0.9194\n",
      "[Train] Class 1: Precision: 0.6446, Recall: 0.6500\n",
      "[Train] Class 2: Precision: 0.4978, Recall: 0.4750\n",
      "[Train] Class 3: Precision: 0.6327, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.5397, Recall: 0.2833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.48 batch/s]\n",
      "[Val] Kappa: 0.8062 Accuracy: 0.6700 Precision: 0.7109 Recall: 0.6700\n",
      "\n",
      "Epoch 11/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.94 batch/s, lr=1.0e-05, Loss=0.9118]\n",
      "[Train] Kappa: 0.8365 Accuracy: 0.7100 Precision: 0.7055 Recall: 0.7100 Loss: 0.7807\n",
      "[Train] Class 0: Precision: 0.8415, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.7220, Recall: 0.6708\n",
      "[Train] Class 2: Precision: 0.5168, Recall: 0.5125\n",
      "[Train] Class 3: Precision: 0.6614, Recall: 0.6917\n",
      "[Train] Class 4: Precision: 0.7308, Recall: 0.4750\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.88 batch/s]\n",
      "[Val] Kappa: 0.7797 Accuracy: 0.6650 Precision: 0.6985 Recall: 0.6650\n",
      "\n",
      "Epoch 12/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.00 batch/s, lr=1.0e-05, Loss=0.5548]\n",
      "[Train] Kappa: 0.8425 Accuracy: 0.7158 Precision: 0.7058 Recall: 0.7158 Loss: 0.7424\n",
      "[Train] Class 0: Precision: 0.8596, Recall: 0.9528\n",
      "[Train] Class 1: Precision: 0.6920, Recall: 0.6833\n",
      "[Train] Class 2: Precision: 0.5887, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.6693, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.5789, Recall: 0.3667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 10.41 batch/s]\n",
      "[Val] Kappa: 0.7983 Accuracy: 0.6700 Precision: 0.7032 Recall: 0.6700\n",
      "\n",
      "Epoch 13/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.98 batch/s, lr=1.0e-05, Loss=0.5298]\n",
      "[Train] Kappa: 0.8469 Accuracy: 0.7242 Precision: 0.7204 Recall: 0.7242 Loss: 0.7408\n",
      "[Train] Class 0: Precision: 0.8529, Recall: 0.9500\n",
      "[Train] Class 1: Precision: 0.7013, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5808, Recall: 0.5542\n",
      "[Train] Class 3: Precision: 0.6691, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.7429, Recall: 0.4333\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.66 batch/s]\n",
      "[Val] Kappa: 0.7759 Accuracy: 0.6725 Precision: 0.7053 Recall: 0.6725\n",
      "\n",
      "Epoch 14/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.89 batch/s, lr=1.0e-05, Loss=0.5289]\n",
      "[Train] Kappa: 0.8615 Accuracy: 0.7350 Precision: 0.7327 Recall: 0.7350 Loss: 0.6992\n",
      "[Train] Class 0: Precision: 0.8756, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.6809, Recall: 0.6667\n",
      "[Train] Class 2: Precision: 0.5826, Recall: 0.5875\n",
      "[Train] Class 3: Precision: 0.7148, Recall: 0.7833\n",
      "[Train] Class 4: Precision: 0.7432, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.58 batch/s]\n",
      "[Val] Kappa: 0.7812 Accuracy: 0.6825 Precision: 0.7105 Recall: 0.6825\n",
      "\n",
      "Epoch 15/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.92 batch/s, lr=1.0e-05, Loss=0.7311]\n",
      "[Train] Kappa: 0.8628 Accuracy: 0.7275 Precision: 0.7193 Recall: 0.7275 Loss: 0.6892\n",
      "[Train] Class 0: Precision: 0.8665, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7049, Recall: 0.7167\n",
      "[Train] Class 2: Precision: 0.6232, Recall: 0.5375\n",
      "[Train] Class 3: Precision: 0.6520, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.6329, Recall: 0.4167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.34 batch/s]\n",
      "[Val] Kappa: 0.8007 Accuracy: 0.6725 Precision: 0.7083 Recall: 0.6725\n",
      "\n",
      "Epoch 16/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.95 batch/s, lr=1.0e-05, Loss=0.7951]\n",
      "[Train] Kappa: 0.8586 Accuracy: 0.7300 Precision: 0.7254 Recall: 0.7300 Loss: 0.6953\n",
      "[Train] Class 0: Precision: 0.8871, Recall: 0.9389\n",
      "[Train] Class 1: Precision: 0.6761, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.5907, Recall: 0.5833\n",
      "[Train] Class 3: Precision: 0.6980, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.6625, Recall: 0.4417\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.64 batch/s]\n",
      "[Val] Kappa: 0.7837 Accuracy: 0.6650 Precision: 0.6981 Recall: 0.6650\n",
      "\n",
      "Epoch 17/25\n",
      "Training: 100%|██████████| 50/50 [00:18<00:00,  2.74 batch/s, lr=1.0e-05, Loss=0.6259]\n",
      "[Train] Kappa: 0.8640 Accuracy: 0.7450 Precision: 0.7408 Recall: 0.7450 Loss: 0.6941\n",
      "[Train] Class 0: Precision: 0.8650, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7345, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6111, Recall: 0.5958\n",
      "[Train] Class 3: Precision: 0.6943, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.7333, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.82 batch/s]\n",
      "[Val] Kappa: 0.7873 Accuracy: 0.6800 Precision: 0.7084 Recall: 0.6800\n",
      "\n",
      "Epoch 18/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.88 batch/s, lr=1.0e-05, Loss=0.6169]\n",
      "[Train] Kappa: 0.8616 Accuracy: 0.7425 Precision: 0.7375 Recall: 0.7425 Loss: 0.6983\n",
      "[Train] Class 0: Precision: 0.8737, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7364, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5785, Recall: 0.5833\n",
      "[Train] Class 3: Precision: 0.7188, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.6860, Recall: 0.4917\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.77 batch/s]\n",
      "[Val] Kappa: 0.7881 Accuracy: 0.6775 Precision: 0.7077 Recall: 0.6775\n",
      "\n",
      "Epoch 19/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.97 batch/s, lr=1.0e-05, Loss=0.8172]\n",
      "[Train] Kappa: 0.8522 Accuracy: 0.7342 Precision: 0.7273 Recall: 0.7342 Loss: 0.6763\n",
      "[Train] Class 0: Precision: 0.8483, Recall: 0.9472\n",
      "[Train] Class 1: Precision: 0.7071, Recall: 0.7042\n",
      "[Train] Class 2: Precision: 0.6037, Recall: 0.5458\n",
      "[Train] Class 3: Precision: 0.7008, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.7051, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.90 batch/s]\n",
      "[Val] Kappa: 0.7849 Accuracy: 0.6775 Precision: 0.7084 Recall: 0.6775\n",
      "\n",
      "Epoch 20/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.94 batch/s, lr=1.0e-05, Loss=0.8167]\n",
      "[Train] Kappa: 0.8638 Accuracy: 0.7383 Precision: 0.7334 Recall: 0.7383 Loss: 0.6984\n",
      "[Train] Class 0: Precision: 0.8766, Recall: 0.9472\n",
      "[Train] Class 1: Precision: 0.7167, Recall: 0.7167\n",
      "[Train] Class 2: Precision: 0.6261, Recall: 0.5792\n",
      "[Train] Class 3: Precision: 0.6667, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.6849, Recall: 0.4167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.64 batch/s]\n",
      "[Val] Kappa: 0.7838 Accuracy: 0.6800 Precision: 0.7112 Recall: 0.6800\n",
      "\n",
      "Epoch 21/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.95 batch/s, lr=1.0e-06, Loss=0.8199]\n",
      "[Train] Kappa: 0.8665 Accuracy: 0.7408 Precision: 0.7358 Recall: 0.7408 Loss: 0.6542\n",
      "[Train] Class 0: Precision: 0.8728, Recall: 0.9528\n",
      "[Train] Class 1: Precision: 0.7339, Recall: 0.6667\n",
      "[Train] Class 2: Precision: 0.6073, Recall: 0.6250\n",
      "[Train] Class 3: Precision: 0.7031, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.6512, Recall: 0.4667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.79 batch/s]\n",
      "[Val] Kappa: 0.7799 Accuracy: 0.6800 Precision: 0.7102 Recall: 0.6800\n",
      "\n",
      "Epoch 22/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.93 batch/s, lr=1.0e-06, Loss=0.9566]\n",
      "[Train] Kappa: 0.8528 Accuracy: 0.7408 Precision: 0.7341 Recall: 0.7408 Loss: 0.6890\n",
      "[Train] Class 0: Precision: 0.8582, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.7523, Recall: 0.6833\n",
      "[Train] Class 2: Precision: 0.6214, Recall: 0.6292\n",
      "[Train] Class 3: Precision: 0.7073, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.6044, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.81 batch/s]\n",
      "[Val] Kappa: 0.7938 Accuracy: 0.6825 Precision: 0.7140 Recall: 0.6825\n",
      "\n",
      "Epoch 23/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.87 batch/s, lr=1.0e-06, Loss=0.5736]\n",
      "[Train] Kappa: 0.8612 Accuracy: 0.7483 Precision: 0.7416 Recall: 0.7483 Loss: 0.6675\n",
      "[Train] Class 0: Precision: 0.8665, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7313, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6303, Recall: 0.6250\n",
      "[Train] Class 3: Precision: 0.7251, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.6437, Recall: 0.4667\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.82 batch/s]\n",
      "[Val] Kappa: 0.7818 Accuracy: 0.6875 Precision: 0.7160 Recall: 0.6875\n",
      "\n",
      "Epoch 24/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.86 batch/s, lr=1.0e-06, Loss=0.7424]\n",
      "[Train] Kappa: 0.8692 Accuracy: 0.7517 Precision: 0.7491 Recall: 0.7517 Loss: 0.6792\n",
      "[Train] Class 0: Precision: 0.8686, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.6935, Recall: 0.7167\n",
      "[Train] Class 2: Precision: 0.6228, Recall: 0.5917\n",
      "[Train] Class 3: Precision: 0.7362, Recall: 0.7792\n",
      "[Train] Class 4: Precision: 0.7805, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.03 batch/s]\n",
      "[Val] Kappa: 0.7680 Accuracy: 0.6825 Precision: 0.7082 Recall: 0.6825\n",
      "\n",
      "Epoch 25/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.95 batch/s, lr=1.0e-06, Loss=0.5005]\n",
      "[Train] Kappa: 0.8688 Accuracy: 0.7475 Precision: 0.7418 Recall: 0.7475 Loss: 0.6519\n",
      "[Train] Class 0: Precision: 0.8880, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7227, Recall: 0.6625\n",
      "[Train] Class 2: Precision: 0.6186, Recall: 0.6083\n",
      "[Train] Class 3: Precision: 0.6988, Recall: 0.7542\n",
      "[Train] Class 4: Precision: 0.6739, Recall: 0.5167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.23 batch/s]\n",
      "[Val] Kappa: 0.7905 Accuracy: 0.6800 Precision: 0.7137 Recall: 0.6800\n",
      "[Val] Best kappa: 0.8062, Epoch 10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    state_dict = torch.load(state_dict_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # # Freeze all layers except the final fully connected (fc) layer\n",
    "    # for param in model.backbone.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # # Ensure only the `fc` layer is trainable\n",
    "    # for param in model.fc.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    #Train and evaluate the model with the training and validation set\n",
    "    model, train_loss, eval_loss = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path= '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD_for_losses.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    # state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD.pth', map_location='cpu')\n",
    "    # model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # # Make predictions on testing set and save the prediction results\n",
    "    # pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_aptos_model_predictions.csv\"\n",
    "    # evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = pd.DataFrame({\n",
    "    'train_loss': train_loss,\n",
    "    'eval_loss': eval_loss\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(loss['train_loss'], label='Train Loss')\n",
    "plt.plot(loss['eval_loss'], label='Eval Loss')\n",
    "plt.title('Loss Curve ResNet18')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
