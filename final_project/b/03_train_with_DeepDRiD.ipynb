{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levelsA\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_47996/143302317.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.96 batch/s, lr=1.0e-04, Loss=0.8666]\n",
      "[Train] Kappa: 0.6292 Accuracy: 0.4817 Precision: 0.4802 Recall: 0.4817 Loss: 1.5124\n",
      "[Train] Class 0: Precision: 0.6777, Recall: 0.7361\n",
      "[Train] Class 1: Precision: 0.4106, Recall: 0.3542\n",
      "[Train] Class 2: Precision: 0.3186, Recall: 0.4208\n",
      "[Train] Class 3: Precision: 0.5124, Recall: 0.4292\n",
      "[Train] Class 4: Precision: 0.2857, Recall: 0.2000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.33 batch/s]\n",
      "[Val] Kappa: 0.7506 Accuracy: 0.6025 Precision: 0.5515 Recall: 0.6025\n",
      "\n",
      "Epoch 2/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.02 batch/s, lr=1.0e-04, Loss=0.8648]\n",
      "[Train] Kappa: 0.7470 Accuracy: 0.5592 Precision: 0.5373 Recall: 0.5592 Loss: 1.0649\n",
      "[Train] Class 0: Precision: 0.7849, Recall: 0.8111\n",
      "[Train] Class 1: Precision: 0.4597, Recall: 0.4750\n",
      "[Train] Class 2: Precision: 0.3985, Recall: 0.4500\n",
      "[Train] Class 3: Precision: 0.5415, Recall: 0.6250\n",
      "[Train] Class 4: Precision: 0.2188, Recall: 0.0583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.77 batch/s]\n",
      "[Val] Kappa: 0.7666 Accuracy: 0.6075 Precision: 0.5796 Recall: 0.6075\n",
      "\n",
      "Epoch 3/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.04 batch/s, lr=1.0e-04, Loss=1.0163]\n",
      "[Train] Kappa: 0.7591 Accuracy: 0.5850 Precision: 0.5627 Recall: 0.5850 Loss: 0.9855\n",
      "[Train] Class 0: Precision: 0.7965, Recall: 0.8806\n",
      "[Train] Class 1: Precision: 0.5405, Recall: 0.5000\n",
      "[Train] Class 2: Precision: 0.3860, Recall: 0.3667\n",
      "[Train] Class 3: Precision: 0.5258, Recall: 0.6792\n",
      "[Train] Class 4: Precision: 0.3333, Recall: 0.1167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.64 batch/s]\n",
      "[Val] Kappa: 0.7664 Accuracy: 0.5750 Precision: 0.6610 Recall: 0.5750\n",
      "\n",
      "Epoch 4/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.97 batch/s, lr=1.0e-04, Loss=0.8071]\n",
      "[Train] Kappa: 0.7718 Accuracy: 0.6192 Precision: 0.6066 Recall: 0.6192 Loss: 0.9652\n",
      "[Train] Class 0: Precision: 0.7897, Recall: 0.8972\n",
      "[Train] Class 1: Precision: 0.5500, Recall: 0.5042\n",
      "[Train] Class 2: Precision: 0.4571, Recall: 0.4667\n",
      "[Train] Class 3: Precision: 0.5984, Recall: 0.6333\n",
      "[Train] Class 4: Precision: 0.4861, Recall: 0.2917\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.78 batch/s]\n",
      "[Val] Kappa: 0.7773 Accuracy: 0.6075 Precision: 0.5708 Recall: 0.6075\n",
      "\n",
      "Epoch 5/25\n",
      "Training: 100%|██████████| 50/50 [00:17<00:00,  2.91 batch/s, lr=1.0e-04, Loss=0.9449]\n",
      "[Train] Kappa: 0.7989 Accuracy: 0.6208 Precision: 0.6133 Recall: 0.6208 Loss: 0.9358\n",
      "[Train] Class 0: Precision: 0.8165, Recall: 0.8778\n",
      "[Train] Class 1: Precision: 0.5040, Recall: 0.5292\n",
      "[Train] Class 2: Precision: 0.4795, Recall: 0.4375\n",
      "[Train] Class 3: Precision: 0.5812, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.5538, Recall: 0.3000\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.65 batch/s]\n",
      "[Val] Kappa: 0.7965 Accuracy: 0.6550 Precision: 0.6980 Recall: 0.6550\n",
      "\n",
      "Epoch 6/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.02 batch/s, lr=1.0e-04, Loss=0.9655]\n",
      "[Train] Kappa: 0.8238 Accuracy: 0.6633 Precision: 0.6575 Recall: 0.6633 Loss: 0.8494\n",
      "[Train] Class 0: Precision: 0.8444, Recall: 0.9194\n",
      "[Train] Class 1: Precision: 0.6390, Recall: 0.5458\n",
      "[Train] Class 2: Precision: 0.4844, Recall: 0.5167\n",
      "[Train] Class 3: Precision: 0.6168, Recall: 0.7042\n",
      "[Train] Class 4: Precision: 0.5616, Recall: 0.3417\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.90 batch/s]\n",
      "[Val] Kappa: 0.7991 Accuracy: 0.6550 Precision: 0.7039 Recall: 0.6550\n",
      "\n",
      "Epoch 7/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.02 batch/s, lr=1.0e-04, Loss=0.7578]\n",
      "[Train] Kappa: 0.8050 Accuracy: 0.6692 Precision: 0.6570 Recall: 0.6692 Loss: 0.8491\n",
      "[Train] Class 0: Precision: 0.8439, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.6416, Recall: 0.6042\n",
      "[Train] Class 2: Precision: 0.5000, Recall: 0.4708\n",
      "[Train] Class 3: Precision: 0.5941, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.5672, Recall: 0.3167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.94 batch/s]\n",
      "[Val] Kappa: 0.8093 Accuracy: 0.6825 Precision: 0.7153 Recall: 0.6825\n",
      "\n",
      "Epoch 8/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.11 batch/s, lr=1.0e-04, Loss=0.8992]\n",
      "[Train] Kappa: 0.7996 Accuracy: 0.6600 Precision: 0.6483 Recall: 0.6600 Loss: 0.8841\n",
      "[Train] Class 0: Precision: 0.8342, Recall: 0.9222\n",
      "[Train] Class 1: Precision: 0.5992, Recall: 0.6042\n",
      "[Train] Class 2: Precision: 0.4937, Recall: 0.4917\n",
      "[Train] Class 3: Precision: 0.6570, Recall: 0.6625\n",
      "[Train] Class 4: Precision: 0.4810, Recall: 0.3167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.98 batch/s]\n",
      "[Val] Kappa: 0.7743 Accuracy: 0.6525 Precision: 0.6496 Recall: 0.6525\n",
      "\n",
      "Epoch 9/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.12 batch/s, lr=1.0e-04, Loss=1.0024]\n",
      "[Train] Kappa: 0.8425 Accuracy: 0.7000 Precision: 0.6946 Recall: 0.7000 Loss: 0.8108\n",
      "[Train] Class 0: Precision: 0.8456, Recall: 0.9278\n",
      "[Train] Class 1: Precision: 0.6967, Recall: 0.6125\n",
      "[Train] Class 2: Precision: 0.5473, Recall: 0.5542\n",
      "[Train] Class 3: Precision: 0.6540, Recall: 0.7167\n",
      "[Train] Class 4: Precision: 0.6136, Recall: 0.4500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.97 batch/s]\n",
      "[Val] Kappa: 0.7885 Accuracy: 0.6575 Precision: 0.6897 Recall: 0.6575\n",
      "\n",
      "Epoch 10/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.11 batch/s, lr=1.0e-04, Loss=0.8767]\n",
      "[Train] Kappa: 0.8317 Accuracy: 0.6933 Precision: 0.6828 Recall: 0.6933 Loss: 0.7961\n",
      "[Train] Class 0: Precision: 0.8568, Recall: 0.9472\n",
      "[Train] Class 1: Precision: 0.6667, Recall: 0.6583\n",
      "[Train] Class 2: Precision: 0.5289, Recall: 0.4958\n",
      "[Train] Class 3: Precision: 0.6510, Recall: 0.6917\n",
      "[Train] Class 4: Precision: 0.5647, Recall: 0.4000\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.60 batch/s]\n",
      "[Val] Kappa: 0.7829 Accuracy: 0.6375 Precision: 0.7025 Recall: 0.6375\n",
      "\n",
      "Epoch 11/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.11 batch/s, lr=1.0e-05, Loss=0.4848]\n",
      "[Train] Kappa: 0.8276 Accuracy: 0.7083 Precision: 0.6989 Recall: 0.7083 Loss: 0.7421\n",
      "[Train] Class 0: Precision: 0.8374, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.6943, Recall: 0.6625\n",
      "[Train] Class 2: Precision: 0.5678, Recall: 0.5583\n",
      "[Train] Class 3: Precision: 0.6667, Recall: 0.7000\n",
      "[Train] Class 4: Precision: 0.6197, Recall: 0.3667\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.93 batch/s]\n",
      "[Val] Kappa: 0.7925 Accuracy: 0.6625 Precision: 0.6879 Recall: 0.6625\n",
      "\n",
      "Epoch 12/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.13 batch/s, lr=1.0e-05, Loss=0.7618]\n",
      "[Train] Kappa: 0.8423 Accuracy: 0.7233 Precision: 0.7214 Recall: 0.7233 Loss: 0.7306\n",
      "[Train] Class 0: Precision: 0.8518, Recall: 0.9417\n",
      "[Train] Class 1: Precision: 0.7074, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5726, Recall: 0.5583\n",
      "[Train] Class 3: Precision: 0.6703, Recall: 0.7625\n",
      "[Train] Class 4: Precision: 0.7576, Recall: 0.4167\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.96 batch/s]\n",
      "[Val] Kappa: 0.7692 Accuracy: 0.6575 Precision: 0.6802 Recall: 0.6575\n",
      "\n",
      "Epoch 13/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.12 batch/s, lr=1.0e-05, Loss=0.7732]\n",
      "[Train] Kappa: 0.8450 Accuracy: 0.7333 Precision: 0.7266 Recall: 0.7333 Loss: 0.6974\n",
      "[Train] Class 0: Precision: 0.8709, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7078, Recall: 0.7167\n",
      "[Train] Class 2: Precision: 0.5819, Recall: 0.5625\n",
      "[Train] Class 3: Precision: 0.7016, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.6707, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.94 batch/s]\n",
      "[Val] Kappa: 0.7856 Accuracy: 0.6575 Precision: 0.6809 Recall: 0.6575\n",
      "\n",
      "Epoch 14/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.01 batch/s, lr=1.0e-05, Loss=0.7677]\n",
      "[Train] Kappa: 0.8498 Accuracy: 0.7250 Precision: 0.7199 Recall: 0.7250 Loss: 0.7178\n",
      "[Train] Class 0: Precision: 0.8662, Recall: 0.9528\n",
      "[Train] Class 1: Precision: 0.7167, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.5983, Recall: 0.5833\n",
      "[Train] Class 3: Precision: 0.6468, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.6765, Recall: 0.3833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.79 batch/s]\n",
      "[Val] Kappa: 0.7863 Accuracy: 0.6550 Precision: 0.6822 Recall: 0.6550\n",
      "\n",
      "Epoch 15/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.94 batch/s, lr=1.0e-05, Loss=0.4669]\n",
      "[Train] Kappa: 0.8572 Accuracy: 0.7358 Precision: 0.7304 Recall: 0.7358 Loss: 0.6905\n",
      "[Train] Class 0: Precision: 0.8786, Recall: 0.9444\n",
      "[Train] Class 1: Precision: 0.7161, Recall: 0.7042\n",
      "[Train] Class 2: Precision: 0.6121, Recall: 0.5917\n",
      "[Train] Class 3: Precision: 0.6783, Recall: 0.7292\n",
      "[Train] Class 4: Precision: 0.6552, Recall: 0.4750\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.11 batch/s]\n",
      "[Val] Kappa: 0.7948 Accuracy: 0.6650 Precision: 0.6902 Recall: 0.6650\n",
      "\n",
      "Epoch 16/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.02 batch/s, lr=1.0e-05, Loss=0.9422]\n",
      "[Train] Kappa: 0.8763 Accuracy: 0.7550 Precision: 0.7510 Recall: 0.7550 Loss: 0.6445\n",
      "[Train] Class 0: Precision: 0.8897, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.7467, Recall: 0.7125\n",
      "[Train] Class 2: Precision: 0.6025, Recall: 0.6000\n",
      "[Train] Class 3: Precision: 0.7115, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.7195, Recall: 0.4917\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.28 batch/s]\n",
      "[Val] Kappa: 0.7866 Accuracy: 0.6600 Precision: 0.6847 Recall: 0.6600\n",
      "\n",
      "Epoch 17/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.08 batch/s, lr=1.0e-05, Loss=0.7165]\n",
      "[Train] Kappa: 0.8498 Accuracy: 0.7333 Precision: 0.7266 Recall: 0.7333 Loss: 0.7010\n",
      "[Train] Class 0: Precision: 0.8675, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.6824, Recall: 0.6625\n",
      "[Train] Class 2: Precision: 0.5940, Recall: 0.5792\n",
      "[Train] Class 3: Precision: 0.7120, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.6867, Recall: 0.4750\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.40 batch/s]\n",
      "[Val] Kappa: 0.7797 Accuracy: 0.6650 Precision: 0.6875 Recall: 0.6650\n",
      "\n",
      "Epoch 18/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.13 batch/s, lr=1.0e-05, Loss=0.6071]\n",
      "[Train] Kappa: 0.8607 Accuracy: 0.7558 Precision: 0.7523 Recall: 0.7558 Loss: 0.6538\n",
      "[Train] Class 0: Precision: 0.8706, Recall: 0.9528\n",
      "[Train] Class 1: Precision: 0.7422, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.6298, Recall: 0.6167\n",
      "[Train] Class 3: Precision: 0.7132, Recall: 0.7875\n",
      "[Train] Class 4: Precision: 0.7407, Recall: 0.5000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.44 batch/s]\n",
      "[Val] Kappa: 0.8066 Accuracy: 0.6675 Precision: 0.6863 Recall: 0.6675\n",
      "\n",
      "Epoch 19/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.95 batch/s, lr=1.0e-05, Loss=0.7508]\n",
      "[Train] Kappa: 0.8574 Accuracy: 0.7308 Precision: 0.7242 Recall: 0.7308 Loss: 0.6684\n",
      "[Train] Class 0: Precision: 0.8687, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7085, Recall: 0.6583\n",
      "[Train] Class 2: Precision: 0.5983, Recall: 0.5708\n",
      "[Train] Class 3: Precision: 0.6877, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.6465, Recall: 0.5333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.30 batch/s]\n",
      "[Val] Kappa: 0.7937 Accuracy: 0.6700 Precision: 0.6817 Recall: 0.6700\n",
      "\n",
      "Epoch 20/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  2.96 batch/s, lr=1.0e-05, Loss=0.6971]\n",
      "[Train] Kappa: 0.8581 Accuracy: 0.7450 Precision: 0.7383 Recall: 0.7450 Loss: 0.6797\n",
      "[Train] Class 0: Precision: 0.8872, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7179, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.6147, Recall: 0.5917\n",
      "[Train] Class 3: Precision: 0.7092, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.6383, Recall: 0.5000\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.77 batch/s]\n",
      "[Val] Kappa: 0.8167 Accuracy: 0.6875 Precision: 0.6989 Recall: 0.6875\n",
      "\n",
      "Epoch 21/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.14 batch/s, lr=1.0e-06, Loss=0.3481]\n",
      "[Train] Kappa: 0.8652 Accuracy: 0.7525 Precision: 0.7454 Recall: 0.7525 Loss: 0.6510\n",
      "[Train] Class 0: Precision: 0.8832, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.7155, Recall: 0.6917\n",
      "[Train] Class 2: Precision: 0.6368, Recall: 0.6208\n",
      "[Train] Class 3: Precision: 0.7186, Recall: 0.7875\n",
      "[Train] Class 4: Precision: 0.6623, Recall: 0.4250\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.41 batch/s]\n",
      "[Val] Kappa: 0.8155 Accuracy: 0.6650 Precision: 0.6842 Recall: 0.6650\n",
      "\n",
      "Epoch 22/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.22 batch/s, lr=1.0e-06, Loss=0.4772]\n",
      "[Train] Kappa: 0.8727 Accuracy: 0.7417 Precision: 0.7357 Recall: 0.7417 Loss: 0.6574\n",
      "[Train] Class 0: Precision: 0.8709, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.7105, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.6167, Recall: 0.5833\n",
      "[Train] Class 3: Precision: 0.6985, Recall: 0.7917\n",
      "[Train] Class 4: Precision: 0.6923, Recall: 0.4500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.65 batch/s]\n",
      "[Val] Kappa: 0.8158 Accuracy: 0.6825 Precision: 0.6946 Recall: 0.6825\n",
      "\n",
      "Epoch 23/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.19 batch/s, lr=1.0e-06, Loss=0.9150]\n",
      "[Train] Kappa: 0.8781 Accuracy: 0.7525 Precision: 0.7475 Recall: 0.7525 Loss: 0.6521\n",
      "[Train] Class 0: Precision: 0.8849, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7368, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.6189, Recall: 0.6292\n",
      "[Train] Class 3: Precision: 0.7148, Recall: 0.7625\n",
      "[Train] Class 4: Precision: 0.6790, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.43 batch/s]\n",
      "[Val] Kappa: 0.8083 Accuracy: 0.6750 Precision: 0.6954 Recall: 0.6750\n",
      "\n",
      "Epoch 24/25\n",
      "Training: 100%|██████████| 50/50 [00:16<00:00,  3.06 batch/s, lr=1.0e-06, Loss=0.4035]\n",
      "[Train] Kappa: 0.8673 Accuracy: 0.7617 Precision: 0.7582 Recall: 0.7617 Loss: 0.6462\n",
      "[Train] Class 0: Precision: 0.8756, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.7682, Recall: 0.7042\n",
      "[Train] Class 2: Precision: 0.6240, Recall: 0.6500\n",
      "[Train] Class 3: Precision: 0.7368, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.6966, Recall: 0.5167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.17 batch/s]\n",
      "[Val] Kappa: 0.8050 Accuracy: 0.6625 Precision: 0.6845 Recall: 0.6625\n",
      "\n",
      "Epoch 25/25\n",
      "Training: 100%|██████████| 50/50 [00:15<00:00,  3.14 batch/s, lr=1.0e-06, Loss=0.5103]\n",
      "[Train] Kappa: 0.8550 Accuracy: 0.7550 Precision: 0.7490 Recall: 0.7550 Loss: 0.6611\n",
      "[Train] Class 0: Precision: 0.8804, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7466, Recall: 0.6875\n",
      "[Train] Class 2: Precision: 0.6420, Recall: 0.6500\n",
      "[Train] Class 3: Precision: 0.7160, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.6395, Recall: 0.4583\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.82 batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_47996/143302317.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val] Kappa: 0.7954 Accuracy: 0.6650 Precision: 0.6725 Recall: 0.6650\n",
      "[Val] Best kappa: 0.8167, Epoch 20\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.58 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_aptos_model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    state_dict = torch.load(state_dict_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # # Freeze all layers except the final fully connected (fc) layer\n",
    "    # for param in model.backbone.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # # Ensure only the `fc` layer is trainable\n",
    "    # for param in model.fc.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    #Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path= '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_aptos_model_predictions.csv\"\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
