{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 32\n",
    "num_classes = 5  # 5 DR levelsA\n",
    "learning_rate = 0.001\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class GaussianBlur:\n",
    "    def __init__(self, kernel_size=(5, 5), sigma=(0.1, 2.0)):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply Gaussian Blur with 50% probability\n",
    "            return transforms.functional.gaussian_blur(img, kernel_size=self.kernel_size, sigma=random.uniform(*self.sigma))\n",
    "        return img\n",
    "\n",
    "\n",
    "class CLAHE:\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:  # Apply CLAHE with 50% probability\n",
    "            img_np = np.array(img)\n",
    "            img_lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(img_lab)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            l = clahe.apply(l)\n",
    "            img_lab = cv2.merge((l, a, b))\n",
    "            img_np = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)\n",
    "            return Image.fromarray(img_np)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),  # Add Gaussian Blur\n",
    "    CLAHE(clip_limit=2.0, tile_grid_size=(8, 8)),  # Add CLAHE for enhanced contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.AutoAugment(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\"\"\"\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_53738/2017720590.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/25\n",
      "Training: 100%|██████████| 38/38 [00:21<00:00,  1.80 batch/s, lr=5.0e-04, Loss=1.3475]\n",
      "[Train] Kappa: 0.5659 Accuracy: 0.4742 Precision: 0.4463 Recall: 0.4742 Loss: 1.4076\n",
      "[Train] Class 0: Precision: 0.6692, Recall: 0.7250\n",
      "[Train] Class 1: Precision: 0.3880, Recall: 0.4042\n",
      "[Train] Class 2: Precision: 0.3045, Recall: 0.3375\n",
      "[Train] Class 3: Precision: 0.4669, Recall: 0.5292\n",
      "[Train] Class 4: Precision: 0.1364, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.34 batch/s]\n",
      "[Val] Kappa: 0.6468 Accuracy: 0.5600 Precision: 0.5081 Recall: 0.5600\n",
      "\n",
      "Epoch 2/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.23 batch/s, lr=5.0e-04, Loss=1.0364]\n",
      "[Train] Kappa: 0.7200 Accuracy: 0.5508 Precision: 0.5164 Recall: 0.5508 Loss: 1.1137\n",
      "[Train] Class 0: Precision: 0.7589, Recall: 0.8833\n",
      "[Train] Class 1: Precision: 0.5193, Recall: 0.3917\n",
      "[Train] Class 2: Precision: 0.3655, Recall: 0.3792\n",
      "[Train] Class 3: Precision: 0.4681, Recall: 0.6417\n",
      "[Train] Class 4: Precision: 0.1818, Recall: 0.0333\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.59 batch/s]\n",
      "[Val] Kappa: 0.7181 Accuracy: 0.5875 Precision: 0.5275 Recall: 0.5875\n",
      "\n",
      "Epoch 3/25\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.35 batch/s, lr=5.0e-04, Loss=1.7669]\n",
      "[Train] Kappa: 0.7192 Accuracy: 0.5783 Precision: 0.5392 Recall: 0.5783 Loss: 1.0761\n",
      "[Train] Class 0: Precision: 0.7737, Recall: 0.8833\n",
      "[Train] Class 1: Precision: 0.5475, Recall: 0.5042\n",
      "[Train] Class 2: Precision: 0.3846, Recall: 0.3750\n",
      "[Train] Class 3: Precision: 0.5094, Recall: 0.6750\n",
      "[Train] Class 4: Precision: 0.1875, Recall: 0.0250\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.47 batch/s]\n",
      "[Val] Kappa: 0.7336 Accuracy: 0.5775 Precision: 0.5134 Recall: 0.5775\n",
      "\n",
      "Epoch 4/25\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.28 batch/s, lr=5.0e-04, Loss=1.3296]\n",
      "[Train] Kappa: 0.7560 Accuracy: 0.5842 Precision: 0.5624 Recall: 0.5842 Loss: 1.0460\n",
      "[Train] Class 0: Precision: 0.7741, Recall: 0.9139\n",
      "[Train] Class 1: Precision: 0.5273, Recall: 0.5625\n",
      "[Train] Class 2: Precision: 0.3702, Recall: 0.2792\n",
      "[Train] Class 3: Precision: 0.5031, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.5000, Recall: 0.0750\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.18 batch/s]\n",
      "[Val] Kappa: 0.7437 Accuracy: 0.5925 Precision: 0.5452 Recall: 0.5925\n",
      "\n",
      "Epoch 5/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.23 batch/s, lr=5.0e-04, Loss=0.7875]\n",
      "[Train] Kappa: 0.7244 Accuracy: 0.5800 Precision: 0.5421 Recall: 0.5800 Loss: 1.0453\n",
      "[Train] Class 0: Precision: 0.7738, Recall: 0.9028\n",
      "[Train] Class 1: Precision: 0.5148, Recall: 0.5083\n",
      "[Train] Class 2: Precision: 0.4057, Recall: 0.3583\n",
      "[Train] Class 3: Precision: 0.5235, Recall: 0.6500\n",
      "[Train] Class 4: Precision: 0.2121, Recall: 0.0583\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.86 batch/s]\n",
      "[Val] Kappa: 0.7119 Accuracy: 0.5825 Precision: 0.5226 Recall: 0.5825\n",
      "\n",
      "Epoch 6/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.16 batch/s, lr=5.0e-04, Loss=0.9574]\n",
      "[Train] Kappa: 0.7685 Accuracy: 0.6100 Precision: 0.5861 Recall: 0.6100 Loss: 0.9751\n",
      "[Train] Class 0: Precision: 0.8120, Recall: 0.9361\n",
      "[Train] Class 1: Precision: 0.6048, Recall: 0.5292\n",
      "[Train] Class 2: Precision: 0.4066, Recall: 0.4083\n",
      "[Train] Class 3: Precision: 0.5210, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 0.3600, Recall: 0.0750\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.15 batch/s]\n",
      "[Val] Kappa: 0.7587 Accuracy: 0.6575 Precision: 0.5876 Recall: 0.6575\n",
      "\n",
      "Epoch 7/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.15 batch/s, lr=5.0e-04, Loss=0.9301]\n",
      "[Train] Kappa: 0.7414 Accuracy: 0.6050 Precision: 0.5788 Recall: 0.6050 Loss: 0.9895\n",
      "[Train] Class 0: Precision: 0.7621, Recall: 0.9167\n",
      "[Train] Class 1: Precision: 0.5365, Recall: 0.5208\n",
      "[Train] Class 2: Precision: 0.4197, Recall: 0.3375\n",
      "[Train] Class 3: Precision: 0.5613, Recall: 0.7625\n",
      "[Train] Class 4: Precision: 0.4667, Recall: 0.0583\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.92 batch/s]\n",
      "[Val] Kappa: 0.7241 Accuracy: 0.5800 Precision: 0.5776 Recall: 0.5800\n",
      "\n",
      "Epoch 8/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.23 batch/s, lr=5.0e-04, Loss=1.1280]\n",
      "[Train] Kappa: 0.7835 Accuracy: 0.6175 Precision: 0.5967 Recall: 0.6175 Loss: 0.9505\n",
      "[Train] Class 0: Precision: 0.8317, Recall: 0.9194\n",
      "[Train] Class 1: Precision: 0.5620, Recall: 0.5667\n",
      "[Train] Class 2: Precision: 0.4182, Recall: 0.3833\n",
      "[Train] Class 3: Precision: 0.5537, Recall: 0.6875\n",
      "[Train] Class 4: Precision: 0.4048, Recall: 0.1417\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.46 batch/s]\n",
      "[Val] Kappa: 0.6764 Accuracy: 0.5525 Precision: 0.5733 Recall: 0.5525\n",
      "\n",
      "Epoch 9/25\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.27 batch/s, lr=5.0e-04, Loss=1.3972]\n",
      "[Train] Kappa: 0.7768 Accuracy: 0.6208 Precision: 0.5909 Recall: 0.6208 Loss: 0.9719\n",
      "[Train] Class 0: Precision: 0.7814, Recall: 0.9333\n",
      "[Train] Class 1: Precision: 0.6205, Recall: 0.5792\n",
      "[Train] Class 2: Precision: 0.4262, Recall: 0.3250\n",
      "[Train] Class 3: Precision: 0.5422, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.3871, Recall: 0.1000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.45 batch/s]\n",
      "[Val] Kappa: 0.7385 Accuracy: 0.5925 Precision: 0.6160 Recall: 0.5925\n",
      "\n",
      "Epoch 10/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.17 batch/s, lr=5.0e-04, Loss=0.8116]\n",
      "[Train] Kappa: 0.7801 Accuracy: 0.6350 Precision: 0.6157 Recall: 0.6350 Loss: 0.9268\n",
      "[Train] Class 0: Precision: 0.8195, Recall: 0.9333\n",
      "[Train] Class 1: Precision: 0.5926, Recall: 0.5333\n",
      "[Train] Class 2: Precision: 0.4744, Recall: 0.4625\n",
      "[Train] Class 3: Precision: 0.5724, Recall: 0.6917\n",
      "[Train] Class 4: Precision: 0.4200, Recall: 0.1750\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.81 batch/s]\n",
      "[Val] Kappa: 0.6924 Accuracy: 0.5875 Precision: 0.6119 Recall: 0.5875\n",
      "\n",
      "Epoch 11/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.21 batch/s, lr=5.0e-05, Loss=0.6517]\n",
      "[Train] Kappa: 0.8077 Accuracy: 0.6792 Precision: 0.6702 Recall: 0.6792 Loss: 0.8403\n",
      "[Train] Class 0: Precision: 0.8199, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.6304, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5376, Recall: 0.3875\n",
      "[Train] Class 3: Precision: 0.6082, Recall: 0.8083\n",
      "[Train] Class 4: Precision: 0.6897, Recall: 0.1667\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.92 batch/s]\n",
      "[Val] Kappa: 0.7700 Accuracy: 0.6275 Precision: 0.6087 Recall: 0.6275\n",
      "\n",
      "Epoch 12/25\n",
      "Training: 100%|██████████| 38/38 [00:16<00:00,  2.31 batch/s, lr=5.0e-05, Loss=1.2795]\n",
      "[Train] Kappa: 0.8165 Accuracy: 0.6725 Precision: 0.6569 Recall: 0.6725 Loss: 0.8467\n",
      "[Train] Class 0: Precision: 0.8480, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.6608, Recall: 0.6250\n",
      "[Train] Class 2: Precision: 0.5023, Recall: 0.4458\n",
      "[Train] Class 3: Precision: 0.5860, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.5263, Recall: 0.1667\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.10 batch/s]\n",
      "[Val] Kappa: 0.7711 Accuracy: 0.6225 Precision: 0.5902 Recall: 0.6225\n",
      "\n",
      "Epoch 13/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.16 batch/s, lr=5.0e-05, Loss=0.7516]\n",
      "[Train] Kappa: 0.8318 Accuracy: 0.6675 Precision: 0.6534 Recall: 0.6675 Loss: 0.8073\n",
      "[Train] Class 0: Precision: 0.8608, Recall: 0.9444\n",
      "[Train] Class 1: Precision: 0.6340, Recall: 0.6208\n",
      "[Train] Class 2: Precision: 0.4650, Recall: 0.3875\n",
      "[Train] Class 3: Precision: 0.6007, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.5522, Recall: 0.3083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.92 batch/s]\n",
      "[Val] Kappa: 0.7801 Accuracy: 0.6400 Precision: 0.6100 Recall: 0.6400\n",
      "\n",
      "Epoch 14/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.12 batch/s, lr=5.0e-05, Loss=0.6533]\n",
      "[Train] Kappa: 0.8375 Accuracy: 0.7000 Precision: 0.6891 Recall: 0.7000 Loss: 0.7887\n",
      "[Train] Class 0: Precision: 0.8617, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.6723, Recall: 0.6583\n",
      "[Train] Class 2: Precision: 0.5526, Recall: 0.5250\n",
      "[Train] Class 3: Precision: 0.6296, Recall: 0.7083\n",
      "[Train] Class 4: Precision: 0.5968, Recall: 0.3083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.56 batch/s]\n",
      "[Val] Kappa: 0.7863 Accuracy: 0.6575 Precision: 0.6424 Recall: 0.6575\n",
      "\n",
      "Epoch 15/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.14 batch/s, lr=5.0e-05, Loss=0.8944]\n",
      "[Train] Kappa: 0.8558 Accuracy: 0.6992 Precision: 0.6886 Recall: 0.6992 Loss: 0.7860\n",
      "[Train] Class 0: Precision: 0.8610, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.6861, Recall: 0.6375\n",
      "[Train] Class 2: Precision: 0.5561, Recall: 0.5167\n",
      "[Train] Class 3: Precision: 0.6202, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.5781, Recall: 0.3083\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.38 batch/s]\n",
      "[Val] Kappa: 0.7891 Accuracy: 0.6475 Precision: 0.6209 Recall: 0.6475\n",
      "\n",
      "Epoch 16/25\n",
      "Training: 100%|██████████| 38/38 [00:18<00:00,  2.08 batch/s, lr=5.0e-05, Loss=0.9907]\n",
      "[Train] Kappa: 0.8491 Accuracy: 0.6967 Precision: 0.6827 Recall: 0.6967 Loss: 0.8034\n",
      "[Train] Class 0: Precision: 0.8564, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.6835, Recall: 0.6750\n",
      "[Train] Class 2: Precision: 0.5652, Recall: 0.4875\n",
      "[Train] Class 3: Precision: 0.6138, Recall: 0.7417\n",
      "[Train] Class 4: Precision: 0.5323, Recall: 0.2750\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.20 batch/s]\n",
      "[Val] Kappa: 0.7662 Accuracy: 0.6450 Precision: 0.6252 Recall: 0.6450\n",
      "\n",
      "Epoch 17/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.15 batch/s, lr=5.0e-05, Loss=0.6932]\n",
      "[Train] Kappa: 0.8508 Accuracy: 0.7200 Precision: 0.7110 Recall: 0.7200 Loss: 0.7492\n",
      "[Train] Class 0: Precision: 0.8557, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.7376, Recall: 0.6792\n",
      "[Train] Class 2: Precision: 0.5775, Recall: 0.5125\n",
      "[Train] Class 3: Precision: 0.6406, Recall: 0.7500\n",
      "[Train] Class 4: Precision: 0.6316, Recall: 0.4000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.48 batch/s]\n",
      "[Val] Kappa: 0.7987 Accuracy: 0.6525 Precision: 0.6371 Recall: 0.6525\n",
      "\n",
      "Epoch 18/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.15 batch/s, lr=5.0e-05, Loss=0.9399]\n",
      "[Train] Kappa: 0.8498 Accuracy: 0.7000 Precision: 0.6869 Recall: 0.7000 Loss: 0.7616\n",
      "[Train] Class 0: Precision: 0.8627, Recall: 0.9778\n",
      "[Train] Class 1: Precision: 0.6485, Recall: 0.6458\n",
      "[Train] Class 2: Precision: 0.5408, Recall: 0.4417\n",
      "[Train] Class 3: Precision: 0.6393, Recall: 0.7458\n",
      "[Train] Class 4: Precision: 0.6234, Recall: 0.4000\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.00 batch/s]\n",
      "[Val] Kappa: 0.7881 Accuracy: 0.6650 Precision: 0.6527 Recall: 0.6650\n",
      "\n",
      "Epoch 19/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.15 batch/s, lr=5.0e-05, Loss=0.4474]\n",
      "[Train] Kappa: 0.8656 Accuracy: 0.7233 Precision: 0.7129 Recall: 0.7233 Loss: 0.7217\n",
      "[Train] Class 0: Precision: 0.8660, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7477, Recall: 0.6667\n",
      "[Train] Class 2: Precision: 0.6018, Recall: 0.5667\n",
      "[Train] Class 3: Precision: 0.6500, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.5325, Recall: 0.3417\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.72 batch/s]\n",
      "[Val] Kappa: 0.8005 Accuracy: 0.6475 Precision: 0.6350 Recall: 0.6475\n",
      "\n",
      "Epoch 20/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.18 batch/s, lr=5.0e-05, Loss=0.6624]\n",
      "[Train] Kappa: 0.8447 Accuracy: 0.7142 Precision: 0.7044 Recall: 0.7142 Loss: 0.7450\n",
      "[Train] Class 0: Precision: 0.8607, Recall: 0.9611\n",
      "[Train] Class 1: Precision: 0.7111, Recall: 0.6667\n",
      "[Train] Class 2: Precision: 0.5855, Recall: 0.5708\n",
      "[Train] Class 3: Precision: 0.6444, Recall: 0.7250\n",
      "[Train] Class 4: Precision: 0.5797, Recall: 0.3333\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  6.10 batch/s]\n",
      "[Val] Kappa: 0.8010 Accuracy: 0.6725 Precision: 0.6713 Recall: 0.6725\n",
      "\n",
      "Epoch 21/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.18 batch/s, lr=5.0e-06, Loss=0.5834]\n",
      "[Train] Kappa: 0.8687 Accuracy: 0.7200 Precision: 0.7121 Recall: 0.7200 Loss: 0.6966\n",
      "[Train] Class 0: Precision: 0.8635, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.7143, Recall: 0.6458\n",
      "[Train] Class 2: Precision: 0.5556, Recall: 0.5417\n",
      "[Train] Class 3: Precision: 0.6809, Recall: 0.7292\n",
      "[Train] Class 4: Precision: 0.6292, Recall: 0.4667\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.68 batch/s]\n",
      "[Val] Kappa: 0.8092 Accuracy: 0.6750 Precision: 0.6636 Recall: 0.6750\n",
      "\n",
      "Epoch 22/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.13 batch/s, lr=5.0e-06, Loss=0.7575]\n",
      "[Train] Kappa: 0.8593 Accuracy: 0.7167 Precision: 0.7059 Recall: 0.7167 Loss: 0.7250\n",
      "[Train] Class 0: Precision: 0.8668, Recall: 0.9583\n",
      "[Train] Class 1: Precision: 0.6971, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.5750, Recall: 0.4792\n",
      "[Train] Class 3: Precision: 0.6523, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.6098, Recall: 0.4167\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.67 batch/s]\n",
      "[Val] Kappa: 0.8208 Accuracy: 0.6725 Precision: 0.6646 Recall: 0.6725\n",
      "\n",
      "Epoch 23/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.14 batch/s, lr=5.0e-06, Loss=0.7035]\n",
      "[Train] Kappa: 0.8618 Accuracy: 0.7275 Precision: 0.7172 Recall: 0.7275 Loss: 0.7016\n",
      "[Train] Class 0: Precision: 0.8582, Recall: 0.9750\n",
      "[Train] Class 1: Precision: 0.7327, Recall: 0.6625\n",
      "[Train] Class 2: Precision: 0.5882, Recall: 0.5417\n",
      "[Train] Class 3: Precision: 0.6764, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.6026, Recall: 0.3917\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.77 batch/s]\n",
      "[Val] Kappa: 0.7959 Accuracy: 0.6725 Precision: 0.6561 Recall: 0.6725\n",
      "\n",
      "Epoch 24/25\n",
      "Training: 100%|██████████| 38/38 [00:17<00:00,  2.17 batch/s, lr=5.0e-06, Loss=1.0429]\n",
      "[Train] Kappa: 0.8567 Accuracy: 0.7100 Precision: 0.6993 Recall: 0.7100 Loss: 0.7251\n",
      "[Train] Class 0: Precision: 0.8478, Recall: 0.9750\n",
      "[Train] Class 1: Precision: 0.7256, Recall: 0.6500\n",
      "[Train] Class 2: Precision: 0.5484, Recall: 0.4958\n",
      "[Train] Class 3: Precision: 0.6506, Recall: 0.7292\n",
      "[Train] Class 4: Precision: 0.6000, Recall: 0.4250\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.70 batch/s]\n",
      "[Val] Kappa: 0.8027 Accuracy: 0.6700 Precision: 0.6511 Recall: 0.6700\n",
      "\n",
      "Epoch 25/25\n",
      "Training: 100%|██████████| 38/38 [00:18<00:00,  2.11 batch/s, lr=5.0e-06, Loss=0.8401]\n",
      "[Train] Kappa: 0.8548 Accuracy: 0.7242 Precision: 0.7135 Recall: 0.7242 Loss: 0.6970\n",
      "[Train] Class 0: Precision: 0.8747, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.7253, Recall: 0.7042\n",
      "[Train] Class 2: Precision: 0.6028, Recall: 0.5375\n",
      "[Train] Class 3: Precision: 0.6460, Recall: 0.7375\n",
      "[Train] Class 4: Precision: 0.5625, Recall: 0.3750\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.97 batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_53738/2017720590.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/b/b_3_train_with_DeepDRiD_exp.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val] Kappa: 0.7845 Accuracy: 0.6750 Precision: 0.6536 Recall: 0.6750\n",
      "[Val] Best kappa: 0.8208, Epoch 22\n",
      "Evaluating: 100%|██████████| 13/13 [00:02<00:00,  5.38 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_aptos_model_predictions_exp.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    state_dict = torch.load(state_dict_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # # Freeze all layers except the final fully connected (fc) layer\n",
    "    # for param in model.backbone.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # # Ensure only the `fc` layer is trainable\n",
    "    # for param in model.fc.parameters():\n",
    "    #     param.requires_grad = True\n",
    "\n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    #Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path= '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD_exp.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_train_with_DeepDRiD_exp.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    pred_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_b/b_3_aptos_model_predictions_exp.csv\"\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
