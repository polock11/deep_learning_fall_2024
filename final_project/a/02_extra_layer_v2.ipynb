{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = 24\n",
    "num_classes = 5  # 5 DR levelsA\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetinopathyDataset(Dataset):\n",
    "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
    "        self.ann_file = ann_file\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.test = test\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'single':\n",
    "            self.data = self.load_data()\n",
    "        else:\n",
    "            self.data = self.load_data_dual()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'single':\n",
    "            return self.get_item(index)\n",
    "        else:\n",
    "            return self.get_item_dual(index)\n",
    "\n",
    "    # 1. single image\n",
    "    def load_data(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        data = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_info = dict()\n",
    "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item(self, index):\n",
    "        data = self.data[index]\n",
    "        img = Image.open(data['img_path']).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # 2. dual image\n",
    "    def load_data_dual(self):\n",
    "        df = pd.read_csv(self.ann_file)\n",
    "\n",
    "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
    "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
    "        grouped = df.groupby(['prefix', 'suffix'])\n",
    "\n",
    "        data = []\n",
    "        for (prefix, suffix), group in grouped:\n",
    "            file_info = dict()\n",
    "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
    "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
    "            if not self.test:\n",
    "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
    "            data.append(file_info)\n",
    "        return data\n",
    "\n",
    "    def get_item_dual(self, index):\n",
    "        data = self.data[index]\n",
    "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
    "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        if not self.test:\n",
    "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
    "            return [img1, img2], label\n",
    "        else:\n",
    "            return [img1, img2]\n",
    "\n",
    "\n",
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p=0.5):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if np.random.rand() > self.p:\n",
    "            return img\n",
    "\n",
    "        # Ensure the image is a tensor\n",
    "        if not isinstance(img, torch.Tensor):\n",
    "            raise TypeError('Input image must be a torch.Tensor')\n",
    "\n",
    "        # Get height and width of the image\n",
    "        h, w = img.shape[1], img.shape[2]\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
    "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
    "\n",
    "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
    "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "\n",
    "        img[:, ymin:ymax, xmin:xmax] = 0\n",
    "        return img\n",
    "\n",
    "\n",
    "class SLORandomPad:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        pad_width = max(0, self.size[0] - img.width)\n",
    "        pad_height = max(0, self.size[1] - img.height)\n",
    "        pad_left = random.randint(0, pad_width)\n",
    "        pad_top = random.randint(0, pad_height)\n",
    "        pad_right = pad_width - pad_left\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))\n",
    "\n",
    "\n",
    "class FundRandomRotate:\n",
    "    def __init__(self, prob, degree):\n",
    "        self.prob = prob\n",
    "        self.degree = degree\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.prob:\n",
    "            angle = random.uniform(-self.degree, self.degree)\n",
    "            return transforms.functional.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop((210, 210)),\n",
    "    SLORandomPad((224, 224)),\n",
    "    FundRandomRotate(prob=0.5, degree=30),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=25,\n",
    "                checkpoint_path='model.pth'):\n",
    "    best_model = model.state_dict()\n",
    "    best_epoch = None\n",
    "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        running_loss = []\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
    "            for images, labels in train_loader:\n",
    "                if not isinstance(images, list):\n",
    "                    images = images.to(device)  # single image case\n",
    "                else:\n",
    "                    images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "\n",
    "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
    "                pbar.update(1)\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        epoch_loss = sum(running_loss) / len(running_loss)\n",
    "\n",
    "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
    "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
    "\n",
    "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
    "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        if len(train_metrics) > 4:\n",
    "            precision_per_class, recall_per_class = train_metrics[4:]\n",
    "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
    "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "        # Evaluation on the validation set at the end of each epoch\n",
    "        val_metrics = evaluate_model(model, val_loader, device)\n",
    "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
    "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
    "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
    "\n",
    "        if val_kappa > best_val_kappa:\n",
    "            best_val_kappa = val_kappa\n",
    "            best_epoch = epoch\n",
    "            best_model = model.state_dict()\n",
    "            torch.save(best_model, checkpoint_path)\n",
    "\n",
    "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='./test_predictions.csv'):\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_image_ids = []\n",
    "\n",
    "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
    "        for i, data in enumerate(test_loader):\n",
    "\n",
    "            if test_only:\n",
    "                images = data\n",
    "            else:\n",
    "                images, labels = data\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                images = images.to(device)  # single image case\n",
    "            else:\n",
    "                images = [x.to(device) for x in images]  # dual images case\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "\n",
    "            if not isinstance(images, list):\n",
    "                # single image case\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                image_ids = [\n",
    "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
    "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
    "                ]\n",
    "                all_image_ids.extend(image_ids)\n",
    "                if not test_only:\n",
    "                    all_labels.extend(labels.numpy())\n",
    "            else:\n",
    "                # dual images case\n",
    "                for k in range(2):\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    image_ids = [\n",
    "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
    "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
    "                    ]\n",
    "                    all_image_ids.extend(image_ids)\n",
    "                    if not test_only:\n",
    "                        all_labels.extend(labels.numpy())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save predictions to csv file for Kaggle online evaluation\n",
    "    if test_only:\n",
    "        df = pd.DataFrame({\n",
    "            'ID': all_image_ids,\n",
    "            'TARGET': all_preds\n",
    "        })\n",
    "        df.to_csv(prediction_path, index=False)\n",
    "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
    "    else:\n",
    "        metrics = compute_metrics(all_preds, all_labels)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels, per_class=False):\n",
    "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate and print precision and recall for each class\n",
    "    if per_class:\n",
    "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
    "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
    "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
    "\n",
    "    return kappa, accuracy, precision, recall\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyDualModel(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        backbone.fc = nn.Identity()\n",
    "\n",
    "        # Here the two backbones will have the same structure but unshared weights\n",
    "        self.backbone1 = copy.deepcopy(backbone)\n",
    "        self.backbone2 = copy.deepcopy(backbone)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        image1, image2 = images\n",
    "\n",
    "        x1 = self.backbone1(image1)\n",
    "        x2 = self.backbone2(image2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Dropout(p=0.4, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "Pipeline Mode: single\n",
      "Device: mps\n",
      "\n",
      "Epoch 1/25\n",
      "Training: 100%|██████████| 50/50 [00:19<00:00,  2.58 batch/s, lr=1.0e-04, Loss=1.5888]\n",
      "[Train] Kappa: 0.0139 Accuracy: 0.2450 Precision: 0.2228 Recall: 0.2450 Loss: 1.5969\n",
      "[Train] Class 0: Precision: 0.3395, Recall: 0.4556\n",
      "[Train] Class 1: Precision: 0.2196, Recall: 0.2333\n",
      "[Train] Class 2: Precision: 0.1782, Recall: 0.1500\n",
      "[Train] Class 3: Precision: 0.1935, Recall: 0.1500\n",
      "[Train] Class 4: Precision: 0.0270, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.98 batch/s]\n",
      "[Val] Kappa: 0.0000 Accuracy: 0.3000 Precision: 0.0900 Recall: 0.3000\n",
      "\n",
      "Epoch 2/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.29 batch/s, lr=1.0e-04, Loss=1.8206]\n",
      "[Train] Kappa: 0.1517 Accuracy: 0.3775 Precision: 0.2993 Recall: 0.3775 Loss: 1.3934\n",
      "[Train] Class 0: Precision: 0.4255, Recall: 0.9278\n",
      "[Train] Class 1: Precision: 0.2886, Recall: 0.2417\n",
      "[Train] Class 2: Precision: 0.2842, Recall: 0.1125\n",
      "[Train] Class 3: Precision: 0.2857, Recall: 0.1417\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.66 batch/s]\n",
      "[Val] Kappa: 0.2507 Accuracy: 0.4250 Precision: 0.2379 Recall: 0.4250\n",
      "\n",
      "Epoch 3/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.21 batch/s, lr=1.0e-04, Loss=1.1231]\n",
      "[Train] Kappa: 0.4409 Accuracy: 0.4558 Precision: 0.3914 Recall: 0.4558 Loss: 1.2414\n",
      "[Train] Class 0: Precision: 0.7277, Recall: 0.9500\n",
      "[Train] Class 1: Precision: 0.2610, Recall: 0.3958\n",
      "[Train] Class 2: Precision: 0.2941, Recall: 0.2708\n",
      "[Train] Class 3: Precision: 0.3103, Recall: 0.1875\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.29 batch/s]\n",
      "[Val] Kappa: 0.2871 Accuracy: 0.4525 Precision: 0.2797 Recall: 0.4525\n",
      "\n",
      "Epoch 4/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.28 batch/s, lr=1.0e-04, Loss=1.1766]\n",
      "[Train] Kappa: 0.4313 Accuracy: 0.4675 Precision: 0.4205 Recall: 0.4675 Loss: 1.1468\n",
      "[Train] Class 0: Precision: 0.7973, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.2781, Recall: 0.5667\n",
      "[Train] Class 2: Precision: 0.2511, Recall: 0.2292\n",
      "[Train] Class 3: Precision: 0.3774, Recall: 0.0833\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.02 batch/s]\n",
      "[Val] Kappa: 0.3268 Accuracy: 0.4625 Precision: 0.4486 Recall: 0.4625\n",
      "\n",
      "Epoch 5/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.12 batch/s, lr=1.0e-04, Loss=0.9859]\n",
      "[Train] Kappa: 0.5486 Accuracy: 0.4983 Precision: 0.4441 Recall: 0.4983 Loss: 1.1368\n",
      "[Train] Class 0: Precision: 0.8282, Recall: 0.9639\n",
      "[Train] Class 1: Precision: 0.3395, Recall: 0.6083\n",
      "[Train] Class 2: Precision: 0.2575, Recall: 0.2500\n",
      "[Train] Class 3: Precision: 0.3814, Recall: 0.1875\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.19 batch/s]\n",
      "[Val] Kappa: 0.6835 Accuracy: 0.5525 Precision: 0.4871 Recall: 0.5525\n",
      "\n",
      "Epoch 6/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.20 batch/s, lr=1.0e-04, Loss=1.1239]\n",
      "[Train] Kappa: 0.6985 Accuracy: 0.5658 Precision: 0.4967 Recall: 0.5658 Loss: 1.0465\n",
      "[Train] Class 0: Precision: 0.8274, Recall: 0.9722\n",
      "[Train] Class 1: Precision: 0.4836, Recall: 0.6125\n",
      "[Train] Class 2: Precision: 0.3209, Recall: 0.2875\n",
      "[Train] Class 3: Precision: 0.4380, Recall: 0.4708\n",
      "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.17 batch/s]\n",
      "[Val] Kappa: 0.6933 Accuracy: 0.5950 Precision: 0.5287 Recall: 0.5950\n",
      "\n",
      "Epoch 7/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.19 batch/s, lr=1.0e-04, Loss=1.4070]\n",
      "[Train] Kappa: 0.7622 Accuracy: 0.5942 Precision: 0.6230 Recall: 0.5942 Loss: 1.0211\n",
      "[Train] Class 0: Precision: 0.8249, Recall: 0.9556\n",
      "[Train] Class 1: Precision: 0.5379, Recall: 0.5917\n",
      "[Train] Class 2: Precision: 0.3743, Recall: 0.2667\n",
      "[Train] Class 3: Precision: 0.4653, Recall: 0.6708\n",
      "[Train] Class 4: Precision: 1.0000, Recall: 0.0167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.37 batch/s]\n",
      "[Val] Kappa: 0.5303 Accuracy: 0.4875 Precision: 0.3832 Recall: 0.4875\n",
      "\n",
      "Epoch 8/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.03 batch/s, lr=1.0e-04, Loss=0.7896]\n",
      "[Train] Kappa: 0.7745 Accuracy: 0.6150 Precision: 0.5849 Recall: 0.6150 Loss: 0.9517\n",
      "[Train] Class 0: Precision: 0.8290, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.5607, Recall: 0.5583\n",
      "[Train] Class 2: Precision: 0.4184, Recall: 0.2458\n",
      "[Train] Class 3: Precision: 0.4935, Recall: 0.7958\n",
      "[Train] Class 4: Precision: 0.4167, Recall: 0.0417\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.10 batch/s]\n",
      "[Val] Kappa: 0.6864 Accuracy: 0.5800 Precision: 0.4999 Recall: 0.5800\n",
      "\n",
      "Epoch 9/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.03 batch/s, lr=1.0e-04, Loss=0.9631]\n",
      "[Train] Kappa: 0.7830 Accuracy: 0.6092 Precision: 0.5770 Recall: 0.6092 Loss: 0.9233\n",
      "[Train] Class 0: Precision: 0.8571, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.5462, Recall: 0.5917\n",
      "[Train] Class 2: Precision: 0.3989, Recall: 0.3042\n",
      "[Train] Class 3: Precision: 0.5032, Recall: 0.6458\n",
      "[Train] Class 4: Precision: 0.3023, Recall: 0.1083\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.70 batch/s]\n",
      "[Val] Kappa: 0.7766 Accuracy: 0.6375 Precision: 0.5694 Recall: 0.6375\n",
      "\n",
      "Epoch 10/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.06 batch/s, lr=1.0e-04, Loss=1.0758]\n",
      "[Train] Kappa: 0.8236 Accuracy: 0.6317 Precision: 0.6115 Recall: 0.6317 Loss: 0.8898\n",
      "[Train] Class 0: Precision: 0.8660, Recall: 0.9694\n",
      "[Train] Class 1: Precision: 0.5854, Recall: 0.6000\n",
      "[Train] Class 2: Precision: 0.4727, Recall: 0.3250\n",
      "[Train] Class 3: Precision: 0.4941, Recall: 0.7000\n",
      "[Train] Class 4: Precision: 0.4130, Recall: 0.1583\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.16 batch/s]\n",
      "[Val] Kappa: 0.7379 Accuracy: 0.5600 Precision: 0.5881 Recall: 0.5600\n",
      "\n",
      "Epoch 11/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.04 batch/s, lr=1.0e-05, Loss=0.9363]\n",
      "[Train] Kappa: 0.8291 Accuracy: 0.6517 Precision: 0.6381 Recall: 0.6517 Loss: 0.8425\n",
      "[Train] Class 0: Precision: 0.8810, Recall: 0.9667\n",
      "[Train] Class 1: Precision: 0.6651, Recall: 0.5875\n",
      "[Train] Class 2: Precision: 0.4694, Recall: 0.3833\n",
      "[Train] Class 3: Precision: 0.5125, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.4444, Recall: 0.1333\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.88 batch/s]\n",
      "[Val] Kappa: 0.8111 Accuracy: 0.6375 Precision: 0.5668 Recall: 0.6375\n",
      "\n",
      "Epoch 12/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.08 batch/s, lr=1.0e-05, Loss=0.7559]\n",
      "[Train] Kappa: 0.8382 Accuracy: 0.6708 Precision: 0.6529 Recall: 0.6708 Loss: 0.8021\n",
      "[Train] Class 0: Precision: 0.8704, Recall: 0.9889\n",
      "[Train] Class 1: Precision: 0.6482, Recall: 0.6833\n",
      "[Train] Class 2: Precision: 0.5115, Recall: 0.3708\n",
      "[Train] Class 3: Precision: 0.5401, Recall: 0.7583\n",
      "[Train] Class 4: Precision: 0.5185, Recall: 0.1167\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.14 batch/s]\n",
      "[Val] Kappa: 0.8013 Accuracy: 0.6350 Precision: 0.5696 Recall: 0.6350\n",
      "\n",
      "Epoch 13/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  3.95 batch/s, lr=1.0e-05, Loss=0.7204]\n",
      "[Train] Kappa: 0.8482 Accuracy: 0.6775 Precision: 0.6583 Recall: 0.6775 Loss: 0.7664\n",
      "[Train] Class 0: Precision: 0.8837, Recall: 0.9917\n",
      "[Train] Class 1: Precision: 0.6546, Recall: 0.6792\n",
      "[Train] Class 2: Precision: 0.5689, Recall: 0.3958\n",
      "[Train] Class 3: Precision: 0.5284, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.4286, Recall: 0.1000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.07 batch/s]\n",
      "[Val] Kappa: 0.8211 Accuracy: 0.6550 Precision: 0.5821 Recall: 0.6550\n",
      "\n",
      "Epoch 14/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.01 batch/s, lr=1.0e-05, Loss=0.6796]\n",
      "[Train] Kappa: 0.8491 Accuracy: 0.6775 Precision: 0.6514 Recall: 0.6775 Loss: 0.7624\n",
      "[Train] Class 0: Precision: 0.8867, Recall: 1.0000\n",
      "[Train] Class 1: Precision: 0.6769, Recall: 0.7333\n",
      "[Train] Class 2: Precision: 0.5192, Recall: 0.3375\n",
      "[Train] Class 3: Precision: 0.5271, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.4074, Recall: 0.0917\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.13 batch/s]\n",
      "[Val] Kappa: 0.8078 Accuracy: 0.6525 Precision: 0.5803 Recall: 0.6525\n",
      "\n",
      "Epoch 15/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.27 batch/s, lr=1.0e-05, Loss=0.6330]\n",
      "[Train] Kappa: 0.8463 Accuracy: 0.6783 Precision: 0.6502 Recall: 0.6783 Loss: 0.7682\n",
      "[Train] Class 0: Precision: 0.8837, Recall: 0.9917\n",
      "[Train] Class 1: Precision: 0.6774, Recall: 0.7000\n",
      "[Train] Class 2: Precision: 0.5602, Recall: 0.3875\n",
      "[Train] Class 3: Precision: 0.5314, Recall: 0.7750\n",
      "[Train] Class 4: Precision: 0.3125, Recall: 0.0833\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.96 batch/s]\n",
      "[Val] Kappa: 0.7789 Accuracy: 0.6400 Precision: 0.5650 Recall: 0.6400\n",
      "\n",
      "Epoch 16/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.18 batch/s, lr=1.0e-05, Loss=0.9699]\n",
      "[Train] Kappa: 0.8539 Accuracy: 0.6850 Precision: 0.6654 Recall: 0.6850 Loss: 0.7579\n",
      "[Train] Class 0: Precision: 0.8815, Recall: 0.9917\n",
      "[Train] Class 1: Precision: 0.6877, Recall: 0.7250\n",
      "[Train] Class 2: Precision: 0.5921, Recall: 0.3750\n",
      "[Train] Class 3: Precision: 0.5318, Recall: 0.7667\n",
      "[Train] Class 4: Precision: 0.3864, Recall: 0.1417\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.44 batch/s]\n",
      "[Val] Kappa: 0.7841 Accuracy: 0.6600 Precision: 0.5859 Recall: 0.6600\n",
      "\n",
      "Epoch 17/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.27 batch/s, lr=1.0e-05, Loss=0.7806]\n",
      "[Train] Kappa: 0.8664 Accuracy: 0.6950 Precision: 0.6910 Recall: 0.6950 Loss: 0.7380\n",
      "[Train] Class 0: Precision: 0.8897, Recall: 0.9861\n",
      "[Train] Class 1: Precision: 0.6898, Recall: 0.7042\n",
      "[Train] Class 2: Precision: 0.5598, Recall: 0.4292\n",
      "[Train] Class 3: Precision: 0.5494, Recall: 0.7875\n",
      "[Train] Class 4: Precision: 0.6429, Recall: 0.1500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.17 batch/s]\n",
      "[Val] Kappa: 0.7985 Accuracy: 0.6350 Precision: 0.5584 Recall: 0.6350\n",
      "\n",
      "Epoch 18/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.14 batch/s, lr=1.0e-05, Loss=0.9218]\n",
      "[Train] Kappa: 0.8548 Accuracy: 0.6900 Precision: 0.6751 Recall: 0.6900 Loss: 0.7401\n",
      "[Train] Class 0: Precision: 0.8864, Recall: 0.9750\n",
      "[Train] Class 1: Precision: 0.6766, Recall: 0.7583\n",
      "[Train] Class 2: Precision: 0.5864, Recall: 0.3958\n",
      "[Train] Class 3: Precision: 0.5409, Recall: 0.7708\n",
      "[Train] Class 4: Precision: 0.4839, Recall: 0.1250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.34 batch/s]\n",
      "[Val] Kappa: 0.7693 Accuracy: 0.6350 Precision: 0.5602 Recall: 0.6350\n",
      "\n",
      "Epoch 19/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.30 batch/s, lr=1.0e-05, Loss=0.7708]\n",
      "[Train] Kappa: 0.8599 Accuracy: 0.7075 Precision: 0.6968 Recall: 0.7075 Loss: 0.7187\n",
      "[Train] Class 0: Precision: 0.9036, Recall: 0.9889\n",
      "[Train] Class 1: Precision: 0.7025, Recall: 0.7083\n",
      "[Train] Class 2: Precision: 0.6117, Recall: 0.4792\n",
      "[Train] Class 3: Precision: 0.5572, Recall: 0.7917\n",
      "[Train] Class 4: Precision: 0.5143, Recall: 0.1500\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.70 batch/s]\n",
      "[Val] Kappa: 0.8020 Accuracy: 0.6400 Precision: 0.5662 Recall: 0.6400\n",
      "\n",
      "Epoch 20/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.11 batch/s, lr=1.0e-05, Loss=0.7263]\n",
      "[Train] Kappa: 0.8522 Accuracy: 0.6967 Precision: 0.6843 Recall: 0.6967 Loss: 0.7194\n",
      "[Train] Class 0: Precision: 0.8945, Recall: 0.9889\n",
      "[Train] Class 1: Precision: 0.6770, Recall: 0.7250\n",
      "[Train] Class 2: Precision: 0.5697, Recall: 0.3917\n",
      "[Train] Class 3: Precision: 0.5587, Recall: 0.8125\n",
      "[Train] Class 4: Precision: 0.5484, Recall: 0.1417\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  9.34 batch/s]\n",
      "[Val] Kappa: 0.8096 Accuracy: 0.6375 Precision: 0.5636 Recall: 0.6375\n",
      "\n",
      "Epoch 21/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.14 batch/s, lr=1.0e-06, Loss=0.7128]\n",
      "[Train] Kappa: 0.8699 Accuracy: 0.7058 Precision: 0.6924 Recall: 0.7058 Loss: 0.6941\n",
      "[Train] Class 0: Precision: 0.8962, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.6944, Recall: 0.7292\n",
      "[Train] Class 2: Precision: 0.6199, Recall: 0.4417\n",
      "[Train] Class 3: Precision: 0.5613, Recall: 0.8208\n",
      "[Train] Class 4: Precision: 0.4839, Recall: 0.1250\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.81 batch/s]\n",
      "[Val] Kappa: 0.8062 Accuracy: 0.6450 Precision: 0.5705 Recall: 0.6450\n",
      "\n",
      "Epoch 22/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.05 batch/s, lr=1.0e-06, Loss=0.6039]\n",
      "[Train] Kappa: 0.8661 Accuracy: 0.7083 Precision: 0.7028 Recall: 0.7083 Loss: 0.7167\n",
      "[Train] Class 0: Precision: 0.8894, Recall: 0.9833\n",
      "[Train] Class 1: Precision: 0.6976, Recall: 0.7208\n",
      "[Train] Class 2: Precision: 0.6080, Recall: 0.4458\n",
      "[Train] Class 3: Precision: 0.5664, Recall: 0.8000\n",
      "[Train] Class 4: Precision: 0.6154, Recall: 0.2000\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.34 batch/s]\n",
      "[Val] Kappa: 0.8040 Accuracy: 0.6425 Precision: 0.5672 Recall: 0.6425\n",
      "\n",
      "Epoch 23/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.12 batch/s, lr=1.0e-06, Loss=0.7617]\n",
      "[Train] Kappa: 0.8859 Accuracy: 0.7067 Precision: 0.6927 Recall: 0.7067 Loss: 0.6899\n",
      "[Train] Class 0: Precision: 0.9000, Recall: 1.0000\n",
      "[Train] Class 1: Precision: 0.7068, Recall: 0.7333\n",
      "[Train] Class 2: Precision: 0.5896, Recall: 0.4250\n",
      "[Train] Class 3: Precision: 0.5616, Recall: 0.7792\n",
      "[Train] Class 4: Precision: 0.5111, Recall: 0.1917\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  7.81 batch/s]\n",
      "[Val] Kappa: 0.8001 Accuracy: 0.6375 Precision: 0.5628 Recall: 0.6375\n",
      "\n",
      "Epoch 24/25\n",
      "Training: 100%|██████████| 50/50 [00:12<00:00,  4.09 batch/s, lr=1.0e-06, Loss=0.7228]\n",
      "[Train] Kappa: 0.8638 Accuracy: 0.6950 Precision: 0.6895 Recall: 0.6950 Loss: 0.7317\n",
      "[Train] Class 0: Precision: 0.8925, Recall: 0.9917\n",
      "[Train] Class 1: Precision: 0.6844, Recall: 0.6958\n",
      "[Train] Class 2: Precision: 0.5380, Recall: 0.3833\n",
      "[Train] Class 3: Precision: 0.5529, Recall: 0.7833\n",
      "[Train] Class 4: Precision: 0.6667, Recall: 0.2500\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.17 batch/s]\n",
      "[Val] Kappa: 0.7946 Accuracy: 0.6300 Precision: 0.5539 Recall: 0.6300\n",
      "\n",
      "Epoch 25/25\n",
      "Training: 100%|██████████| 50/50 [00:11<00:00,  4.28 batch/s, lr=1.0e-06, Loss=0.6530]\n",
      "[Train] Kappa: 0.8710 Accuracy: 0.7092 Precision: 0.6996 Recall: 0.7092 Loss: 0.6842\n",
      "[Train] Class 0: Precision: 0.8883, Recall: 0.9944\n",
      "[Train] Class 1: Precision: 0.6953, Recall: 0.7417\n",
      "[Train] Class 2: Precision: 0.6235, Recall: 0.4208\n",
      "[Train] Class 3: Precision: 0.5647, Recall: 0.8000\n",
      "[Train] Class 4: Precision: 0.5641, Recall: 0.1833\n",
      "Evaluating: 100%|██████████| 17/17 [00:02<00:00,  8.30 batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/t87m92j14g9b1yw35n324r5w0000gn/T/ipykernel_32568/480676328.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_extra_layer_v1.pth', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val] Kappa: 0.8021 Accuracy: 0.6425 Precision: 0.5676 Recall: 0.6425\n",
      "[Val] Best kappa: 0.8211, Epoch 13\n",
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00,  8.61 batch/s]\n",
      "[Test] Save predictions to /Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_extra_layer_v1.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Choose between 'single image' and 'dual images' pipeline\n",
    "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
    "\n",
    "    mode = 'single'  # forward single image to the model each time\n",
    "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
    "\n",
    "    assert mode in ('single', 'dual')\n",
    "\n",
    "    # Define the model\n",
    "    if mode == 'single':\n",
    "        model = MyModel()\n",
    "    else:\n",
    "        model = MyDualModel()\n",
    "\n",
    "    print(model, '\\n')\n",
    "    print('Pipeline Mode:', mode)\n",
    "\n",
    "    # Create datasets\n",
    "\n",
    "    train_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train/\"\n",
    "    train_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/train.csv\"\n",
    "    val_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val/\"\n",
    "    val_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/val.csv\"\n",
    "    test_dir = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test\"\n",
    "    test_ann_file = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/DeepDRiD/test.csv\"\n",
    "\n",
    "    train_dataset = RetinopathyDataset(ann_file=train_ann_file, image_dir=train_dir, mode=mode, transform=transform_train)\n",
    "    val_dataset = RetinopathyDataset(ann_file=val_ann_file, image_dir=val_dir, mode=mode, transform=transform_test)\n",
    "    test_dataset = RetinopathyDataset(ann_file=test_ann_file, image_dir=test_dir, mode=mode, transform=transform_test, test=True)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define the weighted CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Use GPU device is possible\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    # Move class weights to the device\n",
    "    #state_dict_path = \"/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/models/train_with_APTOS.pth\"\n",
    "    #state_dict = torch.load(state_dict_path, map_location='cpu')\n",
    "    #model.load_state_dict(state_dict, strict=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "\n",
    "    # Optimizer and Learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    # Train and evaluate the model with the training and validation set\n",
    "    model = train_model(\n",
    "        model, train_loader, val_loader, device, criterion, optimizer,\n",
    "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
    "        checkpoint_path='/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_extra_layer_v1.pth'\n",
    "    )\n",
    "\n",
    "    # Load the pretrained checkpoint\n",
    "    state_dict = torch.load('/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_extra_layer_v1.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    # Make predictions on testing set and save the prediction results\n",
    "    pred_path = '/Users/shakibibnashameem/Documents/Practice/deep_learning_fall_2024/final_project/data/results/res_a/a_2_extra_layer_v1.csv'\n",
    "    evaluate_model(model, test_loader, device, test_only=True, prediction_path=pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
